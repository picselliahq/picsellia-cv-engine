{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udccc Welcome to the Picsellia CV Engine Docs","text":"<p>Picsellia CV Engine is a modular toolkit for building, testing, and deploying computer vision pipelines \u2014 all fully integrated with Picsellia. Whether you're processing datasets, training models, or deploying experiments, this engine helps you structure everything in a clean, reusable way.</p>"},{"location":"#whats-a-pipeline","title":"\ud83e\udde0 What\u2019s a pipeline?","text":"<p>A pipeline is a sequence of steps that defines how data flows \u2014 from raw inputs to final results.</p> <p>In Picsellia CV Engine, pipelines are used for both:</p> <ul> <li> <p>Training pipelines:</p> <p>Load training datasets, configure a model, run training, log results and export weights.</p> </li> <li> <p>Processing pipelines:</p> <p>Clean or filter datasets, apply data augmentation, run inference for pre-annotation, or convert formats.</p> </li> </ul> <p>Each unit of work is a step \u2014 a standalone function decorated with @step. You can reuse, extend, or combine steps freely depending on your needs.</p>"},{"location":"#key-features","title":"\u2728 Key features","text":"<ul> <li>Composable Steps \u2013 Use or customize ready-made steps for common operations (loading data, training, etc.)</li> <li>Training Pipelines \u2013 Structure model training (e.g. Ultralytics YOLO) with built-in logic</li> <li>Processing Pipelines \u2013 Clean, transform, or validate datasets before use</li> <li>Framework Extensions \u2013 Support custom training libraries via a pluggable architecture</li> <li>CLI Automation \u2013 Use <code>pxl-pipeline</code> cli to scaffold, test, and deploy pipelines locally or on Picsellia</li> </ul>"},{"location":"#get-started","title":"\ud83d\ude80 Get started","text":"<ul> <li>\ud83d\udce6 Installation Guide \u2013 Set up the engine and CLI</li> <li>\ud83d\udee0 Usage Guide \u2013 Build your first processing or training pipeline</li> <li>\ud83d\udcd6 API Reference \u2013 Explore contexts, decorators, steps, and framework integrations</li> </ul>"},{"location":"#new-to-picsellia","title":"\ud83d\udc4b New to Picsellia?","text":"<ul> <li>Learn more about the Picsellia platform</li> <li>Docs for the core Picsellia SDK</li> <li>Reach out for support or contribution ideas!</li> </ul>"},{"location":"installation/","title":"\ud83d\udce6 Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python &gt;=3.10</li> </ul>"},{"location":"installation/#install-via-pypi","title":"Install via PyPI","text":"<p>Use this option if you want to use the CV Engine and Pipeline CLI without modifying the code.</p> <p>\u2705 With uv</p> <pre><code>uv add picsellia-cv-engine\nuv add picsellia-pipelines-cli\n</code></pre> <p>\u2705 With pip</p> <pre><code>pip install picsellia-cv-engine\npip install picsellia-pipelines-cli\n</code></pre> <p>After that, the CLI is available as:</p> <pre><code>pxl-pipeline --help\n</code></pre>"},{"location":"installation/#develop-locally","title":"Develop Locally","text":"<p>Use this setup if you're contributing or exploring the codebase.</p> <ol> <li>Clone the repository</li> </ol> <pre><code>git clone https://github.com/picselliahq/picsellia-cv-engine.git\ncd picsellia-cv-engine\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>uv sync\n</code></pre> <ol> <li>Serve the documentation locally (optional)</li> </ol> <pre><code>uv run mkdocs serve -a 127.0.0.1:8080\n</code></pre> <p>Then open http://127.0.0.1:8080 in your browser.</p>"},{"location":"api/","title":"\ud83d\udcd6 API Reference","text":"<p>The Picsellia CV Engine API is a modular toolkit for building end-to-end pipelines. It\u2019s organized into reusable components, decorators, and framework-specific extensions.</p>"},{"location":"api/#core-concepts","title":"Core concepts","text":"<ul> <li>Steps: Modular units of logic (e.g. load, train, validate)</li> <li>Pipelines: Logical flows decorated with <code>@pipeline</code>, composed of <code>@step</code></li> <li>Contexts: Injected objects carrying pipeline configuration and metadata</li> </ul>"},{"location":"api/#built-in-components","title":"Built-in components","text":""},{"location":"api/#base-steps","title":"Base steps","text":""},{"location":"api/#dataset","title":"Dataset","text":"<ul> <li>Loader</li> <li>Preprocessor</li> <li>Uploader</li> <li>Validator</li> </ul>"},{"location":"api/#model","title":"Model","text":"<ul> <li>Builder</li> <li>Evaluator</li> </ul>"},{"location":"api/#datalake","title":"Datalake","text":"<ul> <li>Loader</li> </ul>"},{"location":"api/#framework-specific-extensions","title":"Framework-Specific extensions","text":"<p>Frameworks are isolated under: <code>src/picsellia_cv_engine/frameworks/&lt;framework_name&gt;/</code></p> <p>Each framework can include:</p> <ul> <li>Custom model modules</li> <li>Hyperparameter definitions</li> <li>Training, evaluation, or export services</li> <li>Framework-specific steps</li> </ul>"},{"location":"api/#decorators","title":"Decorators","text":"<ul> <li>@pipeline \u2013 Defines a pipeline entrypoint</li> <li>@step \u2013 Marks a function as a step</li> <li>Step Metadata</li> </ul>"},{"location":"api/#data-models","title":"Data models","text":"<ul> <li>COCO Dataset</li> <li>Dataset Collection</li> <li>Datalake Collection</li> </ul>"},{"location":"api/#code-example","title":"Code example","text":"<pre><code>from picsellia_cv_engine.decorators.pipeline_decorator import pipeline\nfrom picsellia_cv_engine.steps.base.dataset.loader import load_yolo_datasets\n\n@pipeline\ndef my_pipeline():\n    dataset = load_yolo_datasets()\n    ...\n</code></pre>"},{"location":"api/core/step_metadata/","title":"core.step_metadata","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata","title":"<code>step_metadata</code>","text":"<p>Classes:</p> Name Description <code>StepMetadata</code>"},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata","title":"<code>StepMetadata(id, name, display_name, state, log_file_path=None)</code>","text":"<p>Attributes:</p> Name Type Description <code>id</code> <code>name</code> <code>display_name</code> <code>state</code> <code>execution_time</code> <code>log_file_path</code> <code>index</code> <code>int | None</code>"},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.id","title":"<code>id = id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.display_name","title":"<code>display_name = display_name</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.state","title":"<code>state = state</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.execution_time","title":"<code>execution_time = 0.0</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.log_file_path","title":"<code>log_file_path = log_file_path</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/step_metadata/#picsellia_cv_engine.core.step_metadata.StepMetadata.index","title":"<code>index = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/","title":"core.contexts.common.picsellia_context","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context","title":"<code>picsellia_context</code>","text":"<p>Classes:</p> Name Description <code>PicselliaContext</code>"},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext","title":"<code>PicselliaContext(api_token=None, host=None, organization_id=None, organization_name=None, working_dir=None)</code>","text":"<p>               Bases: <code>ABC</code></p> <p>This context manages authentication and client setup for interacting with Picsellia. It must be subclassed to define a specific working directory once an identifier (e.g., experiment ID or job ID) becomes available.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[str]</code> <p>API token used to authenticate with the Picsellia API. If not provided, the value is read from the 'api_token' environment variable.</p> <code>None</code> <code>Optional[str]</code> <p>Host URL of the Picsellia server. Defaults to 'https://app.picsellia.com'.</p> <code>None</code> <code>Optional[str]</code> <p>ID of the Picsellia organization. Can also be set via the 'organization_id' env variable.</p> <code>None</code> <code>Optional[str]</code> <p>Name of the Picsellia organization. Can also be set via the 'organization_name' env variable.</p> <code>None</code> <code>Optional[str]</code> <p>Optional override for the working directory.</p> <code>None</code> <p>Methods:</p> Name Description <code>to_dict</code> <p>Converts the context to a dictionary representation.</p> <p>Attributes:</p> Name Type Description <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code> <code>working_dir</code> <code>str</code> <p>Abstract property to define the working directory path.</p>"},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext(api_token)","title":"<code>api_token</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext(host)","title":"<code>host</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext(organization_id)","title":"<code>organization_id</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext(organization_name)","title":"<code>organization_name</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext(working_dir)","title":"<code>working_dir</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.working_dir","title":"<code>working_dir</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Abstract property to define the working directory path.</p> <p>This should be implemented by subclasses to specify where files such as datasets, weights, and logs are stored locally.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the working directory.</p>"},{"location":"api/core/contexts/common/picsellia_context/#picsellia_cv_engine.core.contexts.common.picsellia_context.PicselliaContext.to_dict","title":"<code>to_dict()</code>  <code>abstractmethod</code>","text":"<p>Converts the context to a dictionary representation.</p> <p>This method should be implemented by subclasses to expose their internal parameters and configuration for logging or serialization purposes.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/","title":"core.contexts.processing.datalake.local_context","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context","title":"<code>local_context</code>","text":"<p>Classes:</p> Name Description <code>LocalDatalakeProcessingContext</code> <p>Context for local testing of processing jobs without real job execution on Picsellia.</p> <p>Functions:</p> Name Description <code>create_processing</code> <p>Create a processing configuration in Picsellia.</p> <code>get_processing</code> <p>Get the ID of a processing by name.</p> <code>launch_processing</code> <p>Launch a processing job on a datalake.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext","title":"<code>LocalDatalakeProcessingContext(processing_parameters_cls, processing_parameters=None, api_token=None, host=None, organization_id=None, organization_name=None, job_id=None, job_type=None, input_datalake_id=None, output_datalake_id=None, model_version_id=None, offset=0, limit=100, use_id=True, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code></p> <p>Context for local testing of processing jobs without real job execution on Picsellia.</p> <p>Methods:</p> Name Description <code>get_datalake</code> <p>Retrieve a datalake by its ID.</p> <code>get_model_version</code> <p>Retrieve a model version by its ID.</p> <code>get_data_ids</code> <p>List data IDs from a datalake with offset and limit.</p> <code>to_dict</code> <p>Convert the context to a dictionary.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>job_type</code> <code>use_id</code> <code>input_datalake_id</code> <code>output_datalake_id</code> <code>model_version_id</code> <code>input_datalake</code> <code>output_datalake</code> <code>model_version</code> <code>offset</code> <code>limit</code> <code>data_ids</code> <code>processing_parameters</code> <code>working_dir</code> <code>str</code> <p>Return the working directory path for the job.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.job_id","title":"<code>job_id = job_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.job_type","title":"<code>job_type = job_type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.input_datalake_id","title":"<code>input_datalake_id = input_datalake_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.output_datalake_id","title":"<code>output_datalake_id = output_datalake_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.model_version_id","title":"<code>model_version_id = model_version_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.input_datalake","title":"<code>input_datalake = self.get_datalake(input_datalake_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.output_datalake","title":"<code>output_datalake = self.get_datalake(output_datalake_id) if output_datalake_id else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.model_version","title":"<code>model_version = self.get_model_version(model_version_id=model_version_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.offset","title":"<code>offset = offset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.limit","title":"<code>limit = limit</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.data_ids","title":"<code>data_ids = self.get_data_ids(datalake=(self.input_datalake), offset=(self.offset), limit=(self.limit))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.processing_parameters","title":"<code>processing_parameters = processing_parameters_cls(log_data=(processing_parameters or {}))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory path for the job.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.get_datalake","title":"<code>get_datalake(datalake_id)</code>","text":"<p>Retrieve a datalake by its ID.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.get_model_version","title":"<code>get_model_version(model_version_id)</code>","text":"<p>Retrieve a model version by its ID.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.get_data_ids","title":"<code>get_data_ids(datalake, offset, limit)</code>","text":"<p>List data IDs from a datalake with offset and limit.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.LocalDatalakeProcessingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the context to a dictionary.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.create_processing","title":"<code>create_processing(client, name, type, default_cpu, default_gpu, default_parameters, docker_image, docker_tag, docker_flags=None)</code>","text":"<p>Create a processing configuration in Picsellia.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>ID of the created processing.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.get_processing","title":"<code>get_processing(client, name)</code>","text":"<p>Get the ID of a processing by name.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>ID of the found processing.</p>"},{"location":"api/core/contexts/processing/datalake/local_context/#picsellia_cv_engine.core.contexts.processing.datalake.local_context.launch_processing","title":"<code>launch_processing(client, datalake, data_ids, model_version_id, processing_id, parameters, cpu, gpu, target_datalake_name=None)</code>","text":"<p>Launch a processing job on a datalake.</p> <p>Returns:</p> Name Type Description <code>Job</code> <code>Job</code> <p>The launched job object.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/","title":"core.contexts.processing.datalake.picsellia_context","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context","title":"<code>picsellia_context</code>","text":"<p>Classes:</p> Name Description <code>PicselliaDatalakeProcessingContext</code> <p>Context for running Picsellia datalake processing jobs.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext","title":"<code>PicselliaDatalakeProcessingContext(processing_parameters_cls, api_token=None, host=None, organization_id=None, organization_name=None, job_id=None, use_id=True, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[TParameters]</code></p> <p>Context for running Picsellia datalake processing jobs.</p> <p>Manages job initialization, model version, input/output datalakes, and job parameters.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert the context to a dictionary representation.</p> <code>get_datalake</code> <p>Fetch a datalake by ID.</p> <code>get_model_version</code> <p>Fetch the model version by ID.</p> <code>get_data_ids</code> <p>Retrieve data IDs from the job payload.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>job</code> <code>job_type</code> <code>job_context</code> <code>input_datalake</code> <code>output_datalake</code> <code>model_version</code> <code>data_ids</code> <code>use_id</code> <code>processing_parameters</code> <code>working_dir</code> <code>str</code> <p>Return the working directory path for the job.</p> <code>model_version_id</code> <code>str | None</code> <p>Get the model version ID, validating presence if required.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.job_id","title":"<code>job_id = job_id or os.environ.get('job_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.job","title":"<code>job = self._initialize_job()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.job_type","title":"<code>job_type = self.job.sync()['type']</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.job_context","title":"<code>job_context = self._initialize_job_context()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.input_datalake","title":"<code>input_datalake = self.get_datalake(self._input_datalake_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.output_datalake","title":"<code>output_datalake = self.get_datalake(self._output_datalake_id) if self._output_datalake_id else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.model_version","title":"<code>model_version = self.get_model_version() if self._model_version_id else None</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.data_ids","title":"<code>data_ids = self.get_data_ids()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.processing_parameters","title":"<code>processing_parameters = processing_parameters_cls(log_data=(self.job_context['parameters']))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory path for the job.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.model_version_id","title":"<code>model_version_id</code>  <code>property</code>","text":"<p>Get the model version ID, validating presence if required.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the context to a dictionary representation.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.get_datalake","title":"<code>get_datalake(datalake_id)</code>","text":"<p>Fetch a datalake by ID.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.get_model_version","title":"<code>get_model_version()</code>","text":"<p>Fetch the model version by ID.</p>"},{"location":"api/core/contexts/processing/datalake/picsellia_context/#picsellia_cv_engine.core.contexts.processing.datalake.picsellia_context.PicselliaDatalakeProcessingContext.get_data_ids","title":"<code>get_data_ids()</code>","text":"<p>Retrieve data IDs from the job payload.</p>"},{"location":"api/core/contexts/processing/dataset/local_context/","title":"core.contexts.processing.dataset.local_context","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context","title":"<code>local_context</code>","text":"<p>Classes:</p> Name Description <code>LocalDatasetProcessingContext</code> <p>Local context for testing a processing pipeline without executing a real job on Picsellia.</p>"},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext","title":"<code>LocalDatasetProcessingContext(processing_parameters_cls, processing_parameters=None, api_token=None, host=None, organization_id=None, organization_name=None, job_id=None, job_type=None, input_dataset_version_id=None, output_dataset_version_id=None, output_dataset_version_name=None, use_id=True, download_annotations=True, model_version_id=None, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[TParameters]</code></p> <p>Local context for testing a processing pipeline without executing a real job on Picsellia.</p> <p>Can create or retrieve dataset versions and model versions as needed.</p> <p>Methods:</p> Name Description <code>get_dataset_version</code> <p>Fetch a dataset version by its ID.</p> <code>get_model_version</code> <p>Fetch a model version by its ID.</p> <code>to_dict</code> <p>Convert context to a dictionary for logging or serialization.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>job_type</code> <code>input_dataset_version_id</code> <code>output_dataset_version_id</code> <code>model_version_id</code> <code>input_dataset_version</code> <code>output_dataset_version</code> <code>model_version</code> <code>processing_parameters</code> <code>use_id</code> <code>download_annotations</code> <code>working_dir</code> <code>str</code> <p>Return the working directory for this job.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.job_id","title":"<code>job_id = job_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.job_type","title":"<code>job_type = job_type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.input_dataset_version_id","title":"<code>input_dataset_version_id = input_dataset_version_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.output_dataset_version_id","title":"<code>output_dataset_version_id = output_dataset_version_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.model_version_id","title":"<code>model_version_id = model_version_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.input_dataset_version","title":"<code>input_dataset_version = self.get_dataset_version(self.input_dataset_version_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.output_dataset_version","title":"<code>output_dataset_version = self.get_dataset_version(self.output_dataset_version_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.model_version","title":"<code>model_version = self.get_model_version()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.processing_parameters","title":"<code>processing_parameters = processing_parameters_cls(log_data=(processing_parameters or {}))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.download_annotations","title":"<code>download_annotations = download_annotations</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory for this job.</p>"},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.get_dataset_version","title":"<code>get_dataset_version(dataset_version_id)</code>","text":"<p>Fetch a dataset version by its ID.</p>"},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.get_model_version","title":"<code>get_model_version()</code>","text":"<p>Fetch a model version by its ID.</p>"},{"location":"api/core/contexts/processing/dataset/local_context/#picsellia_cv_engine.core.contexts.processing.dataset.local_context.LocalDatasetProcessingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert context to a dictionary for logging or serialization.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/","title":"core.contexts.processing.dataset.picsellia_context","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context","title":"<code>picsellia_context</code>","text":"<p>Classes:</p> Name Description <code>PicselliaDatasetProcessingContext</code> <p>Context for processing jobs in Picsellia using dataset versions and optional model version.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext","title":"<code>PicselliaDatasetProcessingContext(processing_parameters_cls, api_token=None, host=None, organization_id=None, organization_name=None, job_id=None, use_id=True, download_annotations=True, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[TParameters]</code></p> <p>Context for processing jobs in Picsellia using dataset versions and optional model version.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert the context to a dictionary representation.</p> <code>get_dataset_version</code> <p>Fetch a dataset version by its ID.</p> <code>get_model_version</code> <p>Fetch a model version by its ID.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>job</code> <code>job_type</code> <code>job_context</code> <code>input_dataset_version</code> <code>output_dataset_version</code> <code>model_version</code> <code>use_id</code> <code>download_annotations</code> <code>processing_parameters</code> <code>working_dir</code> <code>str</code> <p>Return the working directory path for the job.</p> <code>input_dataset_version_id</code> <code>str</code> <p>Return the input dataset version ID, or raise if missing.</p> <code>model_version_id</code> <code>str | None</code> <p>Return the model version ID, or raise if required and missing.</p> <code>output_dataset_version_id</code> <code>str | None</code> <p>Return the output dataset version ID, falling back to input if needed.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.job_id","title":"<code>job_id = job_id or os.environ.get('job_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.job","title":"<code>job = self._initialize_job()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.job_type","title":"<code>job_type = self.job.sync()['type']</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.job_context","title":"<code>job_context = self._initialize_job_context()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.input_dataset_version","title":"<code>input_dataset_version = self.get_dataset_version(self.input_dataset_version_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.output_dataset_version","title":"<code>output_dataset_version = self.get_dataset_version(self.output_dataset_version_id)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.model_version","title":"<code>model_version = self.get_model_version()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.download_annotations","title":"<code>download_annotations = download_annotations</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.processing_parameters","title":"<code>processing_parameters = processing_parameters_cls(log_data=(self.job_context['parameters']))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory path for the job.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.input_dataset_version_id","title":"<code>input_dataset_version_id</code>  <code>property</code>","text":"<p>Return the input dataset version ID, or raise if missing.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.model_version_id","title":"<code>model_version_id</code>  <code>property</code>","text":"<p>Return the model version ID, or raise if required and missing.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.output_dataset_version_id","title":"<code>output_dataset_version_id</code>  <code>property</code>","text":"<p>Return the output dataset version ID, falling back to input if needed.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the context to a dictionary representation.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.get_dataset_version","title":"<code>get_dataset_version(dataset_version_id)</code>","text":"<p>Fetch a dataset version by its ID.</p>"},{"location":"api/core/contexts/processing/dataset/picsellia_context/#picsellia_cv_engine.core.contexts.processing.dataset.picsellia_context.PicselliaDatasetProcessingContext.get_model_version","title":"<code>get_model_version()</code>","text":"<p>Fetch a model version by its ID.</p>"},{"location":"api/core/contexts/processing/model/local_context/","title":"core.contexts.processing.model.local_context","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context","title":"<code>local_context</code>","text":"<p>Classes:</p> Name Description <code>LocalModelProcessingContext</code>"},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext","title":"<code>LocalModelProcessingContext(processing_parameters_cls, processing_parameters=None, api_token=None, host=None, organization_id=None, organization_name=None, job_id=None, job_type=None, input_model_version_id=None, use_id=True, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[TParameters]</code></p> <p>Methods:</p> Name Description <code>get_model_version</code> <p>Fetch a model version by its ID.</p> <code>to_dict</code> <p>Convert context to a dictionary for logging or serialization.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>job_type</code> <code>model_version_id</code> <code>model_version</code> <code>processing_parameters</code> <code>use_id</code> <code>working_dir</code> <code>str</code> <p>Return the working directory for this job.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.job_id","title":"<code>job_id = job_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.job_type","title":"<code>job_type = job_type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.model_version_id","title":"<code>model_version_id = input_model_version_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.model_version","title":"<code>model_version = self.get_model_version()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.processing_parameters","title":"<code>processing_parameters = processing_parameters_cls(log_data=(processing_parameters or {}))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory for this job.</p>"},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.get_model_version","title":"<code>get_model_version()</code>","text":"<p>Fetch a model version by its ID.</p>"},{"location":"api/core/contexts/processing/model/local_context/#picsellia_cv_engine.core.contexts.processing.model.local_context.LocalModelProcessingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert context to a dictionary for logging or serialization.</p>"},{"location":"api/core/contexts/processing/model/picsellia_context/","title":"core.contexts.processing.model.picsellia_context","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context","title":"<code>picsellia_context</code>","text":"<p>Classes:</p> Name Description <code>PicselliaModelProcessingContext</code> <p>Context for model version processing jobs in Picsellia, including export logic.</p>"},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext","title":"<code>PicselliaModelProcessingContext(processing_parameters_cls, api_token=None, host=None, organization_id=None, organization_name=None, job_id=None, use_id=True, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[TParameters]</code></p> <p>Context for model version processing jobs in Picsellia, including export logic.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert context to a dictionary representation.</p> <code>get_model_version</code> <p>Fetch a model version by ID.</p> <p>Attributes:</p> Name Type Description <code>job_id</code> <code>job</code> <code>job_type</code> <code>job_context</code> <code>model_version</code> <code>use_id</code> <code>processing_parameters</code> <code>working_dir</code> <code>str</code> <p>Return the working directory path for the job.</p> <code>model_version_id</code> <code>str | None</code> <p>Return the model version ID, or raise if missing.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.job_id","title":"<code>job_id = job_id or os.environ.get('job_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.job","title":"<code>job = self._initialize_job()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.job_type","title":"<code>job_type = self.job.sync()['type']</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.job_context","title":"<code>job_context = self._initialize_job_context()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.model_version","title":"<code>model_version = self.get_model_version()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.processing_parameters","title":"<code>processing_parameters = processing_parameters_cls(log_data=(self.job_context['parameters']))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory path for the job.</p>"},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.model_version_id","title":"<code>model_version_id</code>  <code>property</code>","text":"<p>Return the model version ID, or raise if missing.</p>"},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert context to a dictionary representation.</p>"},{"location":"api/core/contexts/processing/model/picsellia_context/#picsellia_cv_engine.core.contexts.processing.model.picsellia_context.PicselliaModelProcessingContext.get_model_version","title":"<code>get_model_version()</code>","text":"<p>Fetch a model version by ID.</p>"},{"location":"api/core/contexts/training/local_context/","title":"core.contexts.training.local_context","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context","title":"<code>local_context</code>","text":"<p>Classes:</p> Name Description <code>LocalTrainingContext</code> <p>Local context for training pipelines without a real job on Picsellia.</p>"},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext","title":"<code>LocalTrainingContext(hyperparameters_cls, augmentation_parameters_cls, export_parameters_cls, hyperparameters=None, augmentation_parameters=None, export_parameters=None, api_token=None, host=None, organization_id=None, organization_name=None, experiment_id=None, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[THyperParameters, TAugmentationParameters]</code></p> <p>Local context for training pipelines without a real job on Picsellia.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert the context to a dictionary representation.</p> <p>Attributes:</p> Name Type Description <code>experiment_id</code> <code>experiment</code> <code>hyperparameters</code> <code>augmentation_parameters</code> <code>export_parameters</code> <code>working_dir</code> <code>str</code> <p>Return the working directory path for the experiment.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.experiment_id","title":"<code>experiment_id = experiment_id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.experiment","title":"<code>experiment = self._initialize_experiment()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.hyperparameters","title":"<code>hyperparameters = hyperparameters_cls(log_data=(hyperparameters or {}))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.augmentation_parameters","title":"<code>augmentation_parameters = augmentation_parameters_cls(log_data=(augmentation_parameters or {}))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.export_parameters","title":"<code>export_parameters = export_parameters_cls(log_data=(export_parameters or {}))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory path for the experiment.</p>"},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/local_context/#picsellia_cv_engine.core.contexts.training.local_context.LocalTrainingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the context to a dictionary representation.</p>"},{"location":"api/core/contexts/training/picsellia_context/","title":"core.contexts.training.picsellia_context","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context","title":"<code>picsellia_context</code>","text":"<p>Classes:</p> Name Description <code>PicselliaTrainingContext</code> <p>Context for training jobs in Picsellia, managing parameters and experiment metadata.</p>"},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext","title":"<code>PicselliaTrainingContext(hyperparameters_cls, augmentation_parameters_cls, export_parameters_cls, api_token=None, host=None, organization_id=None, organization_name=None, experiment_id=None, working_dir=None)</code>","text":"<p>               Bases: <code>PicselliaContext</code>, <code>Generic[THyperParameters, TAugmentationParameters, TExportParameters]</code></p> <p>Context for training jobs in Picsellia, managing parameters and experiment metadata.</p> <p>Methods:</p> Name Description <code>to_dict</code> <p>Convert the context to a dictionary representation.</p> <p>Attributes:</p> Name Type Description <code>experiment_id</code> <code>experiment</code> <code>hyperparameters</code> <code>augmentation_parameters</code> <code>export_parameters</code> <code>working_dir</code> <code>str</code> <p>Return the working directory path for the experiment.</p> <code>api_token</code> <code>host</code> <code>organization_id</code> <code>organization_name</code> <code>client</code>"},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.experiment_id","title":"<code>experiment_id = experiment_id or os.getenv('experiment_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.experiment","title":"<code>experiment = self._initialize_experiment()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.hyperparameters","title":"<code>hyperparameters = hyperparameters_cls(log_data=parameters_log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.augmentation_parameters","title":"<code>augmentation_parameters = augmentation_parameters_cls(log_data=parameters_log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.export_parameters","title":"<code>export_parameters = export_parameters_cls(log_data=parameters_log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.working_dir","title":"<code>working_dir</code>  <code>property</code>","text":"<p>Return the working directory path for the experiment.</p>"},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.api_token","title":"<code>api_token = api_token or os.getenv('api_token')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.host","title":"<code>host = host or os.getenv('host', 'https://app.picsellia.com')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.organization_id","title":"<code>organization_id = organization_id or os.getenv('organization_id')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.organization_name","title":"<code>organization_name = organization_name or os.getenv('organization_name')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.client","title":"<code>client = self._initialize_client()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/contexts/training/picsellia_context/#picsellia_cv_engine.core.contexts.training.picsellia_context.PicselliaTrainingContext.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert the context to a dictionary representation.</p>"},{"location":"api/core/data/datalake/datalake/","title":"core.data.datalake.datalake","text":""},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake","title":"<code>datalake</code>","text":"<p>Classes:</p> Name Description <code>Datalake</code> <p>Manages the context for downloading data from a Datalake.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake","title":"<code>Datalake(name, datalake, data_ids=None, use_id=True)</code>","text":"<p>Manages the context for downloading data from a Datalake.</p> <p>This class allows you to configure and initialize the necessary paths for downloading data from a Datalake to a specified destination path. It handles initializing the access paths and downloading the data based on the specified IDs.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the Datalake.</p> required <code>Datalake</code> <p>The Datalake instance from which data will be downloaded.</p> required <code>list[UUID] | None</code> <p>A list of data IDs to download, or None to download all data.</p> <code>None</code> <code>bool | None</code> <p>A flag indicating whether to use the IDs during data download. Default is True.</p> <code>True</code> <p>Methods:</p> Name Description <code>download_data</code> <p>Downloads data from the Datalake to the specified image directory.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the Datalake.</p> <code>datalake</code> <code>Datalake</code> <p>The Datalake instance from which data will be downloaded.</p> <code>data_ids</code> <code>list[UUID] | None</code> <p>A list of data IDs to download, or None to download all data.</p> <code>use_id</code> <code>bool | None</code> <p>A flag indicating whether to use the IDs during data download.</p> <code>images_dir</code> <code>str | None</code> <p>The directory where the downloaded images will be saved.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake(name)","title":"<code>name</code>","text":""},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake(datalake)","title":"<code>datalake</code>","text":""},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake(data_ids)","title":"<code>data_ids</code>","text":""},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the Datalake.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.datalake","title":"<code>datalake = datalake</code>  <code>instance-attribute</code>","text":"<p>The Datalake instance from which data will be downloaded.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.data_ids","title":"<code>data_ids = data_ids</code>  <code>instance-attribute</code>","text":"<p>A list of data IDs to download, or None to download all data.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.use_id","title":"<code>use_id = use_id</code>  <code>instance-attribute</code>","text":"<p>A flag indicating whether to use the IDs during data download.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.images_dir","title":"<code>images_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where the downloaded images will be saved.</p>"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.download_data","title":"<code>download_data(destination_dir)</code>","text":"<p>Downloads data from the Datalake to the specified image directory.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where the downloaded images will be saved.</p> required"},{"location":"api/core/data/datalake/datalake/#picsellia_cv_engine.core.data.datalake.datalake.Datalake.download_data(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/datalake/datalake_collection/","title":"core.data.datalake.datalake_collection","text":""},{"location":"api/core/data/datalake/datalake_collection/#picsellia_cv_engine.core.data.datalake.datalake_collection","title":"<code>datalake_collection</code>","text":"<p>Classes:</p> Name Description <code>DatalakeCollection</code>"},{"location":"api/core/data/datalake/datalake_collection/#picsellia_cv_engine.core.data.datalake.datalake_collection.DatalakeCollection","title":"<code>DatalakeCollection(input_datalake, output_datalake)</code>","text":"<p>Methods:</p> Name Description <code>download_all</code> <p>Attributes:</p> Name Type Description <code>input</code> <code>output</code>"},{"location":"api/core/data/datalake/datalake_collection/#picsellia_cv_engine.core.data.datalake.datalake_collection.DatalakeCollection.input","title":"<code>input = input_datalake</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/data/datalake/datalake_collection/#picsellia_cv_engine.core.data.datalake.datalake_collection.DatalakeCollection.output","title":"<code>output = output_datalake</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/data/datalake/datalake_collection/#picsellia_cv_engine.core.data.datalake.datalake_collection.DatalakeCollection.download_all","title":"<code>download_all(images_destination_dir)</code>","text":""},{"location":"api/core/data/dataset/base_dataset/","title":"core.data.dataset.base_dataset","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset","title":"<code>base_dataset</code>","text":"<p>Classes:</p> Name Description <code>BaseDataset</code> <p>A base class to manage the context of a dataset, including metadata, paths,</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset","title":"<code>BaseDataset(name, dataset_version, assets=None, labelmap=None)</code>","text":"<p>A base class to manage the context of a dataset, including metadata, paths, assets, and annotation management.</p> <p>This class provides methods to handle dataset assets and annotations, ensuring compatibility with the Picsellia SDK. Subclasses should implement the <code>download_annotations</code> method to manage annotation-specific logic.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the dataset.</p> required <code>DatasetVersion</code> <p>The version of the dataset as managed by Picsellia.</p> required <code>Optional[MultiAsset]</code> <p>A preloaded collection of assets. If not provided, assets will be listed dynamically as needed.</p> <code>None</code> <code>Optional[Dict[str, Label]]</code> <p>A preloaded mapping of labels. If not provided, the labelmap will be fetched from the <code>DatasetVersion</code>.</p> <code>None</code> <p>Methods:</p> Name Description <code>download_annotations</code> <p>Abstract method to download annotations for the dataset.</p> <code>download_assets</code> <p>Downloads all assets (e.g., images) associated with the dataset to the specified directory.</p> <code>get_assets_batch</code> <p>Retrieves a batch of assets from the dataset based on the specified limit and offset.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the dataset.</p> <code>dataset_version</code> <p>The version of the dataset from Picsellia.</p> <code>assets</code> <p>A preloaded collection of assets. If not provided, assets will be dynamically listed.</p> <code>labelmap</code> <code>images_dir</code> <code>str | None</code> <p>The local directory where image assets are downloaded.</p> <code>annotations_dir</code> <code>str | None</code> <p>The local directory where annotation files are stored.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset(name)","title":"<code>name</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset(dataset_version)","title":"<code>dataset_version</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset(assets)","title":"<code>assets</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the dataset.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.dataset_version","title":"<code>dataset_version = dataset_version</code>  <code>instance-attribute</code>","text":"<p>The version of the dataset from Picsellia.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.assets","title":"<code>assets = assets</code>  <code>instance-attribute</code>","text":"<p>A preloaded collection of assets. If not provided, assets will be dynamically listed.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.labelmap","title":"<code>labelmap = get_labelmap(dataset_version=dataset_version)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.images_dir","title":"<code>images_dir = None</code>  <code>instance-attribute</code>","text":"<p>The local directory where image assets are downloaded.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.annotations_dir","title":"<code>annotations_dir = None</code>  <code>instance-attribute</code>","text":"<p>The local directory where annotation files are stored.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_annotations","title":"<code>download_annotations(destination_dir, use_id=True)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to download annotations for the dataset.</p> <p>Subclasses must implement this method to define how annotations are retrieved and stored locally.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where the annotations will be saved locally.</p> required <code>Optional[bool]</code> <p>If True, uses asset IDs for file naming. Defaults to True.</p> <code>True</code>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_annotations(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_annotations(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_assets","title":"<code>download_assets(destination_dir, use_id=True, skip_asset_listing=False)</code>","text":"<p>Downloads all assets (e.g., images) associated with the dataset to the specified directory.</p> <p>This method retrieves and downloads all the assets linked to the dataset version. If assets are preloaded, they are directly downloaded; otherwise, the method dynamically lists and downloads them from the dataset version.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where assets will be saved locally.</p> required <code>Optional[bool]</code> <p>If True, uses asset IDs to generate file paths. Defaults to True.</p> <code>True</code> <code>Optional[bool]</code> <p>If True, skips listing assets after downloading. Defaults to False.</p> <code>False</code> Side Effects <ul> <li>Creates the <code>destination_path</code> directory if it doesn't already exist.</li> <li>Sets <code>self.images_dir</code> to the <code>destination_path</code>.</li> </ul>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_assets(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_assets(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.download_assets(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.get_assets_batch","title":"<code>get_assets_batch(limit, offset)</code>","text":"<p>Retrieves a batch of assets from the dataset based on the specified limit and offset.</p> <p>This method is useful for processing large datasets in smaller chunks.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The maximum number of assets to retrieve in the batch.</p> required <code>int</code> <p>The starting index for asset retrieval.</p> required <p>Returns:</p> Name Type Description <code>MultiAsset</code> <code>MultiAsset</code> <p>A collection of assets retrieved from the dataset.</p>"},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.get_assets_batch(limit)","title":"<code>limit</code>","text":""},{"location":"api/core/data/dataset/base_dataset/#picsellia_cv_engine.core.data.dataset.base_dataset.BaseDataset.get_assets_batch(offset)","title":"<code>offset</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/","title":"core.data.dataset.coco_dataset","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset","title":"<code>coco_dataset</code>","text":"<p>Classes:</p> Name Description <code>CocoDataset</code> <p>A specialized dataset for managing COCO annotations, enabling downloading, batching,</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset","title":"<code>CocoDataset(name, dataset_version, assets=None, labelmap=None)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>A specialized dataset for managing COCO annotations, enabling downloading, batching, and merging of annotation files.</p> <p>This class provides methods for downloading annotations in batches, merging them into a single COCO file, and loading the data for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the dataset.</p> required <code>DatasetVersion</code> <p>The version of the dataset to work with.</p> required <code>Optional[MultiAsset]</code> <p>Preloaded assets, if available.</p> <code>None</code> <code>Optional[Dict[str, Label]]</code> <p>Mapping of labels for the dataset.</p> <code>None</code> <p>Methods:</p> Name Description <code>download_annotations</code> <p>Download COCO annotations in batches, optionally merging them into a single file.</p> <code>load_coco_file_data</code> <p>Load COCO annotation data from the merged annotation file.</p> <code>download_assets</code> <p>Downloads all assets (e.g., images) associated with the dataset to the specified directory.</p> <code>get_assets_batch</code> <p>Retrieves a batch of assets from the dataset based on the specified limit and offset.</p> <p>Attributes:</p> Name Type Description <code>coco_file_path</code> <code>str | None</code> <p>The path to the merged COCO annotation file.</p> <code>coco_data</code> <code>dict[str, Any] | None</code> <p>The loaded COCO annotation data.</p> <code>name</code> <p>The name of the dataset.</p> <code>dataset_version</code> <p>The version of the dataset from Picsellia.</p> <code>assets</code> <p>A preloaded collection of assets. If not provided, assets will be dynamically listed.</p> <code>labelmap</code> <code>images_dir</code> <code>str | None</code> <p>The local directory where image assets are downloaded.</p> <code>annotations_dir</code> <code>str | None</code> <p>The local directory where annotation files are stored.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset(name)","title":"<code>name</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset(dataset_version)","title":"<code>dataset_version</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset(assets)","title":"<code>assets</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.coco_file_path","title":"<code>coco_file_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the merged COCO annotation file.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.coco_data","title":"<code>coco_data = None</code>  <code>instance-attribute</code>","text":"<p>The loaded COCO annotation data.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the dataset.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.dataset_version","title":"<code>dataset_version = dataset_version</code>  <code>instance-attribute</code>","text":"<p>The version of the dataset from Picsellia.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.assets","title":"<code>assets = assets</code>  <code>instance-attribute</code>","text":"<p>A preloaded collection of assets. If not provided, assets will be dynamically listed.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.labelmap","title":"<code>labelmap = get_labelmap(dataset_version=dataset_version)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.images_dir","title":"<code>images_dir = None</code>  <code>instance-attribute</code>","text":"<p>The local directory where image assets are downloaded.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.annotations_dir","title":"<code>annotations_dir = None</code>  <code>instance-attribute</code>","text":"<p>The local directory where annotation files are stored.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_annotations","title":"<code>download_annotations(destination_dir, use_id=True)</code>","text":"<p>Download COCO annotations in batches, optionally merging them into a single file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Directory to save the COCO annotation files.</p> required <code>Optional[bool]</code> <p>Whether to use asset IDs in file paths (default: True).</p> <code>True</code>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_annotations(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_annotations(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.load_coco_file_data","title":"<code>load_coco_file_data()</code>","text":"<p>Load COCO annotation data from the merged annotation file.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: The COCO data loaded as a dictionary.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_assets","title":"<code>download_assets(destination_dir, use_id=True, skip_asset_listing=False)</code>","text":"<p>Downloads all assets (e.g., images) associated with the dataset to the specified directory.</p> <p>This method retrieves and downloads all the assets linked to the dataset version. If assets are preloaded, they are directly downloaded; otherwise, the method dynamically lists and downloads them from the dataset version.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where assets will be saved locally.</p> required <code>Optional[bool]</code> <p>If True, uses asset IDs to generate file paths. Defaults to True.</p> <code>True</code> <code>Optional[bool]</code> <p>If True, skips listing assets after downloading. Defaults to False.</p> <code>False</code> Side Effects <ul> <li>Creates the <code>destination_path</code> directory if it doesn't already exist.</li> <li>Sets <code>self.images_dir</code> to the <code>destination_path</code>.</li> </ul>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_assets(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_assets(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.download_assets(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.get_assets_batch","title":"<code>get_assets_batch(limit, offset)</code>","text":"<p>Retrieves a batch of assets from the dataset based on the specified limit and offset.</p> <p>This method is useful for processing large datasets in smaller chunks.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The maximum number of assets to retrieve in the batch.</p> required <code>int</code> <p>The starting index for asset retrieval.</p> required <p>Returns:</p> Name Type Description <code>MultiAsset</code> <code>MultiAsset</code> <p>A collection of assets retrieved from the dataset.</p>"},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.get_assets_batch(limit)","title":"<code>limit</code>","text":""},{"location":"api/core/data/dataset/coco_dataset/#picsellia_cv_engine.core.data.dataset.coco_dataset.CocoDataset.get_assets_batch(offset)","title":"<code>offset</code>","text":""},{"location":"api/core/data/dataset/dataset_collection/","title":"core.data.dataset.dataset_collection","text":""},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection","title":"<code>dataset_collection</code>","text":"<p>Classes:</p> Name Description <code>DatasetCollection</code> <p>A collection of datasets for different splits of a dataset.</p>"},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection","title":"<code>DatasetCollection(datasets)</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TBaseDataset]</code></p> <p>A collection of datasets for different splits of a dataset.</p> <p>This class aggregates datasets for the common splits used in machine learning projects: training, validation, and testing. It provides a convenient way to access and manipulate these datasets as a unified object. The class supports direct access to individual dataset contexts, iteration over all contexts, and collective operations on all contexts, such as downloading assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[TDataset]</code> <p>A list of datasets for different splits (train, val, test).</p> required <p>Methods:</p> Name Description <code>download_all</code> <p>Downloads all assets and annotations for every dataset in the collection.</p> <p>Attributes:</p> Name Type Description <code>datasets</code> <p>A dictionary of datasets, indexed by their names.</p> <code>dataset_path</code> <code>str | None</code> <p>The path to the dataset directory.</p>"},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection(datasets)","title":"<code>datasets</code>","text":""},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.datasets","title":"<code>datasets = {(dataset.name): datasetfor dataset in datasets}</code>  <code>instance-attribute</code>","text":"<p>A dictionary of datasets, indexed by their names.</p>"},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.dataset_path","title":"<code>dataset_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the dataset directory.</p>"},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.download_all","title":"<code>download_all(images_destination_dir, annotations_destination_dir, use_id=True, skip_asset_listing=False)</code>","text":"<p>Downloads all assets and annotations for every dataset in the collection.</p> <p>For each dataset, this method: 1. Downloads the assets (images) to the corresponding image directory. 2. Downloads and builds the COCO annotation file for each dataset.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where images will be saved.</p> required <code>str</code> <p>The directory where annotations will be saved.</p> required <code>Optional[bool]</code> <p>Whether to use asset IDs in the file paths. If None, the internal logic of each dataset will handle it.</p> <code>True</code> <code>bool</code> <p>If True, skips listing the assets when downloading. Defaults to False.</p> <code>False</code> Example <p>If you want to download assets and annotations for both train and validation datasets, this method will create two directories (e.g., <code>train/images</code>, <code>train/annotations</code>, <code>val/images</code>, <code>val/annotations</code>) under the specified <code>destination_path</code>.</p>"},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.download_all(images_destination_dir)","title":"<code>images_destination_dir</code>","text":""},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.download_all(annotations_destination_dir)","title":"<code>annotations_destination_dir</code>","text":""},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.download_all(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/dataset_collection/#picsellia_cv_engine.core.data.dataset.dataset_collection.DatasetCollection.download_all(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/core/data/dataset/utils/","title":"core.data.dataset.utils","text":""},{"location":"api/core/data/dataset/utils/#picsellia_cv_engine.core.data.dataset.utils","title":"<code>utils</code>","text":"<p>Functions:</p> Name Description <code>remove_empty_directories</code> <p>Recursively remove empty directories from a given directory.</p>"},{"location":"api/core/data/dataset/utils/#picsellia_cv_engine.core.data.dataset.utils.remove_empty_directories","title":"<code>remove_empty_directories(directory)</code>","text":"<p>Recursively remove empty directories from a given directory.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The root directory to clean.</p> required"},{"location":"api/core/data/dataset/utils/#picsellia_cv_engine.core.data.dataset.utils.remove_empty_directories(directory)","title":"<code>directory</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/","title":"core.data.dataset.yolo_dataset","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset","title":"<code>yolo_dataset</code>","text":"<p>Classes:</p> Name Description <code>YoloDataset</code> <p>A specialized dataset for handling YOLO-formatted annotations.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset","title":"<code>YoloDataset(name, dataset_version, assets=None, labelmap=None)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> <p>A specialized dataset for handling YOLO-formatted annotations.</p> <p>This class provides methods to download, process, and unzip YOLO annotations in batches, making it easier to handle large datasets for object detection tasks.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the dataset.</p> required <code>DatasetVersion</code> <p>The version of the dataset to work with.</p> required <code>Optional[MultiAsset]</code> <p>Preloaded assets, if available.</p> <code>None</code> <code>Optional[Dict[str, Label]]</code> <p>Mapping of labels for the dataset.</p> <code>None</code> <p>Methods:</p> Name Description <code>download_annotations</code> <p>Downloads YOLO annotations for the dataset in batches.</p> <code>unzip</code> <p>Extracts the contents of a ZIP file into the specified destination directory.</p> <code>download_assets</code> <p>Downloads all assets (e.g., images) associated with the dataset to the specified directory.</p> <code>get_assets_batch</code> <p>Retrieves a batch of assets from the dataset based on the specified limit and offset.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the dataset.</p> <code>dataset_version</code> <p>The version of the dataset from Picsellia.</p> <code>assets</code> <p>A preloaded collection of assets. If not provided, assets will be dynamically listed.</p> <code>labelmap</code> <code>images_dir</code> <code>str | None</code> <p>The local directory where image assets are downloaded.</p> <code>annotations_dir</code> <code>str | None</code> <p>The local directory where annotation files are stored.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset(name)","title":"<code>name</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset(dataset_version)","title":"<code>dataset_version</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset(assets)","title":"<code>assets</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the dataset.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.dataset_version","title":"<code>dataset_version = dataset_version</code>  <code>instance-attribute</code>","text":"<p>The version of the dataset from Picsellia.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.assets","title":"<code>assets = assets</code>  <code>instance-attribute</code>","text":"<p>A preloaded collection of assets. If not provided, assets will be dynamically listed.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.labelmap","title":"<code>labelmap = get_labelmap(dataset_version=dataset_version)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.images_dir","title":"<code>images_dir = None</code>  <code>instance-attribute</code>","text":"<p>The local directory where image assets are downloaded.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.annotations_dir","title":"<code>annotations_dir = None</code>  <code>instance-attribute</code>","text":"<p>The local directory where annotation files are stored.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_annotations","title":"<code>download_annotations(destination_dir, use_id=True)</code>","text":"<p>Downloads YOLO annotations for the dataset in batches.</p> <p>This method retrieves YOLO annotation files in batches, unzips them, and saves the contents to the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where annotations will be saved.</p> required <code>Optional[bool]</code> <p>Whether to use asset IDs in file paths (default: True).</p> <code>True</code>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_annotations(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_annotations(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.unzip","title":"<code>unzip(zip_path, destination_path)</code>","text":"<p>Extracts the contents of a ZIP file into the specified destination directory.</p> <p>This method removes the original ZIP file after extraction and cleans up any empty directories.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The full path to the ZIP file.</p> required <code>str</code> <p>The directory where the contents will be extracted.</p> required"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.unzip(zip_path)","title":"<code>zip_path</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.unzip(destination_path)","title":"<code>destination_path</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_assets","title":"<code>download_assets(destination_dir, use_id=True, skip_asset_listing=False)</code>","text":"<p>Downloads all assets (e.g., images) associated with the dataset to the specified directory.</p> <p>This method retrieves and downloads all the assets linked to the dataset version. If assets are preloaded, they are directly downloaded; otherwise, the method dynamically lists and downloads them from the dataset version.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory where assets will be saved locally.</p> required <code>Optional[bool]</code> <p>If True, uses asset IDs to generate file paths. Defaults to True.</p> <code>True</code> <code>Optional[bool]</code> <p>If True, skips listing assets after downloading. Defaults to False.</p> <code>False</code> Side Effects <ul> <li>Creates the <code>destination_path</code> directory if it doesn't already exist.</li> <li>Sets <code>self.images_dir</code> to the <code>destination_path</code>.</li> </ul>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_assets(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_assets(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.download_assets(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.get_assets_batch","title":"<code>get_assets_batch(limit, offset)</code>","text":"<p>Retrieves a batch of assets from the dataset based on the specified limit and offset.</p> <p>This method is useful for processing large datasets in smaller chunks.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The maximum number of assets to retrieve in the batch.</p> required <code>int</code> <p>The starting index for asset retrieval.</p> required <p>Returns:</p> Name Type Description <code>MultiAsset</code> <code>MultiAsset</code> <p>A collection of assets retrieved from the dataset.</p>"},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.get_assets_batch(limit)","title":"<code>limit</code>","text":""},{"location":"api/core/data/dataset/yolo_dataset/#picsellia_cv_engine.core.data.dataset.yolo_dataset.YoloDataset.get_assets_batch(offset)","title":"<code>offset</code>","text":""},{"location":"api/core/models/model/","title":"core.models.model","text":""},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model","title":"<code>model</code>","text":"<p>Classes:</p> Name Description <code>Model</code> <p>Represents a model version and manages its associated files and runtime instance.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model","title":"<code>Model(name, model_version=None, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None, labelmap=None)</code>","text":"<p>Represents a model version and manages its associated files and runtime instance.</p> <p>Methods:</p> Name Description <code>set_loaded_model</code> <p>Set the runtime-loaded model instance.</p> <code>download_weights</code> <p>Download all configured model files (weights, config, exports) to destination.</p> <code>save_artifact_to_experiment</code> <p>Store an artifact file in the given experiment.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the model.</p> <code>model_version</code> <p>The version of the model from Picsellia.</p> <code>pretrained_weights_name</code> <p>The name of the pretrained weights file attached to the model version in Picsellia.</p> <code>trained_weights_name</code> <p>The name of the trained weights file attached to the model version in Picsellia.</p> <code>config_name</code> <p>The name of the configuration file attached to the model version in Picsellia.</p> <code>exported_weights_name</code> <p>The name of the exported weights file attached to the model version in Picsellia.</p> <code>labelmap</code> <p>A dictionary mapping category names to labels.</p> <code>weights_dir</code> <code>str | None</code> <p>The directory where model weights are stored.</p> <code>results_dir</code> <code>str | None</code> <p>The directory where model results are stored.</p> <code>pretrained_weights_dir</code> <code>str | None</code> <p>The directory where pretrained weights are stored.</p> <code>trained_weights_dir</code> <code>str | None</code> <p>The directory where trained weights are stored.</p> <code>config_dir</code> <code>str | None</code> <p>The directory where model configuration files are stored.</p> <code>exported_weights_dir</code> <code>str | None</code> <p>The directory where exported weights are stored.</p> <code>pretrained_weights_path</code> <code>str | None</code> <p>The path to the pretrained weights file.</p> <code>trained_weights_path</code> <code>str | None</code> <p>The path to the trained weights file.</p> <code>config_path</code> <code>str | None</code> <p>The path to the model configuration file.</p> <code>exported_weights_path</code> <code>str | None</code> <p>The path to the exported weights file.</p> <code>loaded_model</code> <code>Any</code> <p>Return the loaded model instance.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the model.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.model_version","title":"<code>model_version = model_version</code>  <code>instance-attribute</code>","text":"<p>The version of the model from Picsellia.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.pretrained_weights_name","title":"<code>pretrained_weights_name = pretrained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the pretrained weights file attached to the model version in Picsellia.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.trained_weights_name","title":"<code>trained_weights_name = trained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the trained weights file attached to the model version in Picsellia.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.config_name","title":"<code>config_name = config_name</code>  <code>instance-attribute</code>","text":"<p>The name of the configuration file attached to the model version in Picsellia.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.exported_weights_name","title":"<code>exported_weights_name = exported_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the exported weights file attached to the model version in Picsellia.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.labelmap","title":"<code>labelmap = labelmap or {}</code>  <code>instance-attribute</code>","text":"<p>A dictionary mapping category names to labels.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.weights_dir","title":"<code>weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model weights are stored.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.results_dir","title":"<code>results_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model results are stored.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.pretrained_weights_dir","title":"<code>pretrained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where pretrained weights are stored.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.trained_weights_dir","title":"<code>trained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where trained weights are stored.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.config_dir","title":"<code>config_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model configuration files are stored.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.exported_weights_dir","title":"<code>exported_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where exported weights are stored.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.pretrained_weights_path","title":"<code>pretrained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the pretrained weights file.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.trained_weights_path","title":"<code>trained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the trained weights file.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.config_path","title":"<code>config_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the model configuration file.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.exported_weights_path","title":"<code>exported_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the exported weights file.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.loaded_model","title":"<code>loaded_model</code>  <code>property</code>","text":"<p>Return the loaded model instance.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.set_loaded_model","title":"<code>set_loaded_model(model)</code>","text":"<p>Set the runtime-loaded model instance.</p>"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.download_weights","title":"<code>download_weights(destination_dir)</code>","text":"<p>Download all configured model files (weights, config, exports) to destination.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Root directory for downloaded files.</p> required"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.download_weights(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.save_artifact_to_experiment","title":"<code>save_artifact_to_experiment(experiment, artifact_name, artifact_path)</code>","text":"<p>Store an artifact file in the given experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Experiment to store into.</p> required <code>str</code> <p>Name under which to save the artifact.</p> required <code>str</code> <p>Path to the file.</p> required"},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.save_artifact_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.save_artifact_to_experiment(artifact_name)","title":"<code>artifact_name</code>","text":""},{"location":"api/core/models/model/#picsellia_cv_engine.core.models.model.Model.save_artifact_to_experiment(artifact_path)","title":"<code>artifact_path</code>","text":""},{"location":"api/core/models/model_collection/","title":"core.models.model_collection","text":""},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection","title":"<code>model_collection</code>","text":"<p>Classes:</p> Name Description <code>ModelCollection</code> <p>A collection for managing multiple models, with one active loaded model at a time.</p>"},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection","title":"<code>ModelCollection(models)</code>","text":"<p>               Bases: <code>Generic[TModel]</code></p> <p>A collection for managing multiple models, with one active loaded model at a time.</p> <p>Provides access to individual models by name, and supports downloading weights for all models in the collection.</p> <p>Parameters:</p> Name Type Description Default <code>list[TModel]</code> <p>List of model instances.</p> required <p>Methods:</p> Name Description <code>set_loaded_model</code> <p>Set the loaded model for this collection.</p> <code>download_weights</code> <p>Download weights for all models to subdirectories by model name.</p> <p>Attributes:</p> Name Type Description <code>models</code> <code>loaded_model</code> <code>Any</code> <p>Return the currently loaded model.</p>"},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection(models)","title":"<code>models</code>","text":""},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection.models","title":"<code>models = {(model.name): modelfor model in models}</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection.loaded_model","title":"<code>loaded_model</code>  <code>property</code>","text":"<p>Return the currently loaded model.</p>"},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection.set_loaded_model","title":"<code>set_loaded_model(model)</code>","text":"<p>Set the loaded model for this collection.</p>"},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection.download_weights","title":"<code>download_weights(destination_dir)</code>","text":"<p>Download weights for all models to subdirectories by model name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Base directory where weights will be saved.</p> required"},{"location":"api/core/models/model_collection/#picsellia_cv_engine.core.models.model_collection.ModelCollection.download_weights(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/models/model_downloader/","title":"core.models.model_downloader","text":""},{"location":"api/core/models/model_downloader/#picsellia_cv_engine.core.models.model_downloader","title":"<code>model_downloader</code>","text":"<p>Classes:</p> Name Description <code>ModelDownloader</code> <p>Handles downloading and optional extraction of model files.</p>"},{"location":"api/core/models/model_downloader/#picsellia_cv_engine.core.models.model_downloader.ModelDownloader","title":"<code>ModelDownloader</code>","text":"<p>Handles downloading and optional extraction of model files.</p> <p>Methods:</p> Name Description <code>download_and_process</code> <p>Download a model file and extract it if compressed.</p>"},{"location":"api/core/models/model_downloader/#picsellia_cv_engine.core.models.model_downloader.ModelDownloader.download_and_process","title":"<code>download_and_process(model_file, destination_path)</code>","text":"<p>Download a model file and extract it if compressed.</p> <p>Parameters:</p> Name Type Description Default <code>ModelFile</code> <p>The file to download.</p> required <code>str</code> <p>Target directory for the downloaded file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the extracted or raw file.</p>"},{"location":"api/core/models/model_downloader/#picsellia_cv_engine.core.models.model_downloader.ModelDownloader.download_and_process(model_file)","title":"<code>model_file</code>","text":""},{"location":"api/core/models/model_downloader/#picsellia_cv_engine.core.models.model_downloader.ModelDownloader.download_and_process(destination_path)","title":"<code>destination_path</code>","text":""},{"location":"api/core/models/picsellia_prediction/","title":"core.models.picsellia_prediction","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction","title":"<code>picsellia_prediction</code>","text":"<p>Classes:</p> Name Description <code>PicselliaLabel</code> <p>Label associated with a prediction.</p> <code>PicselliaConfidence</code> <p>Confidence score for a prediction (typically between 0 and 1).</p> <code>PicselliaRectangle</code> <p>Bounding box in [x, y, width, height] format.</p> <code>PicselliaText</code> <p>Recognized text from OCR predictions.</p> <code>PicselliaPolygon</code> <p>Polygon represented by a list of points.</p> <code>PicselliaClassificationPrediction</code> <p>Prediction result for classification tasks.</p> <code>PicselliaRectanglePrediction</code> <p>Prediction result for object detection (rectangles).</p> <code>PicselliaOCRPrediction</code> <p>Prediction result for OCR tasks.</p> <code>PicselliaPolygonPrediction</code> <p>Prediction result for segmentation tasks.</p>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaLabel","title":"<code>PicselliaLabel(value)</code>  <code>dataclass</code>","text":"<p>Label associated with a prediction.</p> <p>Attributes:</p> Name Type Description <code>value</code> <code>Label</code> <code>name</code> <code>str</code> <code>id</code> <code>int</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaLabel.value","title":"<code>value</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaLabel.name","title":"<code>name</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaLabel.id","title":"<code>id</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaConfidence","title":"<code>PicselliaConfidence(value)</code>  <code>dataclass</code>","text":"<p>Confidence score for a prediction (typically between 0 and 1).</p> <p>Attributes:</p> Name Type Description <code>value</code> <code>float</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaConfidence.value","title":"<code>value</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectangle","title":"<code>PicselliaRectangle(x, y, w, h)</code>  <code>dataclass</code>","text":"<p>Bounding box in [x, y, width, height] format.</p> <p>Attributes:</p> Name Type Description <code>value</code> <code>list[int]</code> <code>x</code> <code>int</code> <code>y</code> <code>int</code> <code>width</code> <code>int</code> <code>height</code> <code>int</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectangle.value","title":"<code>value = [int(x), int(y), int(w), int(h)]</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectangle.x","title":"<code>x</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectangle.y","title":"<code>y</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectangle.width","title":"<code>width</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectangle.height","title":"<code>height</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaText","title":"<code>PicselliaText(value)</code>  <code>dataclass</code>","text":"<p>Recognized text from OCR predictions.</p> <p>Attributes:</p> Name Type Description <code>value</code> <code>str</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaText.value","title":"<code>value</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygon","title":"<code>PicselliaPolygon(points)</code>  <code>dataclass</code>","text":"<p>Polygon represented by a list of points.</p> <p>Methods:</p> Name Description <code>compute_area</code> <p>Attributes:</p> Name Type Description <code>value</code> <code>list[list[int]]</code> <code>points</code> <code>list[list[int]]</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygon.value","title":"<code>value = points</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygon.points","title":"<code>points</code>  <code>property</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygon.compute_area","title":"<code>compute_area()</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaClassificationPrediction","title":"<code>PicselliaClassificationPrediction(asset, label, confidence)</code>  <code>dataclass</code>","text":"<p>Prediction result for classification tasks.</p> <p>Attributes:</p> Name Type Description <code>asset</code> <code>Asset</code> <code>label</code> <code>PicselliaLabel</code> <code>confidence</code> <code>PicselliaConfidence</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaClassificationPrediction.asset","title":"<code>asset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaClassificationPrediction.label","title":"<code>label</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaClassificationPrediction.confidence","title":"<code>confidence</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectanglePrediction","title":"<code>PicselliaRectanglePrediction(asset, boxes, labels, confidences)</code>  <code>dataclass</code>","text":"<p>Prediction result for object detection (rectangles).</p> <p>Attributes:</p> Name Type Description <code>asset</code> <code>Asset</code> <code>boxes</code> <code>list[PicselliaRectangle]</code> <code>labels</code> <code>list[PicselliaLabel]</code> <code>confidences</code> <code>list[PicselliaConfidence]</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectanglePrediction.asset","title":"<code>asset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectanglePrediction.boxes","title":"<code>boxes</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectanglePrediction.labels","title":"<code>labels</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaRectanglePrediction.confidences","title":"<code>confidences</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaOCRPrediction","title":"<code>PicselliaOCRPrediction(asset, boxes, labels, texts, confidences)</code>  <code>dataclass</code>","text":"<p>Prediction result for OCR tasks.</p> <p>Attributes:</p> Name Type Description <code>asset</code> <code>Asset</code> <code>boxes</code> <code>list[PicselliaRectangle]</code> <code>labels</code> <code>list[PicselliaLabel]</code> <code>texts</code> <code>list[PicselliaText]</code> <code>confidences</code> <code>list[PicselliaConfidence]</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaOCRPrediction.asset","title":"<code>asset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaOCRPrediction.boxes","title":"<code>boxes</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaOCRPrediction.labels","title":"<code>labels</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaOCRPrediction.texts","title":"<code>texts</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaOCRPrediction.confidences","title":"<code>confidences</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygonPrediction","title":"<code>PicselliaPolygonPrediction(asset, polygons, labels, confidences)</code>  <code>dataclass</code>","text":"<p>Prediction result for segmentation tasks.</p> <p>Attributes:</p> Name Type Description <code>asset</code> <code>Asset</code> <code>polygons</code> <code>list[PicselliaPolygon]</code> <code>labels</code> <code>list[PicselliaLabel]</code> <code>confidences</code> <code>list[PicselliaConfidence]</code>"},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygonPrediction.asset","title":"<code>asset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygonPrediction.polygons","title":"<code>polygons</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygonPrediction.labels","title":"<code>labels</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/models/picsellia_prediction/#picsellia_cv_engine.core.models.picsellia_prediction.PicselliaPolygonPrediction.confidences","title":"<code>confidences</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/","title":"core.parameters.augmentation_parameters","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters","title":"<code>augmentation_parameters</code>","text":"<p>Classes:</p> Name Description <code>AugmentationParameters</code>"},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters","title":"<code>AugmentationParameters(log_data)</code>","text":"<p>               Bases: <code>Parameters</code></p> <p>Methods:</p> Name Description <code>extract_parameter</code> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <code>to_dict</code> <p>Return parameters as a dictionary, excluding internal fields.</p> <code>validate_log_data</code> <p>Validate and return log data if it's a dictionary.</p> <p>Attributes:</p> Name Type Description <code>parameters_data</code> <code>defaulted_keys</code> <code>set[str]</code>"},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.parameters_data","title":"<code>parameters_data = self.validate_log_data(log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.defaulted_keys","title":"<code>defaulted_keys = set()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.extract_parameter","title":"<code>extract_parameter(keys, expected_type, default=..., range_value=None)</code>","text":"<pre><code>extract_parameter(keys: list, expected_type: type[T], default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; T\n</code></pre><pre><code>extract_parameter(keys: list, expected_type: Any, default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; Any\n</code></pre> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <p>Examples:</p> <p>Extract a required string parameter that cannot be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\", \"key2\"], expected_type=str)\n</code></pre></p> <p>Extract a required integer parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=int | None)\n</code></pre></p> <p>Extract an optional float parameter within a specific range: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=float, default=0.5, range_value=(0.0, 1.0))\n</code></pre></p> <p>Extract an optional string parameter with a default value: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=str, default=\"default_value\")\n</code></pre></p> <p>Extract an optional string parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=Union[str, None], default=None)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>A list of possible keys to extract the parameter.</p> required <code>type[T]</code> <p>The expected type of the parameter, can use Union for optional types.</p> required <code>Any</code> <p>The default value if the parameter is not found. Use ... for required parameters.</p> <code>...</code> <code>tuple[Any, Any] | None</code> <p>A tuple of two numbers representing the allowed range of the parameter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed parameter.</p>"},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.extract_parameter(keys)","title":"<code>keys</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.extract_parameter(expected_type)","title":"<code>expected_type</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.extract_parameter(default)","title":"<code>default</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.extract_parameter(range_value)","title":"<code>range_value</code>","text":""},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.to_dict","title":"<code>to_dict()</code>","text":"<p>Return parameters as a dictionary, excluding internal fields.</p>"},{"location":"api/core/parameters/augmentation_parameters/#picsellia_cv_engine.core.parameters.augmentation_parameters.AugmentationParameters.validate_log_data","title":"<code>validate_log_data(log_data)</code>","text":"<p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/core/parameters/base_parameters/","title":"core.parameters.base_parameters","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters","title":"<code>base_parameters</code>","text":"<p>Classes:</p> Name Description <code>Parameters</code> <p>Base class for handling typed parameter extraction from Picsellia log data.</p>"},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters","title":"<code>Parameters(log_data)</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>Base class for handling typed parameter extraction from Picsellia log data.</p> <p>Parameters:</p> Name Type Description Default <code>LogDataType</code> <p>Dictionary of parameters extracted from Picsellia logs.</p> required <p>Methods:</p> Name Description <code>extract_parameter</code> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <code>to_dict</code> <p>Return parameters as a dictionary, excluding internal fields.</p> <code>validate_log_data</code> <p>Validate and return log data if it's a dictionary.</p> <p>Attributes:</p> Name Type Description <code>parameters_data</code> <code>defaulted_keys</code> <code>set[str]</code>"},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters(log_data)","title":"<code>log_data</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.parameters_data","title":"<code>parameters_data = self.validate_log_data(log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.defaulted_keys","title":"<code>defaulted_keys = set()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.extract_parameter","title":"<code>extract_parameter(keys, expected_type, default=..., range_value=None)</code>","text":"<pre><code>extract_parameter(keys: list, expected_type: type[T], default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; T\n</code></pre><pre><code>extract_parameter(keys: list, expected_type: Any, default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; Any\n</code></pre> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <p>Examples:</p> <p>Extract a required string parameter that cannot be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\", \"key2\"], expected_type=str)\n</code></pre></p> <p>Extract a required integer parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=int | None)\n</code></pre></p> <p>Extract an optional float parameter within a specific range: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=float, default=0.5, range_value=(0.0, 1.0))\n</code></pre></p> <p>Extract an optional string parameter with a default value: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=str, default=\"default_value\")\n</code></pre></p> <p>Extract an optional string parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=Union[str, None], default=None)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>A list of possible keys to extract the parameter.</p> required <code>type[T]</code> <p>The expected type of the parameter, can use Union for optional types.</p> required <code>Any</code> <p>The default value if the parameter is not found. Use ... for required parameters.</p> <code>...</code> <code>tuple[Any, Any] | None</code> <p>A tuple of two numbers representing the allowed range of the parameter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed parameter.</p>"},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.extract_parameter(keys)","title":"<code>keys</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.extract_parameter(expected_type)","title":"<code>expected_type</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.extract_parameter(default)","title":"<code>default</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.extract_parameter(range_value)","title":"<code>range_value</code>","text":""},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.to_dict","title":"<code>to_dict()</code>","text":"<p>Return parameters as a dictionary, excluding internal fields.</p>"},{"location":"api/core/parameters/base_parameters/#picsellia_cv_engine.core.parameters.base_parameters.Parameters.validate_log_data","title":"<code>validate_log_data(log_data)</code>","text":"<p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/core/parameters/export_parameters/","title":"core.parameters.export_parameters","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters","title":"<code>export_parameters</code>","text":"<p>Classes:</p> Name Description <code>ExportParameters</code> <p>Handles the export parameters for models exportation processes.</p>"},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters","title":"<code>ExportParameters(log_data)</code>","text":"<p>               Bases: <code>Parameters</code></p> <p>Handles the export parameters for models exportation processes.</p> <p>Inherits from the base <code>Parameters</code> class and is responsible for extracting and managing the format in which the models will be exported, such as ONNX or other supported formats.</p> <p>Attributes:</p> Name Type Description <code>export_format</code> <code>str</code> <p>The format in which the models will be exported. Defaults to 'onnx'.</p> <p>Parameters:</p> Name Type Description Default <code>LogDataType</code> <p>The log data schema that contains the parameters for export.</p> required <p>Methods:</p> Name Description <code>extract_parameter</code> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <code>to_dict</code> <p>Return parameters as a dictionary, excluding internal fields.</p> <code>validate_log_data</code> <p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters(log_data)","title":"<code>log_data</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.export_format","title":"<code>export_format = self.extract_parameter(keys=['export_format'], expected_type=str, default='onnx')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.parameters_data","title":"<code>parameters_data = self.validate_log_data(log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.defaulted_keys","title":"<code>defaulted_keys = set()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.extract_parameter","title":"<code>extract_parameter(keys, expected_type, default=..., range_value=None)</code>","text":"<pre><code>extract_parameter(keys: list, expected_type: type[T], default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; T\n</code></pre><pre><code>extract_parameter(keys: list, expected_type: Any, default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; Any\n</code></pre> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <p>Examples:</p> <p>Extract a required string parameter that cannot be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\", \"key2\"], expected_type=str)\n</code></pre></p> <p>Extract a required integer parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=int | None)\n</code></pre></p> <p>Extract an optional float parameter within a specific range: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=float, default=0.5, range_value=(0.0, 1.0))\n</code></pre></p> <p>Extract an optional string parameter with a default value: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=str, default=\"default_value\")\n</code></pre></p> <p>Extract an optional string parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=Union[str, None], default=None)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>A list of possible keys to extract the parameter.</p> required <code>type[T]</code> <p>The expected type of the parameter, can use Union for optional types.</p> required <code>Any</code> <p>The default value if the parameter is not found. Use ... for required parameters.</p> <code>...</code> <code>tuple[Any, Any] | None</code> <p>A tuple of two numbers representing the allowed range of the parameter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed parameter.</p>"},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.extract_parameter(keys)","title":"<code>keys</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.extract_parameter(expected_type)","title":"<code>expected_type</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.extract_parameter(default)","title":"<code>default</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.extract_parameter(range_value)","title":"<code>range_value</code>","text":""},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.to_dict","title":"<code>to_dict()</code>","text":"<p>Return parameters as a dictionary, excluding internal fields.</p>"},{"location":"api/core/parameters/export_parameters/#picsellia_cv_engine.core.parameters.export_parameters.ExportParameters.validate_log_data","title":"<code>validate_log_data(log_data)</code>","text":"<p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/core/parameters/hyper_parameters/","title":"core.parameters.hyper_parameters","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters","title":"<code>hyper_parameters</code>","text":"<p>Classes:</p> Name Description <code>HyperParameters</code>"},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters","title":"<code>HyperParameters(log_data)</code>","text":"<p>               Bases: <code>Parameters</code></p> <p>Methods:</p> Name Description <code>extract_parameter</code> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <code>to_dict</code> <p>Return parameters as a dictionary, excluding internal fields.</p> <code>validate_log_data</code> <p>Validate and return log data if it's a dictionary.</p> <p>Attributes:</p> Name Type Description <code>epochs</code> <code>batch_size</code> <code>image_size</code> <code>seed</code> <code>validate</code> <code>train_set_split_ratio</code> <code>device</code> <code>parameters_data</code> <code>defaulted_keys</code> <code>set[str]</code>"},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.epochs","title":"<code>epochs = self.extract_parameter(keys=['epoch', 'epochs'], expected_type=int, default=10)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.batch_size","title":"<code>batch_size = self.extract_parameter(keys=['batch_size', 'batch'], expected_type=int, default=8)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.image_size","title":"<code>image_size = self.extract_parameter(keys=['image_size', 'imgsz', 'img_size'], expected_type=int, default=640)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.seed","title":"<code>seed = self.extract_parameter(keys=['seed'], expected_type=int, default=0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.validate","title":"<code>validate = self.extract_parameter(keys=['validate', 'val', 'validation'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.train_set_split_ratio","title":"<code>train_set_split_ratio = self.extract_parameter(keys=['prop_train_split', 'train_set_split_ratio'], expected_type=float, default=0.8)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.device","title":"<code>device = self.extract_parameter(keys=['device'], expected_type=str, default='cuda:0')</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.parameters_data","title":"<code>parameters_data = self.validate_log_data(log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.defaulted_keys","title":"<code>defaulted_keys = set()</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.extract_parameter","title":"<code>extract_parameter(keys, expected_type, default=..., range_value=None)</code>","text":"<pre><code>extract_parameter(keys: list, expected_type: type[T], default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; T\n</code></pre><pre><code>extract_parameter(keys: list, expected_type: Any, default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; Any\n</code></pre> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <p>Examples:</p> <p>Extract a required string parameter that cannot be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\", \"key2\"], expected_type=str)\n</code></pre></p> <p>Extract a required integer parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=int | None)\n</code></pre></p> <p>Extract an optional float parameter within a specific range: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=float, default=0.5, range_value=(0.0, 1.0))\n</code></pre></p> <p>Extract an optional string parameter with a default value: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=str, default=\"default_value\")\n</code></pre></p> <p>Extract an optional string parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=Union[str, None], default=None)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>A list of possible keys to extract the parameter.</p> required <code>type[T]</code> <p>The expected type of the parameter, can use Union for optional types.</p> required <code>Any</code> <p>The default value if the parameter is not found. Use ... for required parameters.</p> <code>...</code> <code>tuple[Any, Any] | None</code> <p>A tuple of two numbers representing the allowed range of the parameter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed parameter.</p>"},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.extract_parameter(keys)","title":"<code>keys</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.extract_parameter(expected_type)","title":"<code>expected_type</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.extract_parameter(default)","title":"<code>default</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.extract_parameter(range_value)","title":"<code>range_value</code>","text":""},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.to_dict","title":"<code>to_dict()</code>","text":"<p>Return parameters as a dictionary, excluding internal fields.</p>"},{"location":"api/core/parameters/hyper_parameters/#picsellia_cv_engine.core.parameters.hyper_parameters.HyperParameters.validate_log_data","title":"<code>validate_log_data(log_data)</code>","text":"<p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/core/services/context/config/","title":"core.services.context.config","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config","title":"<code>config</code>","text":"<p>Classes:</p> Name Description <code>Auth</code> <code>Run</code> <code>Experiment</code> <code>ModelVersion</code> <code>DatasetVersion</code> <code>Datalake</code> <code>JobTraining</code> <code>JobPreAnn</code> <code>JobDSVCreate</code> <code>JobAutoTag</code> <code>JobModelProcess</code> <code>OverrideOutputsMixin</code> <p>Shared toggle to overwrite/replace existing outputs without prompting.</p> <code>InputDatasetVersionCreation</code> <code>OutputDatasetVersionCreation</code> <code>DatasetVersionCreationConfig</code> <code>InputPreAnnotation</code> <code>PreAnnotationConfig</code> <code>AutoTagRunParams</code> <code>InputDataAutoTagging</code> <code>OutputDataAutoTagging</code> <code>DataAutoTaggingConfig</code> <code>InputModelProcess</code> <code>ModelProcessConfig</code> <code>InputTraining</code> <code>OutputTraining</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Auth","title":"<code>Auth</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>organization_name</code> <code>str</code> <code>env</code> <code>str | None</code> <code>host</code> <code>str | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Auth.organization_name","title":"<code>organization_name</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Auth.env","title":"<code>env = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Auth.host","title":"<code>host = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Run","title":"<code>Run</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str | None</code> <code>working_dir</code> <code>str | None</code> <code>mode</code> <code>Literal['local', 'picsellia'] | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Run.name","title":"<code>name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Run.working_dir","title":"<code>working_dir = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Run.mode","title":"<code>mode = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Experiment","title":"<code>Experiment</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str | None</code> <code>name</code> <code>str | None</code> <code>project_name</code> <code>str | None</code> <code>url</code> <code>str | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Experiment.id","title":"<code>id = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Experiment.name","title":"<code>name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Experiment.project_name","title":"<code>project_name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Experiment.url","title":"<code>url = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelVersion","title":"<code>ModelVersion</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <code>name</code> <code>str | None</code> <code>origin_name</code> <code>str | None</code> <code>url</code> <code>str | None</code> <code>visibility</code> <code>Literal['private', 'public']</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelVersion.id","title":"<code>id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelVersion.name","title":"<code>name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelVersion.origin_name","title":"<code>origin_name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelVersion.url","title":"<code>url = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelVersion.visibility","title":"<code>visibility</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersion","title":"<code>DatasetVersion</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str | None</code> <code>name</code> <code>str | None</code> <code>origin_name</code> <code>str | None</code> <code>version_name</code> <code>str | None</code> <code>url</code> <code>str | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersion.id","title":"<code>id = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersion.name","title":"<code>name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersion.origin_name","title":"<code>origin_name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersion.version_name","title":"<code>version_name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersion.url","title":"<code>url = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Datalake","title":"<code>Datalake</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <code>name</code> <code>str | None</code> <code>url</code> <code>str | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Datalake.id","title":"<code>id</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Datalake.name","title":"<code>name = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.Datalake.url","title":"<code>url = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobTraining","title":"<code>JobTraining</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['TRAINING']</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobTraining.type","title":"<code>type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobPreAnn","title":"<code>JobPreAnn</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['PRE_ANNOTATION']</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobPreAnn.type","title":"<code>type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobDSVCreate","title":"<code>JobDSVCreate</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['DATASET_VERSION_CREATION']</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobDSVCreate.type","title":"<code>type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobAutoTag","title":"<code>JobAutoTag</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['DATA_AUTO_TAGGING']</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobAutoTag.type","title":"<code>type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobModelProcess","title":"<code>JobModelProcess</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>type</code> <code>Literal['MODEL_CONVERSION', 'MODEL_COMPRESSION']</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.JobModelProcess.type","title":"<code>type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OverrideOutputsMixin","title":"<code>OverrideOutputsMixin</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Shared toggle to overwrite/replace existing outputs without prompting.</p> <p>Attributes:</p> Name Type Description <code>override_outputs</code> <code>bool</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OverrideOutputsMixin.override_outputs","title":"<code>override_outputs = Field(default=False, description='If true, existing target outputs (e.g., experiment bindings, dataset versions, target datalakes) will be overwritten or recreated without confirmation prompts where applicable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputDatasetVersionCreation","title":"<code>InputDatasetVersionCreation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>dataset_version</code> <code>DatasetVersion</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputDatasetVersionCreation.dataset_version","title":"<code>dataset_version</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OutputDatasetVersionCreation","title":"<code>OutputDatasetVersionCreation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>dataset_version</code> <code>DatasetVersion</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OutputDatasetVersionCreation.dataset_version","title":"<code>dataset_version</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig","title":"<code>DatasetVersionCreationConfig</code>","text":"<p>               Bases: <code>OverrideOutputsMixin</code>, <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>job</code> <code>JobDSVCreate</code> <code>auth</code> <code>Auth</code> <code>run</code> <code>Run</code> <code>input</code> <code>InputDatasetVersionCreation</code> <code>output</code> <code>OutputDatasetVersionCreation</code> <code>parameters</code> <code>dict[str, Any]</code> <code>override_outputs</code> <code>bool</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.job","title":"<code>job</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.auth","title":"<code>auth</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.run","title":"<code>run = Run()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.input","title":"<code>input</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.output","title":"<code>output</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.parameters","title":"<code>parameters = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DatasetVersionCreationConfig.override_outputs","title":"<code>override_outputs = Field(default=False, description='If true, existing target outputs (e.g., experiment bindings, dataset versions, target datalakes) will be overwritten or recreated without confirmation prompts where applicable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputPreAnnotation","title":"<code>InputPreAnnotation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>dataset_version</code> <code>DatasetVersion | None</code> <code>model_version</code> <code>ModelVersion | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputPreAnnotation.dataset_version","title":"<code>dataset_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputPreAnnotation.model_version","title":"<code>model_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig","title":"<code>PreAnnotationConfig</code>","text":"<p>               Bases: <code>OverrideOutputsMixin</code>, <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>job</code> <code>JobPreAnn</code> <code>auth</code> <code>Auth</code> <code>run</code> <code>Run</code> <code>input</code> <code>InputPreAnnotation</code> <code>parameters</code> <code>dict[str, Any]</code> <code>override_outputs</code> <code>bool</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig.job","title":"<code>job</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig.auth","title":"<code>auth</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig.run","title":"<code>run = Run()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig.input","title":"<code>input</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig.parameters","title":"<code>parameters = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.PreAnnotationConfig.override_outputs","title":"<code>override_outputs = Field(default=False, description='If true, existing target outputs (e.g., experiment bindings, dataset versions, target datalakes) will be overwritten or recreated without confirmation prompts where applicable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.AutoTagRunParams","title":"<code>AutoTagRunParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>offset</code> <code>int</code> <code>limit</code> <code>int</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.AutoTagRunParams.offset","title":"<code>offset = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.AutoTagRunParams.limit","title":"<code>limit = 100</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputDataAutoTagging","title":"<code>InputDataAutoTagging</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>datalake</code> <code>Datalake</code> <code>model_version</code> <code>ModelVersion | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputDataAutoTagging.datalake","title":"<code>datalake</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputDataAutoTagging.model_version","title":"<code>model_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OutputDataAutoTagging","title":"<code>OutputDataAutoTagging</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>datalake</code> <code>Datalake</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OutputDataAutoTagging.datalake","title":"<code>datalake</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig","title":"<code>DataAutoTaggingConfig</code>","text":"<p>               Bases: <code>OverrideOutputsMixin</code>, <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>job</code> <code>JobAutoTag</code> <code>auth</code> <code>Auth</code> <code>run</code> <code>Run</code> <code>input</code> <code>InputDataAutoTagging</code> <code>output</code> <code>OutputDataAutoTagging</code> <code>run_parameters</code> <code>AutoTagRunParams</code> <code>parameters</code> <code>dict[str, Any]</code> <code>override_outputs</code> <code>bool</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.job","title":"<code>job</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.auth","title":"<code>auth</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.run","title":"<code>run = Run()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.input","title":"<code>input</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.output","title":"<code>output</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.run_parameters","title":"<code>run_parameters</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.parameters","title":"<code>parameters = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.DataAutoTaggingConfig.override_outputs","title":"<code>override_outputs = Field(default=False, description='If true, existing target outputs (e.g., experiment bindings, dataset versions, target datalakes) will be overwritten or recreated without confirmation prompts where applicable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputModelProcess","title":"<code>InputModelProcess</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>model_version</code> <code>ModelVersion</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputModelProcess.model_version","title":"<code>model_version</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig","title":"<code>ModelProcessConfig</code>","text":"<p>               Bases: <code>OverrideOutputsMixin</code>, <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>job</code> <code>JobModelProcess</code> <code>auth</code> <code>Auth</code> <code>run</code> <code>Run</code> <code>input</code> <code>InputModelProcess</code> <code>parameters</code> <code>dict[str, Any]</code> <code>override_outputs</code> <code>bool</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig.job","title":"<code>job</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig.auth","title":"<code>auth</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig.run","title":"<code>run = Run()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig.input","title":"<code>input</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig.parameters","title":"<code>parameters = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.ModelProcessConfig.override_outputs","title":"<code>override_outputs = Field(default=False, description='If true, existing target outputs (e.g., experiment bindings, dataset versions, target datalakes) will be overwritten or recreated without confirmation prompts where applicable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputTraining","title":"<code>InputTraining</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>train_dataset_version</code> <code>DatasetVersion | None</code> <code>test_dataset_version</code> <code>DatasetVersion | None</code> <code>validation_dataset_version</code> <code>DatasetVersion | None</code> <code>model_version</code> <code>ModelVersion | None</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputTraining.train_dataset_version","title":"<code>train_dataset_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputTraining.test_dataset_version","title":"<code>test_dataset_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputTraining.validation_dataset_version","title":"<code>validation_dataset_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.InputTraining.model_version","title":"<code>model_version = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OutputTraining","title":"<code>OutputTraining</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Attributes:</p> Name Type Description <code>experiment</code> <code>Experiment</code>"},{"location":"api/core/services/context/config/#picsellia_cv_engine.core.services.context.config.OutputTraining.experiment","title":"<code>experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/context/local_context/","title":"core.services.context.local_context","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context","title":"<code>local_context</code>","text":"<p>Functions:</p> Name Description <code>create_local_dataset_processing_context</code> <p>Create a local processing context for running a processing pipeline outside of Picsellia.</p> <code>create_local_datalake_processing_context</code> <p>Create a local context for datalake processing pipelines.</p> <code>create_local_model_processing_context</code> <code>create_local_training_context</code> <p>Create a local training context for running a training pipeline outside of Picsellia.</p>"},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context","title":"<code>create_local_dataset_processing_context(processing_parameters_cls, organization_name, job_type, input_dataset_version_id, output_dataset_version_name=None, model_version_id=None, processing_parameters=None, working_dir=None, api_token=None, host=None)</code>","text":"<p>Create a local processing context for running a processing pipeline outside of Picsellia.</p> <p>This is typically used for development and testing, with full local control over input/output paths and parameter overrides.</p> <p>Parameters:</p> Name Type Description Default <code>type[TParameters]</code> <p>A subclass of <code>Parameters</code> used to define typed inputs.</p> required <code>str</code> <p>API token for authentication with Picsellia.</p> <code>None</code> <code>str</code> <p>Name of the Picsellia organization.</p> required <code>ProcessingType</code> <p>Type of processing job (e.g., <code>PRE_ANNOTATION</code>, <code>DATASET_VERSION_CREATION</code>).</p> required <code>str</code> <p>ID of the dataset version used as input.</p> required <code>str | None</code> <p>Optional name for the output dataset version.</p> <code>None</code> <code>str | None</code> <p>Optional ID of a model version to include in the context.</p> <code>None</code> <code>dict[str, Any] | None</code> <p>Raw values to override defaults in the processing parameters.</p> <code>None</code> <code>str | None</code> <p>Optional working directory for local file operations.</p> <code>None</code> <code>str | None</code> <p>Optional Picsellia API host override.</p> <code>None</code> <p>Returns:</p> Type Description <code>LocalDatasetProcessingContext</code> <p>LocalDatasetProcessingContext[TParameters]: A fully initialized local processing context.</p>"},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(processing_parameters_cls)","title":"<code>processing_parameters_cls</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(api_token)","title":"<code>api_token</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(organization_name)","title":"<code>organization_name</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(job_type)","title":"<code>job_type</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(input_dataset_version_id)","title":"<code>input_dataset_version_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(output_dataset_version_name)","title":"<code>output_dataset_version_name</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(model_version_id)","title":"<code>model_version_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(processing_parameters)","title":"<code>processing_parameters</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(working_dir)","title":"<code>working_dir</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_dataset_processing_context(host)","title":"<code>host</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context","title":"<code>create_local_datalake_processing_context(processing_parameters_cls, organization_name, job_type, input_datalake_id, output_datalake_id=None, model_version_id=None, offset=0, limit=100, use_id=True, processing_parameters=None, working_dir=None, api_token=None, host=None)</code>","text":"<p>Create a local context for datalake processing pipelines.</p> <p>Parameters:</p> Name Type Description Default <code>type[TParameters]</code> <p>Class used to parse processing parameters.</p> required <code>str | None</code> <p>Your Picsellia API token.</p> <code>None</code> <code>str</code> <p>Name of your organization.</p> required <code>ProcessingType</code> <p>Type of processing job.</p> required <code>str</code> <p>ID of the input datalake.</p> required <code>str | None</code> <p>Optional ID of the output datalake.</p> <code>None</code> <code>str | None</code> <p>Optional ID of the model version.</p> <code>None</code> <code>int</code> <p>Data offset for datalake slicing.</p> <code>0</code> <code>int</code> <p>Max number of samples to fetch.</p> <code>100</code> <code>bool</code> <p>Whether to use asset ID or path in output annotations.</p> <code>True</code> <code>dict[str, Any] | None</code> <p>Raw values to override defaults in the processing parameters.</p> <code>None</code> <code>str | None</code> <p>Optional working directory.</p> <code>None</code> <code>str | None</code> <p>Optional custom API host.</p> <code>None</code> <p>Returns:</p> Type Description <code>LocalDatalakeProcessingContext</code> <p>LocalDatalakeProcessingContext</p>"},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(processing_parameters_cls)","title":"<code>processing_parameters_cls</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(api_token)","title":"<code>api_token</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(organization_name)","title":"<code>organization_name</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(job_type)","title":"<code>job_type</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(input_datalake_id)","title":"<code>input_datalake_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(output_datalake_id)","title":"<code>output_datalake_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(model_version_id)","title":"<code>model_version_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(offset)","title":"<code>offset</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(limit)","title":"<code>limit</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(processing_parameters)","title":"<code>processing_parameters</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(working_dir)","title":"<code>working_dir</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_datalake_processing_context(host)","title":"<code>host</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_model_processing_context","title":"<code>create_local_model_processing_context(processing_parameters_cls, organization_name, job_type, input_model_version_id, processing_parameters=None, working_dir=None, api_token=None, host=None)</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context","title":"<code>create_local_training_context(hyperparameters_cls, augmentation_parameters_cls, export_parameters_cls, organization_name, experiment_id, hyperparameters=None, augmentation_parameters=None, export_parameters=None, working_dir=None, api_token=None, host=None)</code>","text":"<p>Create a local training context for running a training pipeline outside of Picsellia.</p> <p>This is typically used for development and debugging, with full local control over hyperparameters, augmentation strategies, and export configuration. Parameters can be pulled from the experiment logs or overridden manually.</p> <p>Parameters:</p> Name Type Description Default <code>type[HyperParameters]</code> <p>Class defining the training hyperparameters.</p> required <code>type[AugmentationParameters]</code> <p>Class defining data augmentation parameters.</p> required <code>type[ExportParameters]</code> <p>Class defining model export parameters.</p> required <code>str</code> <p>API token for authentication with Picsellia.</p> <code>None</code> <code>str</code> <p>Name of the Picsellia organization.</p> required <code>str</code> <p>ID of the experiment from which to load parameter logs.</p> required <code>dict[str, Any] | None</code> <p>Optional overrides for training hyperparameters.</p> <code>None</code> <code>dict[str, Any] | None</code> <p>Optional overrides for augmentation parameters.</p> <code>None</code> <code>dict[str, Any] | None</code> <p>Optional overrides for export parameters.</p> <code>None</code> <code>str | None</code> <p>Optional working directory for local file operations.</p> <code>None</code> <code>str | None</code> <p>Optional Picsellia API host override.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>LocalTrainingContext</code> <code>LocalTrainingContext</code> <p>A fully initialized local training context.</p>"},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(hyperparameters_cls)","title":"<code>hyperparameters_cls</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(augmentation_parameters_cls)","title":"<code>augmentation_parameters_cls</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(export_parameters_cls)","title":"<code>export_parameters_cls</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(api_token)","title":"<code>api_token</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(organization_name)","title":"<code>organization_name</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(experiment_id)","title":"<code>experiment_id</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(hyperparameters)","title":"<code>hyperparameters</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(augmentation_parameters)","title":"<code>augmentation_parameters</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(export_parameters)","title":"<code>export_parameters</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(working_dir)","title":"<code>working_dir</code>","text":""},{"location":"api/core/services/context/local_context/#picsellia_cv_engine.core.services.context.local_context.create_local_training_context(host)","title":"<code>host</code>","text":""},{"location":"api/core/services/context/picsellia_context/","title":"core.services.context.picsellia_context","text":""},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context","title":"<code>picsellia_context</code>","text":"<p>Functions:</p> Name Description <code>create_picsellia_dataset_processing_context</code> <p>Create a remote PicselliaDatasetProcessingContext using a static class to define parameters.</p> <code>create_picsellia_datalake_processing_context</code> <p>Create a remote PicselliaDatalakeProcessingContext using a static parameters class.</p> <code>create_picsellia_model_processing_context</code> <code>create_picsellia_training_context</code> <p>Create a remote PicselliaTrainingContext using static parameter classes.</p>"},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_dataset_processing_context","title":"<code>create_picsellia_dataset_processing_context(processing_parameters_cls)</code>","text":"<p>Create a remote PicselliaDatasetProcessingContext using a static class to define parameters.</p> <p>This context is used during pipeline execution on the Picsellia platform.</p> <p>Parameters:</p> Name Type Description Default <code>type[TParameters]</code> <p>A class inheriting from <code>Parameters</code> defining expected processing parameters.</p> required <p>Returns:</p> Name Type Description <code>PicselliaDatasetProcessingContext</code> <code>PicselliaDatasetProcessingContext</code> <p>An initialized context for use in remote processing pipelines.</p>"},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_dataset_processing_context(processing_parameters_cls)","title":"<code>processing_parameters_cls</code>","text":""},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_datalake_processing_context","title":"<code>create_picsellia_datalake_processing_context(processing_parameters_cls)</code>","text":"<p>Create a remote PicselliaDatalakeProcessingContext using a static parameters class.</p> <p>This context is used during pipeline execution on the Picsellia platform for datalake-based jobs.</p> <p>Parameters:</p> Name Type Description Default <code>type[TParameters]</code> <p>A class inheriting from <code>Parameters</code> defining expected processing parameters.</p> required <p>Returns:</p> Name Type Description <code>PicselliaDatalakeProcessingContext</code> <code>PicselliaDatalakeProcessingContext</code> <p>An initialized context for remote processing pipelines.</p>"},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_datalake_processing_context(processing_parameters_cls)","title":"<code>processing_parameters_cls</code>","text":""},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_model_processing_context","title":"<code>create_picsellia_model_processing_context(processing_parameters_cls)</code>","text":""},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_training_context","title":"<code>create_picsellia_training_context(hyperparameters_cls, augmentation_parameters_cls, export_parameters_cls)</code>","text":"<p>Create a remote PicselliaTrainingContext using static parameter classes.</p> <p>This context is used during model training executed on the Picsellia platform.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <p>Class defining hyperparameters (inherits from <code>HyperParameters</code>).</p> required <code>type</code> <p>Class defining augmentation parameters.</p> required <code>type</code> <p>Class defining export/export format parameters.</p> required <p>Returns:</p> Name Type Description <code>PicselliaTrainingContext</code> <code>PicselliaTrainingContext</code> <p>An initialized context for remote training pipelines.</p>"},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_training_context(hyperparameters_cls)","title":"<code>hyperparameters_cls</code>","text":""},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_training_context(augmentation_parameters_cls)","title":"<code>augmentation_parameters_cls</code>","text":""},{"location":"api/core/services/context/picsellia_context/#picsellia_cv_engine.core.services.context.picsellia_context.create_picsellia_training_context(export_parameters_cls)","title":"<code>export_parameters_cls</code>","text":""},{"location":"api/core/services/context/unified_context/","title":"core.services.context.unified_context","text":""},{"location":"api/core/services/context/unified_context/#picsellia_cv_engine.core.services.context.unified_context","title":"<code>unified_context</code>","text":"<p>Functions:</p> Name Description <code>create_processing_context_from_config</code> <code>create_training_context_from_config</code> <p>Attributes:</p> Name Type Description <code>Mode</code>"},{"location":"api/core/services/context/unified_context/#picsellia_cv_engine.core.services.context.unified_context.Mode","title":"<code>Mode = Literal['local', 'picsellia']</code>  <code>module-attribute</code>","text":""},{"location":"api/core/services/context/unified_context/#picsellia_cv_engine.core.services.context.unified_context.create_processing_context_from_config","title":"<code>create_processing_context_from_config(processing_type, processing_parameters_cls, mode='picsellia', config_file_path=None)</code>","text":""},{"location":"api/core/services/context/unified_context/#picsellia_cv_engine.core.services.context.unified_context.create_training_context_from_config","title":"<code>create_training_context_from_config(hyperparameters_cls, augmentation_parameters_cls, export_parameters_cls, mode='picsellia', config_file_path=None)</code>","text":""},{"location":"api/core/services/data/dataset/utils/","title":"core.services.data.dataset.utils","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils","title":"<code>utils</code>","text":"<p>Functions:</p> Name Description <code>load_coco_datasets_impl</code> <p>Implementation logic to load COCO datasets depending on the pipeline context type.</p> <code>load_yolo_datasets_impl</code> <p>Implementation logic to load YOLO datasets depending on the pipeline context type.</p> <code>validate_dataset_impl</code>"},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_coco_datasets_impl","title":"<code>load_coco_datasets_impl(context, use_id, skip_asset_listing)</code>","text":"<p>Implementation logic to load COCO datasets depending on the pipeline context type.</p> <p>Handles both training and processing contexts and downloads assets and annotations accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>PicselliaTrainingContext | LocalTrainingContext | PicselliaDatasetProcessingContext | LocalDatasetProcessingContext</code> <p>Either a training or processing context instance.</p> required <code>bool</code> <p>Whether to preserve the original asset UUIDs when naming files (instead of filenames).</p> required <code>bool</code> <p>Whether to skip asset listing before download.</p> required <p>Returns:</p> Type Description <code>DatasetCollection[CocoDataset] | CocoDataset</code> <p>DatasetCollection[CocoDataset] or CocoDataset: The loaded dataset(s).</p>"},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_coco_datasets_impl(context)","title":"<code>context</code>","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_coco_datasets_impl(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_coco_datasets_impl(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_yolo_datasets_impl","title":"<code>load_yolo_datasets_impl(context, use_id, skip_asset_listing)</code>","text":"<p>Implementation logic to load YOLO datasets depending on the pipeline context type.</p> <p>Handles both training and processing contexts and downloads assets and annotations accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>PicselliaTrainingContext | LocalTrainingContext | PicselliaDatasetProcessingContext | LocalDatasetProcessingContext</code> <p>Either a training or processing context instance.</p> required <code>bool</code> <p>Whether to preserve the original asset UUIDs when naming files (instead of filenames).</p> required <code>bool</code> <p>Whether to skip asset listing before download.</p> required <p>Returns:</p> Type Description <code>DatasetCollection[YoloDataset] | YoloDataset</code> <p>DatasetCollection[YoloDataset] or YoloDataset: The loaded dataset(s).</p>"},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_yolo_datasets_impl(context)","title":"<code>context</code>","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_yolo_datasets_impl(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.load_yolo_datasets_impl(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/core/services/data/dataset/utils/#picsellia_cv_engine.core.services.data.dataset.utils.validate_dataset_impl","title":"<code>validate_dataset_impl(dataset, fix_annotation=False)</code>","text":""},{"location":"api/core/services/data/dataset/loader/training_dataset_collection_extractor/","title":"core.services.data.dataset.loader.training_dataset_collection_extractor","text":""},{"location":"api/core/services/data/dataset/loader/training_dataset_collection_extractor/#picsellia_cv_engine.core.services.data.dataset.loader.training_dataset_collection_extractor","title":"<code>training_dataset_collection_extractor</code>","text":""},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/","title":"core.services.data.dataset.preprocessing.classification_dataset_preparator","text":""},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator","title":"<code>classification_dataset_preparator</code>","text":"<p>Classes:</p> Name Description <code>ClassificationBaseDatasetPreparator</code> <p>Prepares and organizes dataset images into directories based on their classification categories.</p>"},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator.ClassificationBaseDatasetPreparator","title":"<code>ClassificationBaseDatasetPreparator(dataset, destination_dir)</code>","text":"<p>Prepares and organizes dataset images into directories based on their classification categories.</p> <p>This class takes a dataset with category and annotation information in COCO format. It organizes the dataset by creating a directory for each category and moves the images into their respective category directories, which is often required for classification tasks in deep learning frameworks.</p> <p>Attributes:</p> Name Type Description <code>dataset</code> <code>BaseDataset</code> <p>The context of the dataset including paths and COCO file.</p> <code>destination_dir</code> <code>str</code> <p>The target directory where the images will be moved and organized.</p> <p>Parameters:</p> Name Type Description Default <code>BaseDataset</code> <p>The context of the dataset to organize.</p> required <code>str</code> <p>The directory where the organized images will be stored.</p> required <p>Methods:</p> Name Description <code>organize</code> <p>Organizes the dataset by creating category directories and moving images.</p>"},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator.ClassificationBaseDatasetPreparator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator.ClassificationBaseDatasetPreparator(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator.ClassificationBaseDatasetPreparator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator.ClassificationBaseDatasetPreparator.destination_dir","title":"<code>destination_dir = destination_dir</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/preprocessing/classification_dataset_preparator/#picsellia_cv_engine.core.services.data.dataset.preprocessing.classification_dataset_preparator.ClassificationBaseDatasetPreparator.organize","title":"<code>organize()</code>","text":"<p>Organizes the dataset by creating category directories and moving images.</p> <p>Extracts category information from the COCO file, maps images to their categories, and organizes the images into the respective category directories. Cleans up the original image directory and annotations directory after moving the images.</p> <p>Returns:</p> Name Type Description <code>CocoDataset</code> <code>CocoDataset</code> <p>The updated dataset with the new image directory.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/","title":"core.services.data.dataset.uploader.utils","text":""},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils","title":"<code>utils</code>","text":"<p>Functions:</p> Name Description <code>get_datalake_and_tag</code> <p>Retrieve datalake and data_tag from context or arguments.</p> <code>initialize_coco_data</code> <p>Ensure COCO data is initialized properly.</p> <code>configure_dataset_type</code> <p>Configure dataset type if not already set.</p> <code>determine_inference_type</code> <p>Determine and set the inference type based on annotations.</p> <code>upload_images_and_annotations</code> <p>Upload dataset based on inference type.</p> <code>upload_images</code> <p>Upload images to the dataset.</p> <code>upload_annotations</code> <p>Upload annotations based on inference type.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.get_datalake_and_tag","title":"<code>get_datalake_and_tag(context, datalake, data_tag)</code>","text":"<p>Retrieve datalake and data_tag from context or arguments.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.initialize_coco_data","title":"<code>initialize_coco_data(dataset)</code>","text":"<p>Ensure COCO data is initialized properly.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.configure_dataset_type","title":"<code>configure_dataset_type(dataset, annotations)</code>","text":"<p>Configure dataset type if not already set.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.determine_inference_type","title":"<code>determine_inference_type(dataset, annotations)</code>","text":"<p>Determine and set the inference type based on annotations.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.upload_images_and_annotations","title":"<code>upload_images_and_annotations(dataset, datalake, data_tag, use_id=True, fail_on_asset_not_found=True, replace_annotations=False, attempts=1000)</code>","text":"<p>Upload dataset based on inference type.</p> <p>Supports Classification, Object Detection, and Segmentation inference types.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.upload_images","title":"<code>upload_images(dataset, datalake, data_tag, attempts=1000)</code>","text":"<p>Upload images to the dataset.</p>"},{"location":"api/core/services/data/dataset/uploader/utils/#picsellia_cv_engine.core.services.data.dataset.uploader.utils.upload_annotations","title":"<code>upload_annotations(dataset, use_id=True, fail_on_asset_not_found=True, replace_annotations=False)</code>","text":"<p>Upload annotations based on inference type.</p> <p>Supports Classification, Object Detection, and Segmentation inference types.</p>"},{"location":"api/core/services/data/dataset/validator/utils/","title":"core.services.data.dataset.validator.utils","text":""},{"location":"api/core/services/data/dataset/validator/utils/#picsellia_cv_engine.core.services.data.dataset.validator.utils","title":"<code>utils</code>","text":"<p>Functions:</p> Name Description <code>get_dataset_validator</code> <p>Retrieves the appropriate validator for a given dataset.</p>"},{"location":"api/core/services/data/dataset/validator/utils/#picsellia_cv_engine.core.services.data.dataset.validator.utils.get_dataset_validator","title":"<code>get_dataset_validator(dataset, fix_annotation=True)</code>","text":"<p>Retrieves the appropriate validator for a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset to validate.</p> required <code>bool</code> <p>A flag to indicate whether to automatically fix errors (default is True).</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The validator instance or None if the dataset type is unsupported.</p>"},{"location":"api/core/services/data/dataset/validator/utils/#picsellia_cv_engine.core.services.data.dataset.validator.utils.get_dataset_validator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/utils/#picsellia_cv_engine.core.services.data.dataset.validator.utils.get_dataset_validator(fix_annotation)","title":"<code>fix_annotation</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/","title":"core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator","title":"<code>coco_classification_dataset_context_validator</code>","text":"<p>Classes:</p> Name Description <code>CocoClassificationDatasetValidator</code>"},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator","title":"<code>CocoClassificationDatasetValidator(dataset, fix_annotation=False)</code>","text":"<p>               Bases: <code>DatasetValidator[CocoDataset]</code></p> <p>Parameters:</p> Name Type Description Default <code>Dataset</code> <p>The dataset to validate.</p> required <p>Methods:</p> Name Description <code>validate</code> <p>Validate the classification dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p> <p>Attributes:</p> Name Type Description <code>VALID_IMAGE_EXTENSIONS</code> <code>dataset</code> <code>fix_annotation</code>"},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validate the classification dataset. A classification dataset must have at least 2 classes and at least 1 image per class.</p> <p>Logs the number of images per class and any errors found. Raises:     ValueError: If the classification dataset is not valid.</p>"},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/classification/coco_classification_dataset_context_validator/#picsellia_cv_engine.core.services.data.dataset.validator.classification.coco_classification_dataset_context_validator.CocoClassificationDatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/","title":"core.services.data.dataset.validator.common.dataset_collection_validator","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator","title":"<code>dataset_collection_validator</code>","text":"<p>Classes:</p> Name Description <code>DatasetCollectionValidator</code> <p>Validates various aspects of a dataset collection.</p>"},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator.DatasetCollectionValidator","title":"<code>DatasetCollectionValidator(dataset_collection, dataset_validator)</code>","text":"<p>Validates various aspects of a dataset collection.</p> <p>This class performs common validation tasks for dataset collections, including checking for image extraction completeness, image format, image corruption, and annotation integrity.</p> <p>Attributes:</p> Name Type Description <code>dataset_collection</code> <code>DatasetCollection</code> <p>The dataset collection to validate.</p> <code>dataset_validator</code> <code>Type[DatasetValidator]</code> <p>The validator class for individual datasets.</p> <p>Parameters:</p> Name Type Description Default <code>DatasetCollection</code> <p>The dataset collection to validate.</p> required <code>Type[DatasetValidator]</code> <p>The class used to validate individual datasets.</p> required <p>Methods:</p> Name Description <code>validate</code> <p>Validates the dataset collection.</p>"},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator.DatasetCollectionValidator(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator.DatasetCollectionValidator(dataset_validator)","title":"<code>dataset_validator</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator.DatasetCollectionValidator.dataset_collection","title":"<code>dataset_collection = dataset_collection</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator.DatasetCollectionValidator.dataset_validator","title":"<code>dataset_validator = dataset_validator</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_collection_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_collection_validator.DatasetCollectionValidator.validate","title":"<code>validate(fix_annotation=False)</code>","text":"<p>Validates the dataset collection.</p> <p>Iterates through the datasets in the collection and applies the context validator for each dataset.</p>"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/","title":"core.services.data.dataset.validator.common.dataset_validator","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator","title":"<code>dataset_validator</code>","text":"<p>Classes:</p> Name Description <code>DatasetValidator</code> <p>Validates various aspects of a dataset.</p>"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator","title":"<code>DatasetValidator(dataset, fix_annotation=False)</code>","text":"<p>               Bases: <code>Generic[TBaseDataset]</code></p> <p>Validates various aspects of a dataset.</p> <p>This class performs common validation tasks for datasets, including checking for image extraction completeness, image format, image corruption, and annotation integrity.</p> <p>Attributes:</p> Name Type Description <code>dataset</code> <code>Dataset</code> <p>The dataset to validate.</p> <p>Parameters:</p> Name Type Description Default <code>Dataset</code> <p>The dataset to validate.</p> required <p>Methods:</p> Name Description <code>validate</code> <p>Validates the dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p>"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validates the dataset.</p>"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/common/dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.dataset_validator.DatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/","title":"core.services.data.dataset.validator.common.not_configured_dataset_validator","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator","title":"<code>not_configured_dataset_validator</code>","text":"<p>Classes:</p> Name Description <code>NotConfiguredDatasetValidator</code>"},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator","title":"<code>NotConfiguredDatasetValidator(dataset, fix_annotation=False)</code>","text":"<p>               Bases: <code>DatasetValidator[TBaseDataset]</code></p> <p>Parameters:</p> Name Type Description Default <code>Dataset</code> <p>The dataset to validate.</p> required <p>Methods:</p> Name Description <code>validate</code> <p>Validate the dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p> <p>Attributes:</p> Name Type Description <code>VALID_IMAGE_EXTENSIONS</code> <code>dataset</code> <code>fix_annotation</code>"},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validate the dataset.</p>"},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/common/not_configured_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.common.not_configured_dataset_validator.NotConfiguredDatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/","title":"core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator","title":"<code>coco_object_detection_dataset_validator</code>","text":"<p>Classes:</p> Name Description <code>CocoObjectDetectionDatasetValidator</code>"},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator","title":"<code>CocoObjectDetectionDatasetValidator(dataset, fix_annotation=True)</code>","text":"<p>               Bases: <code>DatasetValidator[CocoDataset]</code></p> <p>Parameters:</p> Name Type Description Default <code>CocoDataset</code> <p>The dataset containing the COCO data to validate.</p> required <code>bool</code> <p>Flag to indicate whether to automatically fix issues (default is True).</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>error_count</code> <code>Dict</code> <p>A dictionary to track the count of different types of errors found during validation.</p> <p>Methods:</p> Name Description <code>validate</code> <p>Validate the COCO object detection dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p> <p>Attributes:</p> Name Type Description <code>error_count</code> <code>VALID_IMAGE_EXTENSIONS</code> <code>dataset</code> <code>fix_annotation</code>"},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator(fix_annotation)","title":"<code>fix_annotation</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.error_count","title":"<code>error_count = {'top_left_x': 0, 'top_left_y': 0, 'bottom_right_x': 0, 'bottom_right_y': 0}</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validate the COCO object detection dataset.</p> <p>Ensures the dataset has: - At least one class in the labelmap. - At least one image with bounding boxes. - Valid bounding box coordinates for all annotations.</p> <p>Returns:</p> Name Type Description <code>CocoDataset</code> <code>CocoDataset</code> <p>The validated (or fixed) dataset.</p>"},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/object_detection/coco_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.coco_object_detection_dataset_validator.CocoObjectDetectionDatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/","title":"core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator","title":"<code>yolo_object_detection_dataset_validator</code>","text":"<p>Classes:</p> Name Description <code>YoloObjectDetectionDatasetValidator</code> <p>Validator for YOLO format annotations.</p>"},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator","title":"<code>YoloObjectDetectionDatasetValidator(dataset, fix_annotation=True)</code>","text":"<p>               Bases: <code>DatasetValidator[YoloDataset]</code></p> <p>Validator for YOLO format annotations.</p> <p>Parameters:</p> Name Type Description Default <code>YoloDataset</code> <p>The context object containing dataset information and annotations.</p> required <code>bool</code> <p>Flag indicating whether to automatically fix the detected issues.</p> <code>True</code> <p>Methods:</p> Name Description <code>validate</code> <p>Validates the YOLO object detection dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p> <p>Attributes:</p> Name Type Description <code>error_count</code> <code>VALID_IMAGE_EXTENSIONS</code> <code>dataset</code> <code>fix_annotation</code>"},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator(fix_annotation)","title":"<code>fix_annotation</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.error_count","title":"<code>error_count = {'class_id': 0, 'x_center': 0, 'y_center': 0, 'width': 0, 'height': 0}</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validates the YOLO object detection dataset.</p> <p>This method performs the following validation checks: - Verifies that the labelmap contains at least one class. - Validates the format and bounds of the YOLO annotations. - Reports any issues found during the validation process.</p> <p>Returns:</p> Name Type Description <code>YoloDataset</code> <code>YoloDataset</code> <p>The validated or updated dataset.</p>"},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/object_detection/yolo_object_detection_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.object_detection.yolo_object_detection_dataset_validator.YoloObjectDetectionDatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/","title":"core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator","title":"<code>coco_segmentation_dataset_validator</code>","text":"<p>Classes:</p> Name Description <code>CocoSegmentationDatasetValidator</code> <p>Validator for COCO Segmentation format annotations.</p>"},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator","title":"<code>CocoSegmentationDatasetValidator(dataset, fix_annotation=True)</code>","text":"<p>               Bases: <code>DatasetValidator[CocoDataset]</code></p> <p>Validator for COCO Segmentation format annotations.</p> <p>Parameters:</p> Name Type Description Default <code>CocoDataset</code> <p>The dataset containing the COCO segmentation data to validate.</p> required <code>bool</code> <p>A flag to indicate whether to automatically fix errors (default is True).</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>error_count</code> <code>dict</code> <p>A dictionary to track the count of different types of errors found during validation.</p> <p>Methods:</p> Name Description <code>validate</code> <p>Validate the COCO segmentation dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p> <p>Attributes:</p> Name Type Description <code>error_count</code> <code>VALID_IMAGE_EXTENSIONS</code> <code>dataset</code> <code>fix_annotation</code>"},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator(fix_annotation)","title":"<code>fix_annotation</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.error_count","title":"<code>error_count = {'class_id': 0, 'polygon_points': 0, 'deleted_objects': 0}</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validate the COCO segmentation dataset.</p> <p>Ensures all COCO segmentation annotations are correctly formatted, within bounds, and valid. If any issues are found, they are reported, and optionally fixed.</p> <p>Returns:</p> Name Type Description <code>CocoDataset</code> <code>CocoDataset</code> <p>The validated (or fixed) dataset.</p>"},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/segmentation/coco_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.coco_segmentation_dataset_validator.CocoSegmentationDatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/","title":"core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator","title":"<code>yolo_segmentation_dataset_validator</code>","text":"<p>Classes:</p> Name Description <code>YoloSegmentationDatasetValidator</code> <p>Validator for YOLO Segmentation format annotations.</p>"},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator","title":"<code>YoloSegmentationDatasetValidator(dataset, fix_annotation=True)</code>","text":"<p>               Bases: <code>DatasetValidator[YoloDataset]</code></p> <p>Validator for YOLO Segmentation format annotations.</p> <p>Parameters:</p> Name Type Description Default <code>YoloDataset</code> <p>The context of the YOLO dataset containing annotation data.</p> required <code>bool</code> <p>Flag to indicate whether to automatically fix the detected issues.</p> <code>True</code> <p>Methods:</p> Name Description <code>validate</code> <p>Validates the YOLO segmentation dataset.</p> <code>validate_images_extraction</code> <p>Validates that the number of extracted images matches the expected number of assets.</p> <code>validate_images_format</code> <p>Validates that all images in the dataset are in an expected format.</p> <code>validate_images_corruption</code> <p>Checks for corruption in the extracted images.</p> <p>Attributes:</p> Name Type Description <code>error_count</code> <code>VALID_IMAGE_EXTENSIONS</code> <code>dataset</code> <code>fix_annotation</code>"},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator(fix_annotation)","title":"<code>fix_annotation</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.error_count","title":"<code>error_count = {'class_id': 0, 'polygon_points': 0, 'deleted_objects': 0}</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.VALID_IMAGE_EXTENSIONS","title":"<code>VALID_IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.dataset","title":"<code>dataset = dataset</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.fix_annotation","title":"<code>fix_annotation = fix_annotation</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate","title":"<code>validate()</code>","text":"<p>Validates the YOLO segmentation dataset.</p> <p>This method checks whether the annotation files are correctly formatted, validates class IDs and polygon points, and optionally fixes issues. It also reports the number of errors detected during validation.</p> <p>Returns:</p> Name Type Description <code>YoloDataset</code> <code>YoloDataset</code> <p>The validated or updated dataset.</p>"},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate_images_extraction","title":"<code>validate_images_extraction(images_path_list)</code>","text":"<p>Validates that the number of extracted images matches the expected number of assets.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate_images_extraction(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate_images_format","title":"<code>validate_images_format(images_path_list)</code>","text":"<p>Validates that all images in the dataset are in an expected format.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate_images_format(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate_images_corruption","title":"<code>validate_images_corruption(images_path_list)</code>","text":"<p>Checks for corruption in the extracted images.</p> <p>Parameters:</p> Name Type Description Default <code>List[str]</code> <p>The list of image paths extracted from the dataset.</p> required"},{"location":"api/core/services/data/dataset/validator/segmentation/yolo_segmentation_dataset_validator/#picsellia_cv_engine.core.services.data.dataset.validator.segmentation.yolo_segmentation_dataset_validator.YoloSegmentationDatasetValidator.validate_images_corruption(images_path_list)","title":"<code>images_path_list</code>","text":""},{"location":"api/core/services/model/utils/","title":"core.services.model.utils","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils","title":"<code>utils</code>","text":"<p>Functions:</p> Name Description <code>build_model_impl</code> <p>Instantiate and initialize a model object within the current Picsellia pipeline context.</p> <code>evaluate_model_impl</code> <p>Run evaluation of model predictions using the appropriate evaluation strategy based on inference type.</p>"},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl","title":"<code>build_model_impl(context, model_cls, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None)</code>","text":"<p>Instantiate and initialize a model object within the current Picsellia pipeline context.</p> <p>This function supports both training and processing contexts and uses the appropriate model version to build the model. It also downloads any associated model weights (pretrained, trained, exported).</p> <p>Parameters:</p> Name Type Description Default <code>PicselliaDatasetProcessingContext | PicselliaTrainingContext | LocalDatasetProcessingContext | LocalTrainingContext</code> <p>The current pipeline context, which must be either a training or processing context.</p> required <code>type[TModel]</code> <p>The model class to instantiate.</p> required <code>str</code> <p>The name of the pretrained weights to download.</p> <code>None</code> <code>str</code> <p>The name of the trained weights to download.</p> <code>None</code> <code>str</code> <p>The name of the model configuration file.</p> <code>None</code> <code>str</code> <p>The name of the exported weights for inference.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TModel</code> <code>TModel</code> <p>An instance of the initialized model with weights downloaded.</p>"},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl(context)","title":"<code>context</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl(model_cls)","title":"<code>model_cls</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.build_model_impl(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl","title":"<code>evaluate_model_impl(context, picsellia_predictions, inference_type, assets, output_dir, training_labelmap=None)</code>","text":"<p>Run evaluation of model predictions using the appropriate evaluation strategy based on inference type.</p> <p>This function leverages Picsellia's <code>ModelEvaluator</code> to: - Compare predictions to ground truth. - Compute classification metrics for classification tasks. - Compute COCO metrics for detection and segmentation tasks.</p> <p>Parameters:</p> Name Type Description Default <code>PicselliaDatasetProcessingContext | PicselliaTrainingContext | LocalDatasetProcessingContext | LocalTrainingContext</code> <p>The current pipeline context, expected to contain an experiment.</p> required <code>list[PicselliaClassificationPrediction] | list[PicselliaRectanglePrediction] | list[PicselliaPolygonPrediction] | list[PicselliaOCRPrediction]</code> <p>List of predictions generated by the model, matching the inference type.</p> required <code>InferenceType</code> <p>The type of model inference performed (e.g., classification, detection).</p> required <code>list[Asset] | MultiAsset</code> <p>Ground truth assets against which predictions are evaluated.</p> required <code>str</code> <p>The directory where evaluation metrics and results will be written.</p> required <code>dict[str, str] | None</code> <p>Optional mapping of training labels for evaluation alignment.</p> <code>None</code>"},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl(context)","title":"<code>context</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl(picsellia_predictions)","title":"<code>picsellia_predictions</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl(inference_type)","title":"<code>inference_type</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl(assets)","title":"<code>assets</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"api/core/services/model/utils/#picsellia_cv_engine.core.services.model.utils.evaluate_model_impl(training_labelmap)","title":"<code>training_labelmap</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/","title":"core.services.model.evaluator.model_evaluator","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator","title":"<code>model_evaluator</code>","text":"<p>Classes:</p> Name Description <code>ModelEvaluator</code> <p>Evaluates model predictions and logs metrics into a Picsellia experiment.</p>"},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator","title":"<code>ModelEvaluator(experiment, inference_type)</code>","text":"<p>Evaluates model predictions and logs metrics into a Picsellia experiment.</p> <p>Supports classification, detection (rectangle), OCR, and segmentation (polygon) evaluations, including COCO-style and sklearn metrics.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>The experiment where results will be logged.</p> required <code>InferenceType</code> <p>Type of inference (classification, detection, etc.).</p> required <p>Methods:</p> Name Description <code>evaluate</code> <p>Add and compute evaluation metrics from a list of predictions.</p> <code>add_evaluation</code> <p>Add a single prediction to the experiment as evaluation.</p> <code>compute_coco_metrics</code> <p>Compute COCO metrics and log them into the experiment.</p> <code>compute_classification_metrics</code> <p>Compute sklearn classification metrics (acc, precision, recall, F1).</p> <p>Attributes:</p> Name Type Description <code>experiment</code> <code>inference_type</code> <code>experiment_logger</code>"},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator(inference_type)","title":"<code>inference_type</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.experiment","title":"<code>experiment = experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.inference_type","title":"<code>inference_type = inference_type</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.experiment_logger","title":"<code>experiment_logger = BaseLogger(experiment=experiment, metric_mapping=(MetricMapping()))</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.evaluate","title":"<code>evaluate(picsellia_predictions)</code>","text":"<p>Add and compute evaluation metrics from a list of predictions.</p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>List of PicselliaPrediction objects.</p> required"},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.evaluate(picsellia_predictions)","title":"<code>picsellia_predictions</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.add_evaluation","title":"<code>add_evaluation(evaluation)</code>","text":"<p>Add a single prediction to the experiment as evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>PicselliaClassificationPrediction | PicselliaRectanglePrediction | PicselliaPolygonPrediction | PicselliaOCRPrediction</code> <p>A prediction (classification, rectangle, OCR, or polygon).</p> required"},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.add_evaluation(evaluation)","title":"<code>evaluation</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_coco_metrics","title":"<code>compute_coco_metrics(assets, output_dir, training_labelmap)</code>","text":"<p>Compute COCO metrics and log them into the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>list | MultiAsset</code> <p>Assets to evaluate.</p> required <code>str</code> <p>Directory to save metrics.</p> required <code>dict</code> <p>Label ID-to-name mapping.</p> required"},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_coco_metrics(assets)","title":"<code>assets</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_coco_metrics(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_coco_metrics(training_labelmap)","title":"<code>training_labelmap</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_classification_metrics","title":"<code>compute_classification_metrics(assets, output_dir, training_labelmap)</code>","text":"<p>Compute sklearn classification metrics (acc, precision, recall, F1).</p> <p>Parameters:</p> Name Type Description Default <code>list | MultiAsset</code> <p>Assets to evaluate.</p> required <code>str</code> <p>Output directory.</p> required <code>dict</code> <p>Label ID-to-name mapping.</p> required"},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_classification_metrics(assets)","title":"<code>assets</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_classification_metrics(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"api/core/services/model/evaluator/model_evaluator/#picsellia_cv_engine.core.services.model.evaluator.model_evaluator.ModelEvaluator.compute_classification_metrics(training_labelmap)","title":"<code>training_labelmap</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/","title":"core.services.model.evaluator.utils.coco_converter","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter","title":"<code>coco_converter</code>","text":"<p>Functions:</p> Name Description <code>save_json</code> <code>get_asset</code> <code>flatten_segmentation</code> <code>compute_bbox_and_area_from_polygon</code> <code>extract_prediction_list</code> <code>build_annotation</code> <code>generate_coco_predictions</code> <code>extract_asset_annotations</code> <code>build_gt_annotation</code> <code>generate_coco_ground_truth</code> <code>create_coco_files_from_experiment</code>"},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.save_json","title":"<code>save_json(coco_data, output_path)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.get_asset","title":"<code>get_asset(id, connexion, dataset_version_id)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.flatten_segmentation","title":"<code>flatten_segmentation(segmentation)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.compute_bbox_and_area_from_polygon","title":"<code>compute_bbox_and_area_from_polygon(flattened_polygon)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.extract_prediction_list","title":"<code>extract_prediction_list(evaluation_info, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.build_annotation","title":"<code>build_annotation(pred, image_id, label_name, category_id, annotation_id, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.generate_coco_predictions","title":"<code>generate_coco_predictions(evaluations, image_name_map, label_name_map, categories, gt_coco_path, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.extract_asset_annotations","title":"<code>extract_asset_annotations(asset, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.build_gt_annotation","title":"<code>build_gt_annotation(ann, image_id, label_name, category_id, annotation_id, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.generate_coco_ground_truth","title":"<code>generate_coco_ground_truth(assets, image_name_map, label_name_map, categories, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_converter/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_converter.create_coco_files_from_experiment","title":"<code>create_coco_files_from_experiment(experiment, assets, gt_coco_path, pred_coco_path, inference_type)</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/","title":"core.services.model.evaluator.utils.coco_utils","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils","title":"<code>coco_utils</code>","text":"<p>Functions:</p> Name Description <code>load_json</code> <p>Load and return the contents of a JSON file.</p> <code>save_json</code> <p>Save data to a JSON file with an indentation of 4 spaces.</p> <code>adjust_image_ids</code> <p>Adjust image IDs in COCO data. If the image IDs start at 0, they are incremented by 1.</p> <code>renumber_annotation_ids</code> <p>Renumber annotation IDs sequentially starting from 1.</p> <code>fix_coco_ids</code> <p>Fix image and annotation IDs in a COCO file. Images whose IDs start at 0 are adjusted and</p> <code>create_image_id_mapping</code> <p>Create a mapping between image IDs from the ground truth and prediction data based on the 'file_name' field.</p> <code>fix_image_ids</code> <p>Fix the 'image_id' fields in prediction data using the provided mapping.</p> <code>match_image_ids</code> <p>Match image IDs between the ground truth and prediction files.</p> <code>compute_tp_fp_fn</code> <p>Compute the number of True Positives (TP), False Positives (FP), and False Negatives (FN) per category</p> <code>calculate_metrics</code> <p>Calculate precision, recall, and F1-score.</p> <code>evaluate_category</code> <p>Evaluate predictions for a given category using COCO metrics.</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.load_json","title":"<code>load_json(file_path)</code>","text":"<p>Load and return the contents of a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the JSON file.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Parsed JSON data.</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.load_json(file_path)","title":"<code>file_path</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.save_json","title":"<code>save_json(data, file_path)</code>","text":"<p>Save data to a JSON file with an indentation of 4 spaces.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>Data to save.</p> required <code>str</code> <p>Output path for the JSON file.</p> required"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.save_json(data)","title":"<code>data</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.save_json(file_path)","title":"<code>file_path</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.adjust_image_ids","title":"<code>adjust_image_ids(coco_data)</code>","text":"<p>Adjust image IDs in COCO data. If the image IDs start at 0, they are incremented by 1.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>COCO data containing the \"images\" and \"annotations\" keys.</p> required"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.adjust_image_ids(coco_data)","title":"<code>coco_data</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.renumber_annotation_ids","title":"<code>renumber_annotation_ids(coco_data)</code>","text":"<p>Renumber annotation IDs sequentially starting from 1.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>COCO data containing the \"annotations\" key.</p> required"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.renumber_annotation_ids(coco_data)","title":"<code>coco_data</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.fix_coco_ids","title":"<code>fix_coco_ids(coco_path)</code>","text":"<p>Fix image and annotation IDs in a COCO file. Images whose IDs start at 0 are adjusted and annotation IDs are renumbered sequentially. The fixed file is saved with the suffix '_fixed'.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the original COCO file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the fixed COCO file.</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.fix_coco_ids(coco_path)","title":"<code>coco_path</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.create_image_id_mapping","title":"<code>create_image_id_mapping(gt_images, pred_images)</code>","text":"<p>Create a mapping between image IDs from the ground truth and prediction data based on the 'file_name' field.</p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>List of ground truth images (each a dict with 'file_name' and 'id').</p> required <code>list</code> <p>List of predicted images (each a dict with 'file_name' and 'id').</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Mapping {predicted_image_id: ground_truth_image_id}.</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.create_image_id_mapping(gt_images)","title":"<code>gt_images</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.create_image_id_mapping(pred_images)","title":"<code>pred_images</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.fix_image_ids","title":"<code>fix_image_ids(pred_data, id_mapping)</code>","text":"<p>Fix the 'image_id' fields in prediction data using the provided mapping.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>Prediction COCO data containing \"images\" and \"annotations\".</p> required <code>dict</code> <p>Mapping between predicted and ground truth image IDs.</p> required"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.fix_image_ids(pred_data)","title":"<code>pred_data</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.fix_image_ids(id_mapping)","title":"<code>id_mapping</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.match_image_ids","title":"<code>match_image_ids(ground_truth_file, prediction_file, corrected_prediction_file)</code>","text":"<p>Match image IDs between the ground truth and prediction files. Loads the ground truth and prediction JSON files, creates a mapping based on 'file_name', fixes the prediction image IDs using the mapping, and saves the corrected predictions.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the COCO ground truth file.</p> required <code>str</code> <p>Path to the COCO predictions file.</p> required <code>str</code> <p>Output path for the corrected predictions file.</p> required"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.match_image_ids(ground_truth_file)","title":"<code>ground_truth_file</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.match_image_ids(prediction_file)","title":"<code>prediction_file</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.match_image_ids(corrected_prediction_file)","title":"<code>corrected_prediction_file</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.compute_tp_fp_fn","title":"<code>compute_tp_fp_fn(coco_eval)</code>","text":"<p>Compute the number of True Positives (TP), False Positives (FP), and False Negatives (FN) per category using a COCOeval object.</p> <p>Parameters:</p> Name Type Description Default <code>COCOeval</code> <p>COCOeval object after evaluation.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary mapping each category ID to a dict with keys \"TP\", \"FP\", and \"FN\".</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.compute_tp_fp_fn(coco_eval)","title":"<code>coco_eval</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.calculate_metrics","title":"<code>calculate_metrics(tp, fp, fn)</code>","text":"<p>Calculate precision, recall, and F1-score.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Number of True Positives.</p> required <code>int</code> <p>Number of False Positives.</p> required <code>int</code> <p>Number of False Negatives.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[float, float, float]</code> <p>Precision, recall, and F1-score.</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.calculate_metrics(tp)","title":"<code>tp</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.calculate_metrics(fp)","title":"<code>fp</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.calculate_metrics(fn)","title":"<code>fn</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.evaluate_category","title":"<code>evaluate_category(coco_gt, coco_pred, cat_name, inference_type)</code>","text":"<p>Evaluate predictions for a given category using COCO metrics. Runs evaluation for the specified category and area 'all', then computes additional metrics (TP, FP, FN, precision, recall, F1-score).</p> <p>Parameters:</p> Name Type Description Default <code>COCO</code> <p>COCO object for the ground truth.</p> required <code>COCO</code> <p>COCO object for the predictions.</p> required <code>str</code> <p>Category name.</p> required <code>InferenceType</code> <p>Type of inference (classification, detection, or segmentation).</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing evaluation metrics for the category.</p>"},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.evaluate_category(coco_gt)","title":"<code>coco_gt</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.evaluate_category(coco_pred)","title":"<code>coco_pred</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.evaluate_category(cat_name)","title":"<code>cat_name</code>","text":""},{"location":"api/core/services/model/evaluator/utils/coco_utils/#picsellia_cv_engine.core.services.model.evaluator.utils.coco_utils.evaluate_category(inference_type)","title":"<code>inference_type</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/","title":"core.services.model.evaluator.utils.compute_confusion_matrix","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix","title":"<code>compute_confusion_matrix</code>","text":"<p>Functions:</p> Name Description <code>box_iou</code> <p>Calculate intersection-over-union (IoU) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format.</p> <code>compute_full_confusion_matrix</code> <p>Compute a confusion matrix for object detection with a background class.</p> <code>compute_confusion_matrix_impl</code>"},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.box_iou","title":"<code>box_iou(box1, box2, eps=1e-07)</code>","text":"<p>Calculate intersection-over-union (IoU) of boxes. Both sets of boxes are expected to be in (x1, y1, x2, y2) format. Based on https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py.</p> <p>Parameters:</p> Name Type Description Default <code>Tensor</code> <p>A tensor of shape (N, 4) representing N bounding boxes.</p> required <code>Tensor</code> <p>A tensor of shape (M, 4) representing M bounding boxes.</p> required <code>float</code> <p>A small value to avoid division by zero. Defaults to 1e-7.</p> <code>1e-07</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>An NxM tensor containing the pairwise IoU values for every element in box1 and box2.</p>"},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.box_iou(box1)","title":"<code>box1</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.box_iou(box2)","title":"<code>box2</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.box_iou(eps)","title":"<code>eps</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.compute_full_confusion_matrix","title":"<code>compute_full_confusion_matrix(gt_annotations, pred_annotations, label_map, iou_threshold=0.5)</code>","text":"<p>Compute a confusion matrix for object detection with a background class.</p> <p>Parameters:</p> Name Type Description Default <code>List[dict]</code> <p>Ground truth annotations from COCO GT (coco.loadAnns()).</p> required <code>List[dict]</code> <p>Predicted annotations from COCO Pred (coco.loadAnns()).</p> required <code>dict</code> <p>Mapping of category indices (as int) to class names.</p> required <code>float</code> <p>IoU threshold for matching.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Confusion matrix of shape (num_classes+1, num_classes+1)         where the last index represents 'background'.</p>"},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.compute_full_confusion_matrix(gt_annotations)","title":"<code>gt_annotations</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.compute_full_confusion_matrix(pred_annotations)","title":"<code>pred_annotations</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.compute_full_confusion_matrix(label_map)","title":"<code>label_map</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.compute_full_confusion_matrix(iou_threshold)","title":"<code>iou_threshold</code>","text":""},{"location":"api/core/services/model/evaluator/utils/compute_confusion_matrix/#picsellia_cv_engine.core.services.model.evaluator.utils.compute_confusion_matrix.compute_confusion_matrix_impl","title":"<code>compute_confusion_matrix_impl(coco_gt, coco_pred, label_map, training_labelmap, experiment_logger)</code>","text":""},{"location":"api/core/services/model/export/model_exporter/","title":"core.services.model.export.model_exporter","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter","title":"<code>model_exporter</code>","text":"<p>Classes:</p> Name Description <code>ModelExporter</code> <p>Base class for exporting and saving a model.</p>"},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter","title":"<code>ModelExporter(model)</code>","text":"<p>Base class for exporting and saving a model.</p> <p>This class provides a standard interface for exporting models and saving them to a Picsellia experiment or model version.</p> <p>Parameters:</p> Name Type Description Default <code>Model</code> <p>The model to export.</p> required <p>Methods:</p> Name Description <code>export_model</code> <p>Abstract method to export the model.</p> <code>save_model_to_experiment</code> <p>Save exported model to a Picsellia experiment.</p> <code>save_model_to_model_version</code> <p>Save exported model to a Picsellia model version.</p> <p>Attributes:</p> Name Type Description <code>model</code>"},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter(model)","title":"<code>model</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.export_model","title":"<code>export_model(exported_model_destination_path, export_format, hyperparameters)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to export the model.</p> <p>Must be implemented in subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Directory to export the model to.</p> required <code>str</code> <p>Format to export the model in.</p> required <code>Any</code> <p>Optional export configuration.</p> required"},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.export_model(exported_model_destination_path)","title":"<code>exported_model_destination_path</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.export_model(export_format)","title":"<code>export_format</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.export_model(hyperparameters)","title":"<code>hyperparameters</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_experiment","title":"<code>save_model_to_experiment(experiment, exported_weights_path, exported_weights_name)</code>","text":"<p>Save exported model to a Picsellia experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Target experiment.</p> required <code>str</code> <p>Path to exported weights directory.</p> required <code>str</code> <p>File name to use in Picsellia.</p> required"},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_experiment(exported_weights_path)","title":"<code>exported_weights_path</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_experiment(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_model_version","title":"<code>save_model_to_model_version(model_version, exported_weights_path, exported_weights_name)</code>","text":"<p>Save exported model to a Picsellia model version.</p> <p>Parameters:</p> Name Type Description Default <code>ModelVersion</code> <p>Target model version.</p> required <code>str</code> <p>Path to exported weights directory.</p> required <code>str</code> <p>File name to use in Picsellia.</p> required"},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_model_version(model_version)","title":"<code>model_version</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_model_version(exported_weights_path)","title":"<code>exported_weights_path</code>","text":""},{"location":"api/core/services/model/export/model_exporter/#picsellia_cv_engine.core.services.model.export.model_exporter.ModelExporter.save_model_to_model_version(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/core/services/model/predictor/model_collection_predictor/","title":"core.services.model.predictor.model_collection_predictor","text":""},{"location":"api/core/services/model/predictor/model_collection_predictor/#picsellia_cv_engine.core.services.model.predictor.model_collection_predictor","title":"<code>model_collection_predictor</code>","text":"<p>Classes:</p> Name Description <code>ModelCollectionPredictor</code>"},{"location":"api/core/services/model/predictor/model_collection_predictor/#picsellia_cv_engine.core.services.model.predictor.model_collection_predictor.ModelCollectionPredictor","title":"<code>ModelCollectionPredictor(model_collection)</code>","text":"<p>               Bases: <code>Generic[TModelCollection]</code></p> <p>Attributes:</p> Name Type Description <code>model_collection</code> <code>TModelCollection</code>"},{"location":"api/core/services/model/predictor/model_collection_predictor/#picsellia_cv_engine.core.services.model.predictor.model_collection_predictor.ModelCollectionPredictor.model_collection","title":"<code>model_collection = model_collection</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/","title":"core.services.model.predictor.model_predictor","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor","title":"<code>model_predictor</code>","text":"<p>Classes:</p> Name Description <code>ModelPredictor</code> <p>Abstract base class for model inference.</p>"},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor","title":"<code>ModelPredictor(model)</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[TModel]</code></p> <p>Abstract base class for model inference.</p> <p>Provides utility methods to standardize prediction outputs (labels, confidence, rectangles) into Picsellia-compatible structures.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>TModel</code> <p>The model instance used for inference.</p> <p>Parameters:</p> Name Type Description Default <code>TModel</code> <p>The model context with loaded weights and configuration.</p> required <p>Methods:</p> Name Description <code>pre_process_dataset</code> <p>Extracts all image paths from the dataset's image directory.</p> <code>prepare_batches</code> <code>get_picsellia_label</code> <p>Get or create a PicselliaLabel from a dataset category name.</p> <code>get_picsellia_confidence</code> <p>Wrap a confidence score in a PicselliaConfidence object.</p> <code>get_picsellia_rectangle</code> <p>Create a PicselliaRectangle from bounding box coordinates.</p>"},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor(model)","title":"<code>model</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Extracts all image paths from the dataset's image directory.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset object containing the image directory.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of file paths to the dataset images.</p>"},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.prepare_batches","title":"<code>prepare_batches(image_paths, batch_size)</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_label","title":"<code>get_picsellia_label(category_name, dataset)</code>","text":"<p>Get or create a PicselliaLabel from a dataset category name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the label category.</p> required <code>TBaseDataset</code> <p>Dataset that provides label access.</p> required <p>Returns:</p> Name Type Description <code>PicselliaLabel</code> <code>PicselliaLabel</code> <p>Wrapped label object.</p>"},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_label(category_name)","title":"<code>category_name</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_label(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_confidence","title":"<code>get_picsellia_confidence(confidence)</code>","text":"<p>Wrap a confidence score in a PicselliaConfidence object.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Prediction confidence score.</p> required <p>Returns:</p> Name Type Description <code>PicselliaConfidence</code> <code>PicselliaConfidence</code> <p>Wrapped confidence object.</p>"},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_confidence(confidence)","title":"<code>confidence</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_rectangle","title":"<code>get_picsellia_rectangle(x, y, w, h)</code>","text":"<p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Top-left x-coordinate.</p> required <code>int</code> <p>Top-left y-coordinate.</p> required <code>int</code> <p>Width of the box.</p> required <code>int</code> <p>Height of the box.</p> required <p>Returns:</p> Name Type Description <code>PicselliaRectangle</code> <code>PicselliaRectangle</code> <p>Rectangle wrapper for object detection.</p>"},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_rectangle(x)","title":"<code>x</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_rectangle(y)","title":"<code>y</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_rectangle(w)","title":"<code>w</code>","text":""},{"location":"api/core/services/model/predictor/model_predictor/#picsellia_cv_engine.core.services.model.predictor.model_predictor.ModelPredictor.get_picsellia_rectangle(h)","title":"<code>h</code>","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/","title":"core.services.processing.dataset_version_creation_processing","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing","title":"<code>dataset_version_creation_processing</code>","text":"<p>Classes:</p> Name Description <code>DatasetVersionCreationProcessing</code> <p>Handles the processing of creating a dataset version.</p>"},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing","title":"<code>DatasetVersionCreationProcessing(client, datalake, output_dataset_version)</code>","text":"<p>Handles the processing of creating a dataset version.</p> <p>This class offers all the necessary methods to handle a processing of type DatasetVersionCreation of Picsellia. It allows to upload images to the datalake, add them to a dataset version, and update the dataset version with the necessary information.</p> <p>Attributes:</p> Name Type Description <code>client</code> <code>Client</code> <p>The Picsellia client to use for the processing.</p> <code>datalake(Datalake)</code> <code>Client</code> <p>The Datalake to use for the processing.</p> <code>output_dataset_version</code> <code>DatasetVersion</code> <p>The dataset version to create.</p> <p>Methods:</p> Name Description <code>update_output_dataset_version_description</code> <p>Updates the description of the output dataset version.</p> <code>update_output_dataset_version_inference_type</code> <p>Updates the inference type of the output dataset version.</p> <code>process</code> <p>Processes the dataset version creation.</p>"},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.client","title":"<code>client = client</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.output_dataset_version","title":"<code>output_dataset_version = output_dataset_version</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.datalake","title":"<code>datalake = datalake</code>  <code>instance-attribute</code>","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.update_output_dataset_version_description","title":"<code>update_output_dataset_version_description(description)</code>","text":"<p>Updates the description of the output dataset version.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The new description to set for the dataset version.</p> required"},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.update_output_dataset_version_description(description)","title":"<code>description</code>","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.update_output_dataset_version_inference_type","title":"<code>update_output_dataset_version_inference_type(inference_type)</code>","text":"<p>Updates the inference type of the output dataset version.</p> <p>Parameters:</p> Name Type Description Default <code>InferenceType</code> <p>The new inference type to set for the dataset version.</p> required"},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.update_output_dataset_version_inference_type(inference_type)","title":"<code>inference_type</code>","text":""},{"location":"api/core/services/processing/dataset_version_creation_processing/#picsellia_cv_engine.core.services.processing.dataset_version_creation_processing.DatasetVersionCreationProcessing.process","title":"<code>process()</code>  <code>abstractmethod</code>","text":"<p>Processes the dataset version creation.</p>"},{"location":"api/core/services/utils/annotations/","title":"core.services.utils.annotations","text":""},{"location":"api/core/services/utils/annotations/#picsellia_cv_engine.core.services.utils.annotations","title":"<code>annotations</code>","text":"<p>Functions:</p> Name Description <code>mask_to_polygons</code> <p>Convert a binary segmentation mask into a list of polygons.</p>"},{"location":"api/core/services/utils/annotations/#picsellia_cv_engine.core.services.utils.annotations.mask_to_polygons","title":"<code>mask_to_polygons(mask)</code>","text":"<p>Convert a binary segmentation mask into a list of polygons.</p> <p>This function extracts the external contours from a 2D binary mask and converts them into polygon representations. Each polygon is a NumPy array of (x, y) coordinates. Contours with fewer than 3 points are discarded to ensure valid polygon shapes.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>A 2D NumPy array representing the binary mask, where non-zero pixels indicate the segmented region.</p> required <p>Returns:</p> Type Description <code>list[ndarray]</code> <p>list[np.ndarray]: A list of polygons extracted from the mask. Each polygon is a NumPy array of shape (N, 2) with integer coordinates, where N is the number of points in the polygon.</p>"},{"location":"api/core/services/utils/annotations/#picsellia_cv_engine.core.services.utils.annotations.mask_to_polygons(mask)","title":"<code>mask</code>","text":""},{"location":"api/core/services/utils/dataset_logging/","title":"core.services.utils.dataset_logging","text":""},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging","title":"<code>dataset_logging</code>","text":"<p>Functions:</p> Name Description <code>get_labelmap</code> <p>Retrieves the label map from a dataset version.</p> <code>log_labelmap</code> <p>Logs the label map to an experiment.</p>"},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging.get_labelmap","title":"<code>get_labelmap(dataset_version)</code>","text":"<p>Retrieves the label map from a dataset version.</p> <p>This function generates a dictionary that maps label names to their corresponding label objects from a given dataset version.</p> <p>Parameters:</p> Name Type Description Default <code>DatasetVersion</code> <p>The dataset version from which to retrieve the label map.</p> required <p>Returns:</p> Type Description <code>dict[str, Label]</code> <p>dict[str, Label]: A dictionary mapping label names to their corresponding Label objects.</p>"},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging.get_labelmap(dataset_version)","title":"<code>dataset_version</code>","text":""},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging.log_labelmap","title":"<code>log_labelmap(labelmap, experiment, log_name)</code>","text":"<p>Logs the label map to an experiment.</p> <p>This function logs the label map to a specified experiment in a tabular format.</p> <p>Parameters:</p> Name Type Description Default <code>dict[str, Label]</code> <p>A dictionary mapping label names to Label objects.</p> required <code>Experiment</code> <p>The experiment where the label map will be logged.</p> required <code>str</code> <p>The name under which the label map will be logged.</p> required"},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging.log_labelmap(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging.log_labelmap(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/core/services/utils/dataset_logging/#picsellia_cv_engine.core.services.utils.dataset_logging.log_labelmap(log_name)","title":"<code>log_name</code>","text":""},{"location":"api/core/services/utils/image_file/","title":"core.services.utils.image_file","text":""},{"location":"api/core/services/utils/image_file/#picsellia_cv_engine.core.services.utils.image_file","title":"<code>image_file</code>","text":"<p>Functions:</p> Name Description <code>get_images_path_list</code> <p>Generates a list of all image file paths within a specified directory.</p>"},{"location":"api/core/services/utils/image_file/#picsellia_cv_engine.core.services.utils.image_file.get_images_path_list","title":"<code>get_images_path_list(images_dir)</code>","text":"<p>Generates a list of all image file paths within a specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The directory to search for image files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list containing the paths to all images found within the directory and its subdirectories.</p>"},{"location":"api/core/services/utils/image_file/#picsellia_cv_engine.core.services.utils.image_file.get_images_path_list(images_dir)","title":"<code>images_dir</code>","text":""},{"location":"api/decorators/pipeline_decorator/","title":"decorators.pipeline_decorator","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator","title":"<code>pipeline_decorator</code>","text":"<p>Classes:</p> Name Description <code>Pipeline</code> <p>Functions:</p> Name Description <code>pipeline</code> <p>Decorator to create a pipeline.</p> <p>Attributes:</p> Name Type Description <code>F</code>"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.F","title":"<code>F = TypeVar('F', bound=(Callable[..., Any]))</code>  <code>module-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline","title":"<code>Pipeline(context, name, log_folder_path, remove_logs_on_completion, entrypoint)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>Any</code> <p>The context of the pipeline. This object can be used to store and share data between steps. It will be accessible by calling the method <code>Pipeline.get_active_context()</code>.</p> required <code>str</code> <p>The name of the pipeline.</p> required <code>str | None</code> <p>The path to the log folder. If left empty, a temporary folder will be created.</p> required <code>bool</code> <p>Whether to remove the logs on completion. Defaults to True.</p> required <code>F</code> <p>The entrypoint of the pipeline. This is the function that will be called when the pipeline is run.</p> required <p>Methods:</p> Name Description <code>log_pipeline_info</code> <p>Log the provided content inside the pipeline log file.</p> <code>log_pipeline_warning</code> <p>Log the provided content inside the pipeline log file.</p> <code>register_active_step_metadata</code> <p>Register the metadata of a step found during the pipeline scan.</p> <code>flag_pipeline</code> <p>Flags the pipeline with the provided state.</p> <code>get_active_context</code> <p>Get the context of the currently running pipeline.</p> <code>register_step_metadata</code> <p>Register a step metadata into the global steps' registry.</p> <p>Attributes:</p> Name Type Description <code>ACTIVE_PIPELINE</code> <code>Optional[Pipeline]</code> <code>STEPS_REGISTRY</code> <code>dict[str, StepMetadata]</code> <code>name</code> <code>logger_manager</code> <code>remove_logs_on_completion</code> <code>entrypoint</code> <code>initialization_log_file_path</code> <code>str | None</code> <code>state</code> <code>PipelineState</code> <p>The state of the pipeline.</p> <code>steps_metadata</code> <code>list[StepMetadata]</code> <p>All the pipeline's steps' metadata.</p>"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline(context)","title":"<code>context</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline(name)","title":"<code>name</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline(log_folder_path)","title":"<code>log_folder_path</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline(remove_logs_on_completion)","title":"<code>remove_logs_on_completion</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline(entrypoint)","title":"<code>entrypoint</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.ACTIVE_PIPELINE","title":"<code>ACTIVE_PIPELINE = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.STEPS_REGISTRY","title":"<code>STEPS_REGISTRY = {}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.logger_manager","title":"<code>logger_manager = LoggerManager(pipeline_name=name, log_folder_root_path=log_folder_path)</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.remove_logs_on_completion","title":"<code>remove_logs_on_completion = remove_logs_on_completion</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.entrypoint","title":"<code>entrypoint = entrypoint</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.initialization_log_file_path","title":"<code>initialization_log_file_path = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.state","title":"<code>state</code>  <code>property</code>","text":"<p>The state of the pipeline.</p> <p>The pipeline's state is determined by the states of its steps. The pipeline can be in one of the following states:</p> <ul> <li>PENDING: All the steps are pending.</li> <li>RUNNING: At least one step is running, and no step has failed.</li> <li>SUCCESS: All the steps have succeeded.</li> <li>FAILED: At least one step has failed and no step has succeeded after it. By default, a step is skipped if a     previous step has failed. This behavior can be changed by setting the <code>continue_on_failure</code> parameter to     <code>True</code> when defining a step.</li> <li>PARTIAL_SUCCESS: At least one step has succeeded after a failed step.</li> </ul> <p>Returns:</p> Type Description <code>PipelineState</code> <p>The state of the pipeline.</p>"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.steps_metadata","title":"<code>steps_metadata</code>  <code>property</code>","text":"<p>All the pipeline's steps' metadata.</p> <p>Returns:</p> Type Description <code>list[StepMetadata]</code> <p>All the pipeline's steps' metadata.</p>"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.log_pipeline_info","title":"<code>log_pipeline_info(log_content)</code>","text":"<p>Log the provided content inside the pipeline log file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The content to log.</p> required"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.log_pipeline_info(log_content)","title":"<code>log_content</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.log_pipeline_warning","title":"<code>log_pipeline_warning(log_content)</code>","text":"<p>Log the provided content inside the pipeline log file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The content to log.</p> required"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.log_pipeline_warning(log_content)","title":"<code>log_content</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.register_active_step_metadata","title":"<code>register_active_step_metadata(step_metadata)</code>","text":"<p>Register the metadata of a step found during the pipeline scan.</p> <p>Parameters:</p> Name Type Description Default <code>StepMetadata</code> <p>The metadata of the step to register.</p> required"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.register_active_step_metadata(step_metadata)","title":"<code>step_metadata</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.flag_pipeline","title":"<code>flag_pipeline(state)</code>","text":"<p>Flags the pipeline with the provided state.</p> <p>Parameters:</p> Name Type Description Default <code>PipelineState</code> <p>The state to flag the pipeline with.</p> required"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.flag_pipeline(state)","title":"<code>state</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.get_active_context","title":"<code>get_active_context()</code>  <code>staticmethod</code>","text":"<p>Get the context of the currently running pipeline.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The context of the currently running pipeline.</p>"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.register_step_metadata","title":"<code>register_step_metadata(step_metadata)</code>  <code>staticmethod</code>","text":"<p>Register a step metadata into the global steps' registry.</p> <p>This method is only used to register the steps' metadata within the global steps registry, typically when a step is defined. This registry will then be used during the pipeline scan to identify the steps used inside.</p> <p>Parameters:</p> Name Type Description Default <code>StepMetadata</code> <p>The metadata of the step to register.</p> required"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.Pipeline.register_step_metadata(step_metadata)","title":"<code>step_metadata</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.pipeline","title":"<code>pipeline(_func=None, context=None, name=None, log_folder_path=None, remove_logs_on_completion=True)</code>","text":"<pre><code>pipeline(_func: F) -&gt; Pipeline\n</code></pre><pre><code>pipeline(*, context: Any | None = None, name: str | None = None, log_folder_path: str | None = None, remove_logs_on_completion: bool = True) -&gt; Callable[[F], Pipeline]\n</code></pre> <p>Decorator to create a pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[F]</code> <p>The decorated function.</p> <code>None</code> <code>Any | None</code> <p>The context of the pipeline. This object can be used to store and share data between steps. It will be accessible by calling the method <code>Pipeline.get_active_context()</code>.</p> <code>None</code> <code>str | None</code> <p>The name of the pipeline. If left empty, the name of the decorated function will be used as a fallback.</p> <code>None</code> <code>str | None</code> <p>The path to the log folder. If left empty, a temporary folder will be created.</p> <code>None</code> <code>bool</code> <p>Whether to remove the logs on completion. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Pipeline, Callable[[F], Pipeline]]</code> <p>A pipeline instance.</p>"},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.pipeline(_func)","title":"<code>_func</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.pipeline(context)","title":"<code>context</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.pipeline(name)","title":"<code>name</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.pipeline(log_folder_path)","title":"<code>log_folder_path</code>","text":""},{"location":"api/decorators/pipeline_decorator/#picsellia_cv_engine.decorators.pipeline_decorator.pipeline(remove_logs_on_completion)","title":"<code>remove_logs_on_completion</code>","text":""},{"location":"api/decorators/step_decorator/","title":"decorators.step_decorator","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator","title":"<code>step_decorator</code>","text":"<p>Classes:</p> Name Description <code>Step</code> <p>Functions:</p> Name Description <code>step</code> <p>Decorator to create a step.</p> <p>Attributes:</p> Name Type Description <code>F</code>"},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.F","title":"<code>F = TypeVar('F', bound=(Callable[..., Any]))</code>  <code>module-attribute</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step","title":"<code>Step(continue_on_failure, entrypoint, metadata)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>bool</code> <p>Tells if the step should be executed, even if the previous steps have failed.</p> required <code>F</code> <p>The function to be executed when the step is called.</p> required <code>StepMetadata</code> <p>The metadata associated to the step.</p> required <p>Methods:</p> Name Description <code>log_step_info</code> <p>Wrapper to log step information.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>step_name</code> <code>continue_on_failure</code> <code>entrypoint</code> <code>metadata</code> <code>StepMetadata</code> <p>The metadata associated to the step.</p> <code>state</code> <code>StepState</code> <p>The step's current state.</p>"},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step(continue_on_failure)","title":"<code>continue_on_failure</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step(entrypoint)","title":"<code>entrypoint</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step(metadata)","title":"<code>metadata</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.id","title":"<code>id = metadata.id</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.step_name","title":"<code>step_name = metadata.name</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.continue_on_failure","title":"<code>continue_on_failure = continue_on_failure</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.entrypoint","title":"<code>entrypoint = entrypoint</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.metadata","title":"<code>metadata</code>  <code>property</code>","text":"<p>The metadata associated to the step.</p> <p>Returns:</p> Type Description <code>StepMetadata</code> <p>The metadata associated to the step.</p>"},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.state","title":"<code>state</code>  <code>property</code>","text":"<p>The step's current state.</p> <p>Returns:</p> Type Description <code>StepState</code> <p>The step's current state.</p>"},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.log_step_info","title":"<code>log_step_info(pipeline, step_logger, log_content)</code>","text":"<p>Wrapper to log step information.</p> <p>Parameters:</p> Name Type Description Default <code>Pipeline</code> <p>The pipeline the step belongs to.</p> required <code>Logger</code> <p>The logger to use for logging.</p> required <code>str</code> <p>The content to log.</p> required"},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.log_step_info(pipeline)","title":"<code>pipeline</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.log_step_info(step_logger)","title":"<code>step_logger</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.Step.log_step_info(log_content)","title":"<code>log_content</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.step","title":"<code>step(_func=None, name=None, continue_on_failure=False)</code>","text":"<pre><code>step(_func: F) -&gt; Step\n</code></pre><pre><code>step(*, name: str | None = None, continue_on_failure: bool = False) -&gt; Callable[[F], Step]\n</code></pre> <p>Decorator to create a step. The step will automatically be registered in the current pipeline and log its content inside a dedicated log file.</p> <p>Parameters:</p> Name Type Description Default <code>Optional[F]</code> <p>The decorated function.</p> <code>None</code> <code>str | None</code> <p>The name of the step. If left empty, the name of the decorated function will be used as a fallback.</p> <code>None</code> <code>bool</code> <p>Tells if the step should be executed, even if the previous steps have failed</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Step, Callable[[F], Step]]</code> <p>A pipeline instance.</p>"},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.step(_func)","title":"<code>_func</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.step(name)","title":"<code>name</code>","text":""},{"location":"api/decorators/step_decorator/#picsellia_cv_engine.decorators.step_decorator.step(continue_on_failure)","title":"<code>continue_on_failure</code>","text":""},{"location":"api/decorators/step_metadata/","title":"decorators.step_metadata","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata","title":"<code>step_metadata</code>","text":"<p>Classes:</p> Name Description <code>StepMetadata</code>"},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata","title":"<code>StepMetadata(id, name, display_name, state, log_file_path=None)</code>","text":"<p>Attributes:</p> Name Type Description <code>id</code> <code>name</code> <code>display_name</code> <code>state</code> <code>execution_time</code> <code>log_file_path</code> <code>index</code> <code>int | None</code>"},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.id","title":"<code>id = id</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.display_name","title":"<code>display_name = display_name</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.state","title":"<code>state = state</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.execution_time","title":"<code>execution_time = 0.0</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.log_file_path","title":"<code>log_file_path = log_file_path</code>  <code>instance-attribute</code>","text":""},{"location":"api/decorators/step_metadata/#picsellia_cv_engine.decorators.step_metadata.StepMetadata.index","title":"<code>index = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/model/model/","title":"frameworks.clip.model.model","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model","title":"<code>model</code>","text":"<p>Classes:</p> Name Description <code>CLIPModel</code> <p>CLIP model wrapper for managing weights, processor, and runtime configurations.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel","title":"<code>CLIPModel(name, model_version, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None, labelmap=None)</code>","text":"<p>               Bases: <code>Model</code></p> <p>CLIP model wrapper for managing weights, processor, and runtime configurations.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the model.</p> required <code>ModelVersion</code> <p>Associated Picsellia ModelVersion.</p> required <code>str | None</code> <p>Optional name of the pretrained weights file.</p> <code>None</code> <code>str | None</code> <p>Optional name of the trained weights file.</p> <code>None</code> <code>str | None</code> <p>Optional name of the config file.</p> <code>None</code> <code>str | None</code> <p>Optional name of the exported weights file.</p> <code>None</code> <code>dict[str, Label] | None</code> <p>Optional dictionary mapping label names to Picsellia Label objects.</p> <code>None</code> <p>Methods:</p> Name Description <code>set_loaded_processor</code> <p>Set the processor instance after loading it at runtime.</p> <code>load_weights</code> <p>Load model weights and processor from the specified path and Hugging Face repository.</p> <code>set_loaded_model</code> <p>Set the runtime-loaded model instance.</p> <code>download_weights</code> <p>Download all configured model files (weights, config, exports) to destination.</p> <code>save_artifact_to_experiment</code> <p>Store an artifact file in the given experiment.</p> <p>Attributes:</p> Name Type Description <code>loaded_processor</code> <code>Any</code> <p>Return the loaded processor instance.</p> <code>name</code> <p>The name of the model.</p> <code>model_version</code> <p>The version of the model from Picsellia.</p> <code>pretrained_weights_name</code> <p>The name of the pretrained weights file attached to the model version in Picsellia.</p> <code>trained_weights_name</code> <p>The name of the trained weights file attached to the model version in Picsellia.</p> <code>config_name</code> <p>The name of the configuration file attached to the model version in Picsellia.</p> <code>exported_weights_name</code> <p>The name of the exported weights file attached to the model version in Picsellia.</p> <code>labelmap</code> <p>A dictionary mapping category names to labels.</p> <code>weights_dir</code> <code>str | None</code> <p>The directory where model weights are stored.</p> <code>results_dir</code> <code>str | None</code> <p>The directory where model results are stored.</p> <code>pretrained_weights_dir</code> <code>str | None</code> <p>The directory where pretrained weights are stored.</p> <code>trained_weights_dir</code> <code>str | None</code> <p>The directory where trained weights are stored.</p> <code>config_dir</code> <code>str | None</code> <p>The directory where model configuration files are stored.</p> <code>exported_weights_dir</code> <code>str | None</code> <p>The directory where exported weights are stored.</p> <code>pretrained_weights_path</code> <code>str | None</code> <p>The path to the pretrained weights file.</p> <code>trained_weights_path</code> <code>str | None</code> <p>The path to the trained weights file.</p> <code>config_path</code> <code>str | None</code> <p>The path to the model configuration file.</p> <code>exported_weights_path</code> <code>str | None</code> <p>The path to the exported weights file.</p> <code>loaded_model</code> <code>Any</code> <p>Return the loaded model instance.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(model_version)","title":"<code>model_version</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.loaded_processor","title":"<code>loaded_processor</code>  <code>property</code>","text":"<p>Return the loaded processor instance.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The loaded processor.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the model.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.model_version","title":"<code>model_version = model_version</code>  <code>instance-attribute</code>","text":"<p>The version of the model from Picsellia.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.pretrained_weights_name","title":"<code>pretrained_weights_name = pretrained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the pretrained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.trained_weights_name","title":"<code>trained_weights_name = trained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the trained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.config_name","title":"<code>config_name = config_name</code>  <code>instance-attribute</code>","text":"<p>The name of the configuration file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.exported_weights_name","title":"<code>exported_weights_name = exported_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the exported weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.labelmap","title":"<code>labelmap = labelmap or {}</code>  <code>instance-attribute</code>","text":"<p>A dictionary mapping category names to labels.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.weights_dir","title":"<code>weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model weights are stored.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.results_dir","title":"<code>results_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model results are stored.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.pretrained_weights_dir","title":"<code>pretrained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where pretrained weights are stored.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.trained_weights_dir","title":"<code>trained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where trained weights are stored.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.config_dir","title":"<code>config_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model configuration files are stored.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.exported_weights_dir","title":"<code>exported_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where exported weights are stored.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.pretrained_weights_path","title":"<code>pretrained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the pretrained weights file.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.trained_weights_path","title":"<code>trained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the trained weights file.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.config_path","title":"<code>config_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the model configuration file.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.exported_weights_path","title":"<code>exported_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the exported weights file.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.loaded_model","title":"<code>loaded_model</code>  <code>property</code>","text":"<p>Return the loaded model instance.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.set_loaded_processor","title":"<code>set_loaded_processor(processor)</code>","text":"<p>Set the processor instance after loading it at runtime.</p> <p>Parameters:</p> Name Type Description Default <code>Any</code> <p>The processor instance to attach to the model.</p> required"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.set_loaded_processor(processor)","title":"<code>processor</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.load_weights","title":"<code>load_weights(weights_path, repo_id='openai/clip-vit-large-patch14-336')</code>","text":"<p>Load model weights and processor from the specified path and Hugging Face repository.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Local path to the model weights.</p> required <code>str</code> <p>Identifier of the Hugging Face model to load the processor from.</p> <code>'openai/clip-vit-large-patch14-336'</code> <p>Returns:</p> Type Description <code>tuple[CLIPModel, CLIPProcessor]</code> <p>A tuple containing the CLIP model and its processor, both loaded and ready for inference.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.load_weights(weights_path)","title":"<code>weights_path</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.load_weights(repo_id)","title":"<code>repo_id</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.set_loaded_model","title":"<code>set_loaded_model(model)</code>","text":"<p>Set the runtime-loaded model instance.</p>"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.download_weights","title":"<code>download_weights(destination_dir)</code>","text":"<p>Download all configured model files (weights, config, exports) to destination.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Root directory for downloaded files.</p> required"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.download_weights(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.save_artifact_to_experiment","title":"<code>save_artifact_to_experiment(experiment, artifact_name, artifact_path)</code>","text":"<p>Store an artifact file in the given experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Experiment to store into.</p> required <code>str</code> <p>Name under which to save the artifact.</p> required <code>str</code> <p>Path to the file.</p> required"},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.save_artifact_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.save_artifact_to_experiment(artifact_name)","title":"<code>artifact_name</code>","text":""},{"location":"api/frameworks/clip/model/model/#picsellia_cv_engine.frameworks.clip.model.model.CLIPModel.save_artifact_to_experiment(artifact_path)","title":"<code>artifact_path</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/","title":"frameworks.clip.services.clip_utils","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils","title":"<code>clip_utils</code>","text":"<p>Training a CLIP like dual encoder models using text and vision encoders in the library.</p> <p>The script can be used to train CLIP like models for languages other than English by using a text encoder pre-trained in the desired language. Currently this script supports the following vision and text models: Vision models: ViT(https://huggingface.co/models?filter=vit), CLIP (https://huggingface.co/models?filter=clip) Text models: BERT, ROBERTa (https://huggingface.co/models?filter=fill-mask)</p> <p>Classes:</p> Name Description <code>ModelArguments</code> <p>Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.</p> <code>DataTrainingArguments</code> <p>Arguments pertaining to what data we are going to input our model for training and eval.</p> <p>Functions:</p> Name Description <code>collate_fn</code> <code>parse_args</code> <code>set_logging</code> <code>detect_last_checkpoint</code> <code>load_and_prepare_dataset</code> <code>initialize_model_components</code> <code>resolve_column_names</code> <code>build_transforms</code> <code>prepare_split_dataset</code> <code>preprocess_datasets</code> <code>train_and_evaluate</code> <code>main</code> <p>Attributes:</p> Name Type Description <code>dataset_name_mapping</code>"},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.dataset_name_mapping","title":"<code>dataset_name_mapping = {'image_caption_dataset.py': ('image_path', 'caption')}</code>  <code>module-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments","title":"<code>ModelArguments(model_name_or_path, config_name=None, tokenizer_name=None, feature_extractor_name=None, cache_dir=None, model_revision='main', use_fast_tokenizer=True, use_auth_token=False, freeze_vision_model=False, freeze_text_model=False)</code>  <code>dataclass</code>","text":"<p>Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.</p> <p>Attributes:</p> Name Type Description <code>model_name_or_path</code> <code>str</code> <code>config_name</code> <code>str | None</code> <code>tokenizer_name</code> <code>str | None</code> <code>feature_extractor_name</code> <code>str | None</code> <code>cache_dir</code> <code>str | None</code> <code>model_revision</code> <code>str</code> <code>use_fast_tokenizer</code> <code>bool</code> <code>use_auth_token</code> <code>bool</code> <code>freeze_vision_model</code> <code>bool</code> <code>freeze_text_model</code> <code>bool</code>"},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.model_name_or_path","title":"<code>model_name_or_path = field(metadata={'help': 'Path to pretrained model or model identifier from huggingface.co/models'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.config_name","title":"<code>config_name = field(default=None, metadata={'help': 'Pretrained config name or path if not the same as model_name'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.tokenizer_name","title":"<code>tokenizer_name = field(default=None, metadata={'help': 'Pretrained tokenizer name or path if not the same as model_name'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.feature_extractor_name","title":"<code>feature_extractor_name = field(default=None, metadata={'help': 'Name or path of preprocessor config.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.cache_dir","title":"<code>cache_dir = field(default=None, metadata={'help': 'Where do you want to store the pretrained models downloaded from s3'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.model_revision","title":"<code>model_revision = field(default='main', metadata={'help': 'The specific model version to use (can be a branch name, tag name or commit id).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.use_fast_tokenizer","title":"<code>use_fast_tokenizer = field(default=True, metadata={'help': 'Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.use_auth_token","title":"<code>use_auth_token = field(default=False, metadata={'help': 'Will use the token generated when running `huggingface-cli login` (necessary to use this script with private models).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.freeze_vision_model","title":"<code>freeze_vision_model = field(default=False, metadata={'help': 'Whether to freeze the vision model parameters or not.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.ModelArguments.freeze_text_model","title":"<code>freeze_text_model = field(default=False, metadata={'help': 'Whether to freeze the text model parameters or not.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments","title":"<code>DataTrainingArguments(dataset_name=None, dataset_config_name=None, data_dir=None, image_column='image_path', caption_column='caption', train_file=None, validation_file=None, test_file=None, max_seq_length=128, max_train_samples=None, max_eval_samples=None, overwrite_cache=False, preprocessing_num_workers=None)</code>  <code>dataclass</code>","text":"<p>Arguments pertaining to what data we are going to input our model for training and eval.</p> <p>Attributes:</p> Name Type Description <code>dataset_name</code> <code>str | None</code> <code>dataset_config_name</code> <code>str | None</code> <code>data_dir</code> <code>str | None</code> <code>image_column</code> <code>str | None</code> <code>caption_column</code> <code>str | None</code> <code>train_file</code> <code>str | None</code> <code>validation_file</code> <code>str | None</code> <code>test_file</code> <code>str | None</code> <code>max_seq_length</code> <code>int | None</code> <code>max_train_samples</code> <code>int | None</code> <code>max_eval_samples</code> <code>int | None</code> <code>overwrite_cache</code> <code>bool</code> <code>preprocessing_num_workers</code> <code>int | None</code>"},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.dataset_name","title":"<code>dataset_name = field(default=None, metadata={'help': 'The name of the dataset to use (via the datasets library).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.dataset_config_name","title":"<code>dataset_config_name = field(default=None, metadata={'help': 'The configuration name of the dataset to use (via the datasets library).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.data_dir","title":"<code>data_dir = field(default=None, metadata={'help': 'The data directory containing input files.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.image_column","title":"<code>image_column = field(default='image_path', metadata={'help': 'The name of the column in the datasets containing the full image file paths.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.caption_column","title":"<code>caption_column = field(default='caption', metadata={'help': 'The name of the column in the datasets containing the image captions.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.train_file","title":"<code>train_file = field(default=None, metadata={'help': 'The input training data file (a jsonlines file).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.validation_file","title":"<code>validation_file = field(default=None, metadata={'help': 'An optional input evaluation data file (a jsonlines file).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.test_file","title":"<code>test_file = field(default=None, metadata={'help': 'An optional input test data file (a jsonlines file).'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.max_seq_length","title":"<code>max_seq_length = field(default=128, metadata={'help': 'The maximum total input sequence length after tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.max_train_samples","title":"<code>max_train_samples = field(default=None, metadata={'help': 'For debugging purposes or quicker training, truncate the number of training examples to this value if set.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.max_eval_samples","title":"<code>max_eval_samples = field(default=None, metadata={'help': 'For debugging purposes or quicker training, truncate the number of evaluation examples to this value if set.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.overwrite_cache","title":"<code>overwrite_cache = field(default=False, metadata={'help': 'Overwrite the cached training and evaluation sets'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.DataTrainingArguments.preprocessing_num_workers","title":"<code>preprocessing_num_workers = field(default=None, metadata={'help': 'The number of processes to use for the preprocessing.'})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.collate_fn","title":"<code>collate_fn(examples)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.parse_args","title":"<code>parse_args()</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.set_logging","title":"<code>set_logging(training_args)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.detect_last_checkpoint","title":"<code>detect_last_checkpoint(training_args)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.load_and_prepare_dataset","title":"<code>load_and_prepare_dataset(model_args, data_args, training_args)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.initialize_model_components","title":"<code>initialize_model_components(model_args)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.resolve_column_names","title":"<code>resolve_column_names(data_args, column_names)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.build_transforms","title":"<code>build_transforms(config, feature_extractor)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.prepare_split_dataset","title":"<code>prepare_split_dataset(dataset, split, args, tokenizer, transform, image_column, caption_column, column_names)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.preprocess_datasets","title":"<code>preprocess_datasets(dataset, data_args, training_args, tokenizer, feature_extractor, image_column, caption_column, column_names, config)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.train_and_evaluate","title":"<code>train_and_evaluate(trainer, training_args, last_checkpoint, model_args, data_args)</code>","text":""},{"location":"api/frameworks/clip/services/clip_utils/#picsellia_cv_engine.frameworks.clip.services.clip_utils.main","title":"<code>main()</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/","title":"frameworks.clip.services.evaluator","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator","title":"<code>evaluator</code>","text":"<p>Functions:</p> Name Description <code>run_umap_dbscan_clustering</code> <p>Run UMAP dimensionality reduction followed by DBSCAN clustering with automatic eps search.</p> <code>save_clustering_visualizations</code> <p>Save clustering plots, cluster image grids, and outlier grids. Optionally logs them to an experiment.</p> <code>generate_embeddings_from_results</code> <p>Combine image paths and embeddings from batched inference results.</p> <code>load_stored_embeddings</code> <p>Load stored embeddings and image paths from a .npz file.</p> <code>reduce_dimensionality_umap</code> <p>Reduce embedding dimensionality using UMAP.</p> <code>apply_dbscan_clustering</code> <p>Apply DBSCAN clustering on embeddings.</p> <code>save_clustering_plots</code> <p>Save annotated DBSCAN clustering plot.</p> <code>save_cluster_images_plot</code> <p>Save a grid of images for each cluster.</p> <code>save_outliers_images</code> <p>Save a grid of images classified as outliers.</p> <code>find_best_eps</code> <p>Find the best epsilon value for DBSCAN using silhouette score.</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.run_umap_dbscan_clustering","title":"<code>run_umap_dbscan_clustering(embeddings, min_samples=5, initial_eps_list=None, fallback_eps_list=None, default_eps=0.3)</code>","text":"<p>Run UMAP dimensionality reduction followed by DBSCAN clustering with automatic eps search.</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations","title":"<code>save_clustering_visualizations(reduced_embeddings, cluster_labels, image_paths, results_dir, log_images=True, experiment=None)</code>","text":"<p>Save clustering plots, cluster image grids, and outlier grids. Optionally logs them to an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>UMAP-reduced 2D embeddings.</p> required <code>ndarray</code> <p>DBSCAN-assigned cluster labels.</p> required <code>list[str]</code> <p>Corresponding image file paths.</p> required <code>str</code> <p>Output directory for saved plots.</p> required <code>bool</code> <p>Whether to log images via experiment.</p> <code>True</code> <code>Experiment | None</code> <p>Experiment if logging is enabled.</p> <code>None</code>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations(reduced_embeddings)","title":"<code>reduced_embeddings</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations(cluster_labels)","title":"<code>cluster_labels</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations(image_paths)","title":"<code>image_paths</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations(results_dir)","title":"<code>results_dir</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations(log_images)","title":"<code>log_images</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_visualizations(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.generate_embeddings_from_results","title":"<code>generate_embeddings_from_results(image_batches, batch_results)</code>","text":"<p>Combine image paths and embeddings from batched inference results.</p> <p>Parameters:</p> Name Type Description Default <code>Sequence[list[str]]</code> <p>List of image path batches.</p> required <code>Sequence[list[dict[str, Any]]]</code> <p>List of inference result batches.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, list[str]]</code> <p>A tuple of (embeddings array, image path list).</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.generate_embeddings_from_results(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.generate_embeddings_from_results(batch_results)","title":"<code>batch_results</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.load_stored_embeddings","title":"<code>load_stored_embeddings(file_path)</code>","text":"<p>Load stored embeddings and image paths from a .npz file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the .npz file.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, list[str]]</code> <p>Tuple of (embeddings array, image paths).</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.load_stored_embeddings(file_path)","title":"<code>file_path</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.reduce_dimensionality_umap","title":"<code>reduce_dimensionality_umap(embeddings, n_components)</code>","text":"<p>Reduce embedding dimensionality using UMAP.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>High-dimensional embeddings.</p> required <code>int</code> <p>Target number of dimensions.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>UMAP-reduced embeddings.</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.reduce_dimensionality_umap(embeddings)","title":"<code>embeddings</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.reduce_dimensionality_umap(n_components)","title":"<code>n_components</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.apply_dbscan_clustering","title":"<code>apply_dbscan_clustering(embeddings, dbscan_eps, dbscan_min_samples)</code>","text":"<p>Apply DBSCAN clustering on embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>2D array of points to cluster.</p> required <code>float</code> <p>Epsilon parameter for DBSCAN.</p> required <code>int</code> <p>Minimum samples per cluster.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of cluster labels.</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.apply_dbscan_clustering(embeddings)","title":"<code>embeddings</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.apply_dbscan_clustering(dbscan_eps)","title":"<code>dbscan_eps</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.apply_dbscan_clustering(dbscan_min_samples)","title":"<code>dbscan_min_samples</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_plots","title":"<code>save_clustering_plots(reduced_embeddings, cluster_labels, results_dir)</code>","text":"<p>Save annotated DBSCAN clustering plot.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>2D UMAP-reduced embeddings.</p> required <code>ndarray</code> <p>Cluster labels for each point.</p> required <code>str</code> <p>Directory to save the plot.</p> required"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_plots(reduced_embeddings)","title":"<code>reduced_embeddings</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_plots(cluster_labels)","title":"<code>cluster_labels</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_clustering_plots(results_dir)","title":"<code>results_dir</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_cluster_images_plot","title":"<code>save_cluster_images_plot(image_paths, cluster_labels, results_dir, max_images_per_cluster=25, grid_size=(5, 5))</code>","text":"<p>Save a grid of images for each cluster.</p> <p>Parameters:</p> Name Type Description Default <code>list[str]</code> <p>List of image file paths.</p> required <code>ndarray</code> <p>Cluster label for each image.</p> required <code>str</code> <p>Directory to save plots.</p> required <code>int</code> <p>Maximum number of images per plot.</p> <code>25</code> <code>tuple[int, int]</code> <p>Size of the plot grid (rows, cols).</p> <code>(5, 5)</code>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_cluster_images_plot(image_paths)","title":"<code>image_paths</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_cluster_images_plot(cluster_labels)","title":"<code>cluster_labels</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_cluster_images_plot(results_dir)","title":"<code>results_dir</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_cluster_images_plot(max_images_per_cluster)","title":"<code>max_images_per_cluster</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_cluster_images_plot(grid_size)","title":"<code>grid_size</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_outliers_images","title":"<code>save_outliers_images(image_paths, cluster_labels, results_dir, max_images=25, grid_size=(5, 5))</code>","text":"<p>Save a grid of images classified as outliers.</p> <p>Parameters:</p> Name Type Description Default <code>list[str]</code> <p>List of image file paths.</p> required <code>ndarray</code> <p>Cluster label for each image.</p> required <code>str</code> <p>Directory to save the output.</p> required <code>int</code> <p>Maximum number of outlier images to display.</p> <code>25</code> <code>tuple[int, int]</code> <p>Size of the output grid (rows, cols).</p> <code>(5, 5)</code>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_outliers_images(image_paths)","title":"<code>image_paths</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_outliers_images(cluster_labels)","title":"<code>cluster_labels</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_outliers_images(results_dir)","title":"<code>results_dir</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_outliers_images(max_images)","title":"<code>max_images</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.save_outliers_images(grid_size)","title":"<code>grid_size</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.find_best_eps","title":"<code>find_best_eps(reduced, eps_list)</code>","text":"<p>Find the best epsilon value for DBSCAN using silhouette score.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>2D array of reduced embeddings.</p> required <code>list[float]</code> <p>List of candidate epsilon values.</p> required <p>Returns:</p> Type Description <code>float | None</code> <p>The epsilon value with the highest silhouette score.</p>"},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.find_best_eps(reduced)","title":"<code>reduced</code>","text":""},{"location":"api/frameworks/clip/services/evaluator/#picsellia_cv_engine.frameworks.clip.services.evaluator.find_best_eps(eps_list)","title":"<code>eps_list</code>","text":""},{"location":"api/frameworks/clip/services/predictor/","title":"frameworks.clip.services.predictor","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor","title":"<code>predictor</code>","text":"<p>Classes:</p> Name Description <code>PicselliaCLIPEmbeddingPrediction</code> <p>Dataclass representing a CLIP prediction for an image,</p> <code>CLIPModelPredictor</code> <p>Predictor class for CLIP-based inference on image and text data.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.PicselliaCLIPEmbeddingPrediction","title":"<code>PicselliaCLIPEmbeddingPrediction(asset, image_embedding, text_embedding)</code>  <code>dataclass</code>","text":"<p>Dataclass representing a CLIP prediction for an image, optionally including a text embedding.</p> <p>Attributes:</p> Name Type Description <code>asset</code> <code>Asset</code> <code>image_embedding</code> <code>list[float]</code> <code>text_embedding</code> <code>list[float]</code>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.PicselliaCLIPEmbeddingPrediction.asset","title":"<code>asset</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.PicselliaCLIPEmbeddingPrediction.image_embedding","title":"<code>image_embedding</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.PicselliaCLIPEmbeddingPrediction.text_embedding","title":"<code>text_embedding</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor","title":"<code>CLIPModelPredictor(model, device)</code>","text":"<p>               Bases: <code>ModelPredictor</code></p> <p>Predictor class for CLIP-based inference on image and text data.</p> <p>Parameters:</p> Name Type Description Default <code>CLIPModel</code> <p>The CLIP model instance.</p> required <code>str</code> <p>Target device (\"cuda\" or \"cpu\").</p> required <p>Methods:</p> Name Description <code>embed_image</code> <p>Encode an image into a CLIP embedding.</p> <code>embed_text</code> <p>Encode a text string into a CLIP embedding.</p> <code>run_image_inference_on_batches</code> <p>Perform inference on batches of images.</p> <code>run_inference_on_batches</code> <p>Perform inference on batches of image-text pairs.</p> <code>post_process_batches</code> <p>Convert image-text batch results into Picsellia prediction objects.</p> <code>post_process_image_batches</code> <p>Convert image-only batch results into Picsellia prediction objects.</p> <code>pre_process_dataset</code> <p>Extracts all image paths from the dataset's image directory.</p> <code>prepare_batches</code> <code>get_picsellia_label</code> <p>Get or create a PicselliaLabel from a dataset category name.</p> <code>get_picsellia_confidence</code> <p>Wrap a confidence score in a PicselliaConfidence object.</p> <code>get_picsellia_rectangle</code> <p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>device</code>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor(device)","title":"<code>device</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.device","title":"<code>device = device</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.embed_image","title":"<code>embed_image(image_path)</code>","text":"<p>Encode an image into a CLIP embedding.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the input image.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>A list of float values representing the image embedding.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.embed_image(image_path)","title":"<code>image_path</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.embed_text","title":"<code>embed_text(text)</code>","text":"<p>Encode a text string into a CLIP embedding.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Input text string.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>A list of float values representing the text embedding.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.embed_text(text)","title":"<code>text</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.run_image_inference_on_batches","title":"<code>run_image_inference_on_batches(image_batches)</code>","text":"<p>Perform inference on batches of images.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>List of batches, each batch is a list of image paths.</p> required <p>Returns:</p> Type Description <code>list[list[dict]]</code> <p>Nested list of dictionaries containing image embeddings.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.run_image_inference_on_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.run_inference_on_batches","title":"<code>run_inference_on_batches(image_text_batches)</code>","text":"<p>Perform inference on batches of image-text pairs.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[tuple[str, str]]]</code> <p>List of batches containing (image_path, text) tuples.</p> required <p>Returns:</p> Type Description <code>list[list[dict]]</code> <p>Nested list of dictionaries with image and text embeddings.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.run_inference_on_batches(image_text_batches)","title":"<code>image_text_batches</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_batches","title":"<code>post_process_batches(image_text_batches, batch_results, dataset)</code>","text":"<p>Convert image-text batch results into Picsellia prediction objects.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[tuple[str, str]]]</code> <p>Input image-text batches.</p> required <code>list[list[dict]]</code> <p>Corresponding results from inference.</p> required <code>TBaseDataset</code> <p>Dataset object to resolve asset references.</p> required <p>Returns:</p> Type Description <code>list[PicselliaCLIPEmbeddingPrediction]</code> <p>List of PicselliaCLIPEmbeddingPrediction.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_batches(image_text_batches)","title":"<code>image_text_batches</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_batches(batch_results)","title":"<code>batch_results</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_batches(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_image_batches","title":"<code>post_process_image_batches(image_batches, batch_results, dataset)</code>","text":"<p>Convert image-only batch results into Picsellia prediction objects.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>List of image batches.</p> required <code>list[list[dict]]</code> <p>Corresponding image-only inference results.</p> required <code>TBaseDataset</code> <p>Dataset object to resolve asset references.</p> required <p>Returns:</p> Type Description <code>list[PicselliaCLIPEmbeddingPrediction]</code> <p>List of PicselliaCLIPEmbeddingPrediction with empty text embeddings.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_image_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_image_batches(batch_results)","title":"<code>batch_results</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.post_process_image_batches(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Extracts all image paths from the dataset's image directory.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset object containing the image directory.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of file paths to the dataset images.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.prepare_batches","title":"<code>prepare_batches(image_paths, batch_size)</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_label","title":"<code>get_picsellia_label(category_name, dataset)</code>","text":"<p>Get or create a PicselliaLabel from a dataset category name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the label category.</p> required <code>TBaseDataset</code> <p>Dataset that provides label access.</p> required <p>Returns:</p> Name Type Description <code>PicselliaLabel</code> <code>PicselliaLabel</code> <p>Wrapped label object.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_label(category_name)","title":"<code>category_name</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_label(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_confidence","title":"<code>get_picsellia_confidence(confidence)</code>","text":"<p>Wrap a confidence score in a PicselliaConfidence object.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Prediction confidence score.</p> required <p>Returns:</p> Name Type Description <code>PicselliaConfidence</code> <code>PicselliaConfidence</code> <p>Wrapped confidence object.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_confidence(confidence)","title":"<code>confidence</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_rectangle","title":"<code>get_picsellia_rectangle(x, y, w, h)</code>","text":"<p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Top-left x-coordinate.</p> required <code>int</code> <p>Top-left y-coordinate.</p> required <code>int</code> <p>Width of the box.</p> required <code>int</code> <p>Height of the box.</p> required <p>Returns:</p> Name Type Description <code>PicselliaRectangle</code> <code>PicselliaRectangle</code> <p>Rectangle wrapper for object detection.</p>"},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_rectangle(x)","title":"<code>x</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_rectangle(y)","title":"<code>y</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_rectangle(w)","title":"<code>w</code>","text":""},{"location":"api/frameworks/clip/services/predictor/#picsellia_cv_engine.frameworks.clip.services.predictor.CLIPModelPredictor.get_picsellia_rectangle(h)","title":"<code>h</code>","text":""},{"location":"api/frameworks/clip/services/trainer/","title":"frameworks.clip.services.trainer","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer","title":"<code>trainer</code>","text":"<p>Classes:</p> Name Description <code>ClipModelTrainer</code> <p>CLIP model trainer using BLIP-generated captions for fine-tuning.</p> <p>Functions:</p> Name Description <code>prepare_caption_model</code> <p>Load the BLIP processor and model for caption generation.</p> <code>generate_caption</code> <p>Generate a caption from an image using BLIP.</p> <code>export_dataset_to_clip_json</code> <p>Convert a COCO-format dataset to a JSONL file for CLIP training.</p> <code>build_clip_command</code> <p>Build CLI command for CLIP training.</p> <code>parse_and_log_training_output</code> <p>Parse stdout of subprocess and log relevant training metrics.</p> <code>run_clip_training</code> <p>Run CLIP training with provided hyperparameters and log the output.</p>"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer","title":"<code>ClipModelTrainer(model, context)</code>","text":"<p>CLIP model trainer using BLIP-generated captions for fine-tuning.</p> <p>Parameters:</p> Name Type Description Default <code>CLIPModel</code> <p>The Picsellia model wrapper.</p> required <code>PicselliaTrainingContext | LocalTrainingContext</code> <p>Training context containing experiment, paths, and hyperparameters.</p> required <p>Methods:</p> Name Description <code>train_model</code> <p>Run the full CLIP fine-tuning process using BLIP captions.</p> <code>save_best_checkpoint</code> <p>Save the best checkpoint by selecting the latest one.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>context</code> <code>model_dir</code> <code>run_script_path</code>"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer(context)","title":"<code>context</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.context","title":"<code>context = context</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.model_dir","title":"<code>model_dir = os.path.join(model.results_dir, 'clip_finetuned')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.run_script_path","title":"<code>run_script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'clip_utils.py')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.train_model","title":"<code>train_model(dataset_collection)</code>","text":"<p>Run the full CLIP fine-tuning process using BLIP captions.</p> <p>Parameters:</p> Name Type Description Default <code>DatasetCollection</code> <p>Collection with train, validation, and test datasets.</p> required <p>Returns:</p> Type Description <code>CLIPModel</code> <p>The trained model with exported weights set.</p>"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.train_model(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.save_best_checkpoint","title":"<code>save_best_checkpoint(output_dir, context)</code>","text":"<p>Save the best checkpoint by selecting the latest one.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Directory where checkpoints are stored.</p> required <code>PicselliaTrainingContext | LocalTrainingContext</code> <p>Training context for logging.</p> required"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.save_best_checkpoint(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.ClipModelTrainer.save_best_checkpoint(context)","title":"<code>context</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.prepare_caption_model","title":"<code>prepare_caption_model()</code>","text":"<p>Load the BLIP processor and model for caption generation.</p> <p>Returns:</p> Type Description <code>tuple[PreTrainedModel, PreTrainedTokenizer]</code> <p>A tuple containing the model and processor.</p>"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.generate_caption","title":"<code>generate_caption(model, processor, image_path, prompt, device)</code>","text":"<p>Generate a caption from an image using BLIP.</p> <p>Parameters:</p> Name Type Description Default <code>PreTrainedModel</code> <p>Captioning model.</p> required <code>PreTrainedTokenizer</code> <p>Processor for BLIP input formatting.</p> required <code>str</code> <p>Path to the image.</p> required <code>str</code> <p>Prompt to guide the captioning.</p> required <code>str</code> <p>Target device.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string caption.</p>"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.generate_caption(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.generate_caption(processor)","title":"<code>processor</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.generate_caption(image_path)","title":"<code>image_path</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.generate_caption(prompt)","title":"<code>prompt</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.generate_caption(device)","title":"<code>device</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json","title":"<code>export_dataset_to_clip_json(model, processor, dataset, output_path, device, prompt)</code>","text":"<p>Convert a COCO-format dataset to a JSONL file for CLIP training.</p> <p>Parameters:</p> Name Type Description Default <code>PreTrainedModel</code> <p>Captioning model.</p> required <code>PreTrainedTokenizer</code> <p>Processor for image and prompt.</p> required <code>CocoDataset</code> <p>Dataset to process.</p> required <code>str</code> <p>Where to save the JSONL file.</p> required <code>str</code> <p>Target device.</p> required <code>str</code> <p>Prompt to use for all captions.</p> required"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json(processor)","title":"<code>processor</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json(output_path)","title":"<code>output_path</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json(device)","title":"<code>device</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.export_dataset_to_clip_json(prompt)","title":"<code>prompt</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.build_clip_command","title":"<code>build_clip_command(model_name_or_path, script_path, output_dir, train_file, val_file, test_file, epochs, batch_size, learning_rate, warmup_steps, weight_decay)</code>","text":"<p>Build CLI command for CLIP training.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of command-line arguments.</p>"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.parse_and_log_training_output","title":"<code>parse_and_log_training_output(process, context, log_file_path)</code>","text":"<p>Parse stdout of subprocess and log relevant training metrics.</p> <p>Parameters:</p> Name Type Description Default <code>Popen[str]</code> <p>Running training process.</p> required <code>PicselliaTrainingContext | LocalTrainingContext</code> <p>Training context to log metrics.</p> required <code>str</code> <p>Path to write full logs.</p> required"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.parse_and_log_training_output(process)","title":"<code>process</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.parse_and_log_training_output(context)","title":"<code>context</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.parse_and_log_training_output(log_file_path)","title":"<code>log_file_path</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training","title":"<code>run_clip_training(run_script_path, output_dir, train_json, val_json, test_json, batch_size, epochs, context)</code>","text":"<p>Run CLIP training with provided hyperparameters and log the output.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to training script.</p> required <code>str</code> <p>Output directory for results.</p> required <code>str</code> <p>Path to training JSON file.</p> required <code>str</code> <p>Path to validation JSON file.</p> required <code>str</code> <p>Path to test JSON file.</p> required <code>int</code> <p>Batch size for training.</p> required <code>int</code> <p>Number of training epochs.</p> required <code>PicselliaTrainingContext | LocalTrainingContext</code> <p>Context holding hyperparameters and experiment.</p> required"},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(run_script_path)","title":"<code>run_script_path</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(train_json)","title":"<code>train_json</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(val_json)","title":"<code>val_json</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(test_json)","title":"<code>test_json</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(batch_size)","title":"<code>batch_size</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(epochs)","title":"<code>epochs</code>","text":""},{"location":"api/frameworks/clip/services/trainer/#picsellia_cv_engine.frameworks.clip.services.trainer.run_clip_training(context)","title":"<code>context</code>","text":""},{"location":"api/frameworks/grounding_dino/model/model/","title":"frameworks.grounding_dino.model.model","text":""},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model","title":"<code>model</code>","text":"<p>Classes:</p> Name Description <code>GroundingDinoModel</code>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel","title":"<code>GroundingDinoModel(name, model_version=None, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None, labelmap=None)</code>","text":"<p>               Bases: <code>Model</code></p> <p>Methods:</p> Name Description <code>load_weights</code> <code>set_loaded_model</code> <p>Set the runtime-loaded model instance.</p> <code>download_weights</code> <p>Download all configured model files (weights, config, exports) to destination.</p> <code>save_artifact_to_experiment</code> <p>Store an artifact file in the given experiment.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>The name of the model.</p> <code>model_version</code> <p>The version of the model from Picsellia.</p> <code>pretrained_weights_name</code> <p>The name of the pretrained weights file attached to the model version in Picsellia.</p> <code>trained_weights_name</code> <p>The name of the trained weights file attached to the model version in Picsellia.</p> <code>config_name</code> <p>The name of the configuration file attached to the model version in Picsellia.</p> <code>exported_weights_name</code> <p>The name of the exported weights file attached to the model version in Picsellia.</p> <code>labelmap</code> <p>A dictionary mapping category names to labels.</p> <code>weights_dir</code> <code>str | None</code> <p>The directory where model weights are stored.</p> <code>results_dir</code> <code>str | None</code> <p>The directory where model results are stored.</p> <code>pretrained_weights_dir</code> <code>str | None</code> <p>The directory where pretrained weights are stored.</p> <code>trained_weights_dir</code> <code>str | None</code> <p>The directory where trained weights are stored.</p> <code>config_dir</code> <code>str | None</code> <p>The directory where model configuration files are stored.</p> <code>exported_weights_dir</code> <code>str | None</code> <p>The directory where exported weights are stored.</p> <code>pretrained_weights_path</code> <code>str | None</code> <p>The path to the pretrained weights file.</p> <code>trained_weights_path</code> <code>str | None</code> <p>The path to the trained weights file.</p> <code>config_path</code> <code>str | None</code> <p>The path to the model configuration file.</p> <code>exported_weights_path</code> <code>str | None</code> <p>The path to the exported weights file.</p> <code>loaded_model</code> <code>Any</code> <p>Return the loaded model instance.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the model.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.model_version","title":"<code>model_version = model_version</code>  <code>instance-attribute</code>","text":"<p>The version of the model from Picsellia.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.pretrained_weights_name","title":"<code>pretrained_weights_name = pretrained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the pretrained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.trained_weights_name","title":"<code>trained_weights_name = trained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the trained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.config_name","title":"<code>config_name = config_name</code>  <code>instance-attribute</code>","text":"<p>The name of the configuration file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.exported_weights_name","title":"<code>exported_weights_name = exported_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the exported weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.labelmap","title":"<code>labelmap = labelmap or {}</code>  <code>instance-attribute</code>","text":"<p>A dictionary mapping category names to labels.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.weights_dir","title":"<code>weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model weights are stored.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.results_dir","title":"<code>results_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model results are stored.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.pretrained_weights_dir","title":"<code>pretrained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where pretrained weights are stored.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.trained_weights_dir","title":"<code>trained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where trained weights are stored.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.config_dir","title":"<code>config_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model configuration files are stored.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.exported_weights_dir","title":"<code>exported_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where exported weights are stored.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.pretrained_weights_path","title":"<code>pretrained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the pretrained weights file.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.trained_weights_path","title":"<code>trained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the trained weights file.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.config_path","title":"<code>config_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the model configuration file.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.exported_weights_path","title":"<code>exported_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the exported weights file.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.loaded_model","title":"<code>loaded_model</code>  <code>property</code>","text":"<p>Return the loaded model instance.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.load_weights","title":"<code>load_weights(weights_path, config_path)</code>","text":""},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.set_loaded_model","title":"<code>set_loaded_model(model)</code>","text":"<p>Set the runtime-loaded model instance.</p>"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.download_weights","title":"<code>download_weights(destination_dir)</code>","text":"<p>Download all configured model files (weights, config, exports) to destination.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Root directory for downloaded files.</p> required"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.download_weights(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.save_artifact_to_experiment","title":"<code>save_artifact_to_experiment(experiment, artifact_name, artifact_path)</code>","text":"<p>Store an artifact file in the given experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Experiment to store into.</p> required <code>str</code> <p>Name under which to save the artifact.</p> required <code>str</code> <p>Path to the file.</p> required"},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.save_artifact_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.save_artifact_to_experiment(artifact_name)","title":"<code>artifact_name</code>","text":""},{"location":"api/frameworks/grounding_dino/model/model/#picsellia_cv_engine.frameworks.grounding_dino.model.model.GroundingDinoModel.save_artifact_to_experiment(artifact_path)","title":"<code>artifact_path</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/","title":"frameworks.grounding_dino.services.predictor","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor","title":"<code>predictor</code>","text":"<p>Classes:</p> Name Description <code>GroundingDinoDetectionModelPredictor</code> <p>A predictor class to run GroundingDINO inference for object detection.</p>"},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor","title":"<code>GroundingDinoDetectionModelPredictor(model, label_names, box_threshold=0.5, text_threshold=0.5)</code>","text":"<p>               Bases: <code>ModelPredictor</code></p> <p>A predictor class to run GroundingDINO inference for object detection. Converts results into PicselliaRectanglePrediction objects.</p> <p>Parameters:</p> Name Type Description Default <code>GroundingDinoModel</code> <p>Loaded GroundingDINO model.</p> required <code>list[str]</code> <p>list of class names to detect.</p> required <p>Methods:</p> Name Description <code>run_inference_on_batches</code> <code>post_process_batches</code> <code>pre_process_dataset</code> <p>Extracts all image paths from the dataset's image directory.</p> <code>prepare_batches</code> <code>get_picsellia_label</code> <p>Get or create a PicselliaLabel from a dataset category name.</p> <code>get_picsellia_confidence</code> <p>Wrap a confidence score in a PicselliaConfidence object.</p> <code>get_picsellia_rectangle</code> <p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>label_names</code> <code>box_threshold</code> <code>text_threshold</code>"},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor(label_names)","title":"<code>label_names</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.label_names","title":"<code>label_names = label_names</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.box_threshold","title":"<code>box_threshold = box_threshold</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.text_threshold","title":"<code>text_threshold = text_threshold</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.run_inference_on_batches","title":"<code>run_inference_on_batches(image_batches)</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.post_process_batches","title":"<code>post_process_batches(image_batches, batch_results, dataset)</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Extracts all image paths from the dataset's image directory.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset object containing the image directory.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of file paths to the dataset images.</p>"},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.prepare_batches","title":"<code>prepare_batches(image_paths, batch_size)</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_label","title":"<code>get_picsellia_label(category_name, dataset)</code>","text":"<p>Get or create a PicselliaLabel from a dataset category name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the label category.</p> required <code>TBaseDataset</code> <p>Dataset that provides label access.</p> required <p>Returns:</p> Name Type Description <code>PicselliaLabel</code> <code>PicselliaLabel</code> <p>Wrapped label object.</p>"},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_label(category_name)","title":"<code>category_name</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_label(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_confidence","title":"<code>get_picsellia_confidence(confidence)</code>","text":"<p>Wrap a confidence score in a PicselliaConfidence object.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Prediction confidence score.</p> required <p>Returns:</p> Name Type Description <code>PicselliaConfidence</code> <code>PicselliaConfidence</code> <p>Wrapped confidence object.</p>"},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_confidence(confidence)","title":"<code>confidence</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_rectangle","title":"<code>get_picsellia_rectangle(x, y, w, h)</code>","text":"<p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Top-left x-coordinate.</p> required <code>int</code> <p>Top-left y-coordinate.</p> required <code>int</code> <p>Width of the box.</p> required <code>int</code> <p>Height of the box.</p> required <p>Returns:</p> Name Type Description <code>PicselliaRectangle</code> <code>PicselliaRectangle</code> <p>Rectangle wrapper for object detection.</p>"},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_rectangle(x)","title":"<code>x</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_rectangle(y)","title":"<code>y</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_rectangle(w)","title":"<code>w</code>","text":""},{"location":"api/frameworks/grounding_dino/services/predictor/#picsellia_cv_engine.frameworks.grounding_dino.services.predictor.GroundingDinoDetectionModelPredictor.get_picsellia_rectangle(h)","title":"<code>h</code>","text":""},{"location":"api/frameworks/sam2/model/model/","title":"frameworks.sam2.model.model","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model","title":"<code>model</code>","text":"<p>Classes:</p> Name Description <code>SAM2Model</code> <p>SAM2 model wrapper for managing weight loading, mask generation, and runtime configuration.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model","title":"<code>SAM2Model(name, model_version=None, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None, labelmap=None)</code>","text":"<p>               Bases: <code>Model</code></p> <p>SAM2 model wrapper for managing weight loading, mask generation, and runtime configuration.</p> <p>This class encapsulates the logic for working with SAM2 fine-tuning and inference within the Picsellia CV engine. It provides utilities to load a trained model from local files and attach a <code>SAM2AutomaticMaskGenerator</code> for downstream predictions.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the model.</p> required <code>ModelVersion</code> <p>Associated Picsellia model version.</p> <code>None</code> <code>str | None</code> <p>Optional name of the pretrained weights file.</p> <code>None</code> <code>str | None</code> <p>Optional name of the fine-tuned weights file.</p> <code>None</code> <code>str | None</code> <p>Optional name of the SAM2 configuration file.</p> <code>None</code> <code>str | None</code> <p>Optional name for exported weights (e.g., ONNX).</p> <code>None</code> <code>dict[str, Label] | None</code> <p>Optional label mapping for the dataset.</p> <code>None</code> <p>Methods:</p> Name Description <code>set_loaded_predictor</code> <p>Attach a loaded SAM2ImagePredictor instance to the model.</p> <code>load_weights</code> <p>Load a SAM2 model and its mask generator from disk.</p> <code>predict</code> <p>Run prediction on an image with given input points and labels.</p> <code>set_loaded_model</code> <p>Set the runtime-loaded model instance.</p> <code>download_weights</code> <p>Download all configured model files (weights, config, exports) to destination.</p> <code>save_artifact_to_experiment</code> <p>Store an artifact file in the given experiment.</p> <p>Attributes:</p> Name Type Description <code>loaded_predictor</code> <code>Any</code> <p>Return the loaded SAM2ImagePredictor instance.</p> <code>name</code> <p>The name of the model.</p> <code>model_version</code> <p>The version of the model from Picsellia.</p> <code>pretrained_weights_name</code> <p>The name of the pretrained weights file attached to the model version in Picsellia.</p> <code>trained_weights_name</code> <p>The name of the trained weights file attached to the model version in Picsellia.</p> <code>config_name</code> <p>The name of the configuration file attached to the model version in Picsellia.</p> <code>exported_weights_name</code> <p>The name of the exported weights file attached to the model version in Picsellia.</p> <code>labelmap</code> <p>A dictionary mapping category names to labels.</p> <code>weights_dir</code> <code>str | None</code> <p>The directory where model weights are stored.</p> <code>results_dir</code> <code>str | None</code> <p>The directory where model results are stored.</p> <code>pretrained_weights_dir</code> <code>str | None</code> <p>The directory where pretrained weights are stored.</p> <code>trained_weights_dir</code> <code>str | None</code> <p>The directory where trained weights are stored.</p> <code>config_dir</code> <code>str | None</code> <p>The directory where model configuration files are stored.</p> <code>exported_weights_dir</code> <code>str | None</code> <p>The directory where exported weights are stored.</p> <code>pretrained_weights_path</code> <code>str | None</code> <p>The path to the pretrained weights file.</p> <code>trained_weights_path</code> <code>str | None</code> <p>The path to the trained weights file.</p> <code>config_path</code> <code>str | None</code> <p>The path to the model configuration file.</p> <code>exported_weights_path</code> <code>str | None</code> <p>The path to the exported weights file.</p> <code>loaded_model</code> <code>Any</code> <p>Return the loaded model instance.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(model_version)","title":"<code>model_version</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.loaded_predictor","title":"<code>loaded_predictor</code>  <code>property</code>","text":"<p>Return the loaded SAM2ImagePredictor instance.</p> <p>Returns:</p> Name Type Description <code>SAM2ImagePredictor</code> <code>Any</code> <p>The initialized predictor for mask predictions.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the model.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.model_version","title":"<code>model_version = model_version</code>  <code>instance-attribute</code>","text":"<p>The version of the model from Picsellia.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.pretrained_weights_name","title":"<code>pretrained_weights_name = pretrained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the pretrained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.trained_weights_name","title":"<code>trained_weights_name = trained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the trained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.config_name","title":"<code>config_name = config_name</code>  <code>instance-attribute</code>","text":"<p>The name of the configuration file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.exported_weights_name","title":"<code>exported_weights_name = exported_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the exported weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.labelmap","title":"<code>labelmap = labelmap or {}</code>  <code>instance-attribute</code>","text":"<p>A dictionary mapping category names to labels.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.weights_dir","title":"<code>weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model weights are stored.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.results_dir","title":"<code>results_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model results are stored.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.pretrained_weights_dir","title":"<code>pretrained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where pretrained weights are stored.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.trained_weights_dir","title":"<code>trained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where trained weights are stored.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.config_dir","title":"<code>config_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model configuration files are stored.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.exported_weights_dir","title":"<code>exported_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where exported weights are stored.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.pretrained_weights_path","title":"<code>pretrained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the pretrained weights file.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.trained_weights_path","title":"<code>trained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the trained weights file.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.config_path","title":"<code>config_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the model configuration file.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.exported_weights_path","title":"<code>exported_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the exported weights file.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.loaded_model","title":"<code>loaded_model</code>  <code>property</code>","text":"<p>Return the loaded model instance.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.set_loaded_predictor","title":"<code>set_loaded_predictor(predictor)</code>","text":"<p>Attach a loaded SAM2ImagePredictor instance to the model.</p> <p>Parameters:</p> Name Type Description Default <code>Any</code> <p>The predictor instance to attach.</p> required"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.set_loaded_predictor(predictor)","title":"<code>predictor</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.load_weights","title":"<code>load_weights(weights_path, config_path, device)</code>","text":"<p>Load a SAM2 model and its mask generator from disk.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the model's trained checkpoint.</p> required <code>str</code> <p>Path to the model's YAML config file.</p> required <code>str</code> <p>Target device for inference, e.g., \"cuda\" or \"cpu\".</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[SAM2Base, SAM2ImagePredictor]</code> <p>A tuple of (SAM2 model, SAM2ImagePredictor).</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.load_weights(weights_path)","title":"<code>weights_path</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.load_weights(config_path)","title":"<code>config_path</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.load_weights(device)","title":"<code>device</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.predict","title":"<code>predict(image, input_points, input_labels, multimask_output=True)</code>","text":"<p>Run prediction on an image with given input points and labels.</p> <p>Parameters:</p> Name Type Description Default <code>Image</code> <p>The PIL image to segment.</p> required <code>list[tuple[int, int]]</code> <p>Coordinates of user-provided points.</p> required <code>list[int]</code> <p>Labels for each point (1: foreground, 0: background).</p> required <code>bool</code> <p>Whether to return multiple mask hypotheses.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict]: Each dict contains: - \"polygon\": List of (x, y) coordinates - \"score\": IoU score associated with the mask</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.predict(image)","title":"<code>image</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.predict(input_points)","title":"<code>input_points</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.predict(input_labels)","title":"<code>input_labels</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.predict(multimask_output)","title":"<code>multimask_output</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.set_loaded_model","title":"<code>set_loaded_model(model)</code>","text":"<p>Set the runtime-loaded model instance.</p>"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.download_weights","title":"<code>download_weights(destination_dir)</code>","text":"<p>Download all configured model files (weights, config, exports) to destination.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Root directory for downloaded files.</p> required"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.download_weights(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.save_artifact_to_experiment","title":"<code>save_artifact_to_experiment(experiment, artifact_name, artifact_path)</code>","text":"<p>Store an artifact file in the given experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Experiment to store into.</p> required <code>str</code> <p>Name under which to save the artifact.</p> required <code>str</code> <p>Path to the file.</p> required"},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.save_artifact_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.save_artifact_to_experiment(artifact_name)","title":"<code>artifact_name</code>","text":""},{"location":"api/frameworks/sam2/model/model/#picsellia_cv_engine.frameworks.sam2.model.model.SAM2Model.save_artifact_to_experiment(artifact_path)","title":"<code>artifact_path</code>","text":""},{"location":"api/frameworks/sam2/services/predictor/","title":"frameworks.sam2.services.predictor","text":""},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor","title":"<code>predictor</code>","text":"<p>Classes:</p> Name Description <code>SAM2ModelPredictor</code>"},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor","title":"<code>SAM2ModelPredictor(predictor)</code>","text":"<p>Methods:</p> Name Description <code>pre_process_dataset</code> <p>Collects image file paths from the dataset.</p> <code>preprocess_images</code> <code>preprocess</code> <code>run_inference</code> <code>post_process</code> <p>Converts mask predictions to polygons and associates them with their scores.</p> <p>Attributes:</p> Name Type Description <code>predictor</code>"},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.predictor","title":"<code>predictor = predictor</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Collects image file paths from the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>CocoDataset</code> <p>Dataset object containing image directory.</p> required <p>Returns:</p> Type Description <code>list[ndarray]</code> <p>list[str]: List of full paths to image files.</p>"},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.preprocess_images","title":"<code>preprocess_images(image_list)</code>","text":""},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.preprocess","title":"<code>preprocess(image)</code>","text":""},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.run_inference","title":"<code>run_inference(point_coords=None, point_labels=None, box=None, mask_input=None, multimask_output=True)</code>","text":""},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.post_process","title":"<code>post_process(results)</code>","text":"<p>Converts mask predictions to polygons and associates them with their scores.</p> <p>Parameters:</p> Name Type Description Default <code>list[dict]</code> <p>List of dictionaries with keys \"segmentation\" and \"score\".</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: List of {\"polygon\": [...], \"score\": float} dictionaries.</p>"},{"location":"api/frameworks/sam2/services/predictor/#picsellia_cv_engine.frameworks.sam2.services.predictor.SAM2ModelPredictor.post_process(results)","title":"<code>results</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/","title":"frameworks.sam2.services.trainer","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer","title":"<code>trainer</code>","text":"<p>Classes:</p> Name Description <code>Sam2Trainer</code> <p>Trainer class for managing the full fine-tuning process of a SAM2 model using a COCO dataset.</p> <p>Functions:</p> Name Description <code>prepare_directories</code> <p>Creates required directories for image and annotation data.</p> <code>load_coco_annotations</code> <p>Loads COCO-format annotations from a JSON file.</p> <code>generate_mask</code> <p>Generates a PNG mask from COCO-style polygon annotations.</p> <code>convert_coco_to_png_masks</code> <p>Converts COCO annotations to PNG masks and organizes them in folders.</p> <code>normalize_filenames</code> <p>Normalizes filenames in a list of directories to avoid naming conflicts.</p> <code>parse_and_log_sam2_output</code> <p>Parses SAM2 training output and logs metrics into the Picsellia experiment.</p>"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer","title":"<code>Sam2Trainer(model, dataset_collection, context, sam2_repo_path)</code>","text":"<p>Trainer class for managing the full fine-tuning process of a SAM2 model using a COCO dataset. This class handles data preparation, training launch, and checkpoint saving.</p> <p>Parameters:</p> Name Type Description Default <code>Model</code> <p>Picsellia model instance containing paths and metadata.</p> required <code>DatasetCollection[CocoDataset]</code> <p>Dataset collection containing the training data.</p> required <code>PicselliaTrainingContext | LocalTrainingContext</code> <p>Training context containing hyperparameters and working directory.</p> required <code>str</code> <p>Path to the local SAM2 repository.</p> required <p>Methods:</p> Name Description <code>prepare_data</code> <p>Prepares the training data by converting COCO annotations to PNG masks.</p> <code>launch_training</code> <p>Launches the SAM2 training process.</p> <code>save_checkpoint</code> <p>Saves the final model checkpoint as an artifact in the Picsellia experiment.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>dataset_collection</code> <code>context</code> <code>sam2_repo_path</code> <code>img_root</code> <code>ann_root</code>"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer(context)","title":"<code>context</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer(sam2_repo_path)","title":"<code>sam2_repo_path</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.dataset_collection","title":"<code>dataset_collection = dataset_collection</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.context","title":"<code>context = context</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.sam2_repo_path","title":"<code>sam2_repo_path = sam2_repo_path</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.img_root","title":"<code>img_root = os.path.join(sam2_repo_path, 'data', 'JPEGImages')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.ann_root","title":"<code>ann_root = os.path.join(sam2_repo_path, 'data', 'Annotations')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Prepares the training data by converting COCO annotations to PNG masks.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The filename of the pretrained weights.</p>"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.launch_training","title":"<code>launch_training(pretrained_weights_name)</code>","text":"<p>Launches the SAM2 training process.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Filename of the checkpoint to use as pretrained weights.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the trained checkpoint file.</p>"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.launch_training(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.save_checkpoint","title":"<code>save_checkpoint(checkpoint_path)</code>","text":"<p>Saves the final model checkpoint as an artifact in the Picsellia experiment.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the trained model checkpoint.</p> required"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.Sam2Trainer.save_checkpoint(checkpoint_path)","title":"<code>checkpoint_path</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.prepare_directories","title":"<code>prepare_directories(img_root, ann_root)</code>","text":"<p>Creates required directories for image and annotation data.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the image directory.</p> required <code>str</code> <p>Path to the annotation directory.</p> required"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.prepare_directories(img_root)","title":"<code>img_root</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.prepare_directories(ann_root)","title":"<code>ann_root</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.load_coco_annotations","title":"<code>load_coco_annotations(coco_path)</code>","text":"<p>Loads COCO-format annotations from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the COCO annotations file.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Parsed JSON dictionary.</p>"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.load_coco_annotations(coco_path)","title":"<code>coco_path</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.generate_mask","title":"<code>generate_mask(width, height, annotations)</code>","text":"<p>Generates a PNG mask from COCO-style polygon annotations.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Width of the mask.</p> required <code>int</code> <p>Height of the mask.</p> required <code>list</code> <p>List of annotation objects.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>Image.Image: The generated mask image.</p>"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.generate_mask(width)","title":"<code>width</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.generate_mask(height)","title":"<code>height</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.generate_mask(annotations)","title":"<code>annotations</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.convert_coco_to_png_masks","title":"<code>convert_coco_to_png_masks(coco, source_images, img_root, ann_root)</code>","text":"<p>Converts COCO annotations to PNG masks and organizes them in folders.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>Loaded COCO annotations.</p> required <code>str</code> <p>Directory containing original image files.</p> required <code>str</code> <p>Destination directory for images.</p> required <code>str</code> <p>Destination directory for annotations.</p> required"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.convert_coco_to_png_masks(coco)","title":"<code>coco</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.convert_coco_to_png_masks(source_images)","title":"<code>source_images</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.convert_coco_to_png_masks(img_root)","title":"<code>img_root</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.convert_coco_to_png_masks(ann_root)","title":"<code>ann_root</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.normalize_filenames","title":"<code>normalize_filenames(root_dirs)</code>","text":"<p>Normalizes filenames in a list of directories to avoid naming conflicts.</p> <p>Parameters:</p> Name Type Description Default <code>list[str]</code> <p>List of directory paths.</p> required"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.normalize_filenames(root_dirs)","title":"<code>root_dirs</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.parse_and_log_sam2_output","title":"<code>parse_and_log_sam2_output(process, context, log_file_path)</code>","text":"<p>Parses SAM2 training output and logs metrics into the Picsellia experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Popen[str]</code> <p>Subprocess running the training script.</p> required <code>PicselliaTrainingContext | LocalTrainingContext</code> <p>Picsellia pipeline context used for logging.</p> required <code>str</code> <p>File to store raw stdout logs from the training process.</p> required"},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.parse_and_log_sam2_output(process)","title":"<code>process</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.parse_and_log_sam2_output(context)","title":"<code>context</code>","text":""},{"location":"api/frameworks/sam2/services/trainer/#picsellia_cv_engine.frameworks.sam2.services.trainer.parse_and_log_sam2_output(log_file_path)","title":"<code>log_file_path</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/","title":"frameworks.ultralytics.model.model","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model","title":"<code>model</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsModel</code> <p>Specialized model class for handling Ultralytics models.</p> <p>Functions:</p> Name Description <code>find_latest_run_dir</code> <p>Finds the latest run directory for a given model name.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel","title":"<code>UltralyticsModel(name, model_version, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None, labelmap=None)</code>","text":"<p>               Bases: <code>Model</code></p> <p>Specialized model class for handling Ultralytics models.</p> <p>This class extends the base <code>Model</code> class to support Ultralytics-specific logic such as automatically locating the latest run directory and setting the trained weights' path.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the model.</p> required <code>ModelVersion</code> <p>Picsellia ModelVersion associated with the model.</p> required <code>Optional[str]</code> <p>Name of the pretrained weights file.</p> <code>None</code> <code>Optional[str]</code> <p>Name of the trained weights file.</p> <code>None</code> <code>Optional[str]</code> <p>Name of the config file.</p> <code>None</code> <code>Optional[str]</code> <p>Name of the exported weights file.</p> <code>None</code> <code>Optional[dict[str, Label]]</code> <p>Label map for the model.</p> <code>None</code> <p>Methods:</p> Name Description <code>load_yolo_weights</code> <p>Loads a YOLO model from the given weights file and moves it to the specified device.</p> <code>set_latest_run_dir</code> <p>Sets the path to the latest run directory.</p> <code>set_trained_weights_path</code> <p>Sets the path to the trained weights file from the latest run directory.</p> <code>set_loaded_model</code> <p>Set the runtime-loaded model instance.</p> <code>download_weights</code> <p>Download all configured model files (weights, config, exports) to destination.</p> <code>save_artifact_to_experiment</code> <p>Store an artifact file in the given experiment.</p> <p>Attributes:</p> Name Type Description <code>latest_run_dir</code> <code>str | None</code> <code>name</code> <p>The name of the model.</p> <code>model_version</code> <p>The version of the model from Picsellia.</p> <code>pretrained_weights_name</code> <p>The name of the pretrained weights file attached to the model version in Picsellia.</p> <code>trained_weights_name</code> <p>The name of the trained weights file attached to the model version in Picsellia.</p> <code>config_name</code> <p>The name of the configuration file attached to the model version in Picsellia.</p> <code>exported_weights_name</code> <p>The name of the exported weights file attached to the model version in Picsellia.</p> <code>labelmap</code> <p>A dictionary mapping category names to labels.</p> <code>weights_dir</code> <code>str | None</code> <p>The directory where model weights are stored.</p> <code>results_dir</code> <code>str | None</code> <p>The directory where model results are stored.</p> <code>pretrained_weights_dir</code> <code>str | None</code> <p>The directory where pretrained weights are stored.</p> <code>trained_weights_dir</code> <code>str | None</code> <p>The directory where trained weights are stored.</p> <code>config_dir</code> <code>str | None</code> <p>The directory where model configuration files are stored.</p> <code>exported_weights_dir</code> <code>str | None</code> <p>The directory where exported weights are stored.</p> <code>pretrained_weights_path</code> <code>str | None</code> <p>The path to the pretrained weights file.</p> <code>trained_weights_path</code> <code>str | None</code> <p>The path to the trained weights file.</p> <code>config_path</code> <code>str | None</code> <p>The path to the model configuration file.</p> <code>exported_weights_path</code> <code>str | None</code> <p>The path to the exported weights file.</p> <code>loaded_model</code> <code>Any</code> <p>Return the loaded model instance.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(model_version)","title":"<code>model_version</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.latest_run_dir","title":"<code>latest_run_dir = None</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.name","title":"<code>name = name</code>  <code>instance-attribute</code>","text":"<p>The name of the model.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.model_version","title":"<code>model_version = model_version</code>  <code>instance-attribute</code>","text":"<p>The version of the model from Picsellia.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.pretrained_weights_name","title":"<code>pretrained_weights_name = pretrained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the pretrained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.trained_weights_name","title":"<code>trained_weights_name = trained_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the trained weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.config_name","title":"<code>config_name = config_name</code>  <code>instance-attribute</code>","text":"<p>The name of the configuration file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.exported_weights_name","title":"<code>exported_weights_name = exported_weights_name</code>  <code>instance-attribute</code>","text":"<p>The name of the exported weights file attached to the model version in Picsellia.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.labelmap","title":"<code>labelmap = labelmap or {}</code>  <code>instance-attribute</code>","text":"<p>A dictionary mapping category names to labels.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.weights_dir","title":"<code>weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model weights are stored.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.results_dir","title":"<code>results_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model results are stored.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.pretrained_weights_dir","title":"<code>pretrained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where pretrained weights are stored.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.trained_weights_dir","title":"<code>trained_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where trained weights are stored.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.config_dir","title":"<code>config_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where model configuration files are stored.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.exported_weights_dir","title":"<code>exported_weights_dir = None</code>  <code>instance-attribute</code>","text":"<p>The directory where exported weights are stored.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.pretrained_weights_path","title":"<code>pretrained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the pretrained weights file.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.trained_weights_path","title":"<code>trained_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the trained weights file.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.config_path","title":"<code>config_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the model configuration file.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.exported_weights_path","title":"<code>exported_weights_path = None</code>  <code>instance-attribute</code>","text":"<p>The path to the exported weights file.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.loaded_model","title":"<code>loaded_model</code>  <code>property</code>","text":"<p>Return the loaded model instance.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.load_yolo_weights","title":"<code>load_yolo_weights(weights_path, device)</code>","text":"<p>Loads a YOLO model from the given weights file and moves it to the specified device.</p> <p>This function loads a YOLO model using the provided weights path and transfers it to the specified device (e.g., 'cpu' or 'cuda'). It raises an error if the weights file is not found or cannot be loaded.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The file path to the YOLO model weights.</p> required <code>str</code> <p>The device to which the model should be moved ('cpu' or 'cuda').</p> required <p>Returns:</p> Name Type Description <code>YOLO</code> <code>YOLO</code> <p>The loaded YOLO model ready for inference or training.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.load_yolo_weights(weights_path)","title":"<code>weights_path</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.load_yolo_weights(device)","title":"<code>device</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.set_latest_run_dir","title":"<code>set_latest_run_dir()</code>","text":"<p>Sets the path to the latest run directory.</p> <p>Uses the results directory to find and assign the most recent run folder. Raises an error if the results directory is not set or does not exist.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.set_trained_weights_path","title":"<code>set_trained_weights_path()</code>","text":"<p>Sets the path to the trained weights file from the latest run directory.</p> <p>Assumes the file is stored as <code>best.pt</code> inside a <code>weights/</code> subdirectory. Raises an error if the required directories do not exist.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.set_loaded_model","title":"<code>set_loaded_model(model)</code>","text":"<p>Set the runtime-loaded model instance.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.download_weights","title":"<code>download_weights(destination_dir)</code>","text":"<p>Download all configured model files (weights, config, exports) to destination.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Root directory for downloaded files.</p> required"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.download_weights(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.save_artifact_to_experiment","title":"<code>save_artifact_to_experiment(experiment, artifact_name, artifact_path)</code>","text":"<p>Store an artifact file in the given experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Experiment to store into.</p> required <code>str</code> <p>Name under which to save the artifact.</p> required <code>str</code> <p>Path to the file.</p> required"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.save_artifact_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.save_artifact_to_experiment(artifact_name)","title":"<code>artifact_name</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.UltralyticsModel.save_artifact_to_experiment(artifact_path)","title":"<code>artifact_path</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.find_latest_run_dir","title":"<code>find_latest_run_dir(dir, model_name)</code>","text":"<p>Finds the latest run directory for a given model name.</p> <p>This function looks for subdirectories starting with the model name and returns the most recent one (by sorting the folder names ending with digits).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to the directory containing run folders.</p> required <code>str</code> <p>Prefix used to identify run folders.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Path to the most recent run directory.</p>"},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.find_latest_run_dir(dir)","title":"<code>dir</code>","text":""},{"location":"api/frameworks/ultralytics/model/model/#picsellia_cv_engine.frameworks.ultralytics.model.model.find_latest_run_dir(model_name)","title":"<code>model_name</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/","title":"frameworks.ultralytics.parameters.augmentation_parameters","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters","title":"<code>augmentation_parameters</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsAugmentationParameters</code> <p>Defines data augmentation parameters for Ultralytics-based training.</p>"},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters","title":"<code>UltralyticsAugmentationParameters(log_data)</code>","text":"<p>               Bases: <code>AugmentationParameters</code></p> <p>Defines data augmentation parameters for Ultralytics-based training.</p> <p>This class extracts and validates augmentation parameters from Picsellia logs. Each parameter is automatically parsed and type-checked using <code>extract_parameter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>LogDataType</code> <p>The dictionary of logged parameters from the Picsellia platform.</p> required <p>Methods:</p> Name Description <code>extract_parameter</code> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <code>to_dict</code> <p>Return parameters as a dictionary, excluding internal fields.</p> <code>validate_log_data</code> <p>Validate and return log data if it's a dictionary.</p> <p>Attributes:</p> Name Type Description <code>hsv_h</code> <code>hsv_s</code> <code>hsv_v</code> <code>degrees</code> <code>translate</code> <code>scale</code> <code>shear</code> <code>perspective</code> <code>flipud</code> <code>fliplr</code> <code>bgr</code> <code>mosaic</code> <code>mixup</code> <code>copy_paste</code> <code>auto_augment</code> <code>erasing</code> <code>crop_fraction</code> <code>parameters_data</code> <code>defaulted_keys</code> <code>set[str]</code>"},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters(log_data)","title":"<code>log_data</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.hsv_h","title":"<code>hsv_h = self.extract_parameter(keys=['hsv_h'], expected_type=float, default=0.015, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.hsv_s","title":"<code>hsv_s = self.extract_parameter(keys=['hsv_s'], expected_type=float, default=0.7, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.hsv_v","title":"<code>hsv_v = self.extract_parameter(keys=['hsv_v'], expected_type=float, default=0.4, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.degrees","title":"<code>degrees = self.extract_parameter(keys=['degrees'], expected_type=float, default=0.0, range_value=(-180.0, 180.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.translate","title":"<code>translate = self.extract_parameter(keys=['translate'], expected_type=float, default=0.1, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.scale","title":"<code>scale = self.extract_parameter(keys=['scale'], expected_type=float, default=0.5, range_value=(0.0, float('inf')))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.shear","title":"<code>shear = self.extract_parameter(keys=['shear'], expected_type=float, default=0.0, range_value=(-180.0, 180.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.perspective","title":"<code>perspective = self.extract_parameter(keys=['perspective'], expected_type=float, default=0.0, range_value=(0.0, 0.001))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.flipud","title":"<code>flipud = self.extract_parameter(keys=['flipud'], expected_type=float, default=0.0, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.fliplr","title":"<code>fliplr = self.extract_parameter(keys=['fliplr'], expected_type=float, default=0.5, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.bgr","title":"<code>bgr = self.extract_parameter(keys=['bgr'], expected_type=float, default=0.0, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.mosaic","title":"<code>mosaic = self.extract_parameter(keys=['mosaic'], expected_type=float, default=1.0, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.mixup","title":"<code>mixup = self.extract_parameter(keys=['mixup'], expected_type=float, default=0.0, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.copy_paste","title":"<code>copy_paste = self.extract_parameter(keys=['copy_paste'], expected_type=float, default=0.0, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.auto_augment","title":"<code>auto_augment = self.extract_parameter(keys=['auto_augment'], expected_type=str, default='randaugment')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.erasing","title":"<code>erasing = self.extract_parameter(keys=['erasing'], expected_type=float, default=0.4, range_value=(0.0, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.crop_fraction","title":"<code>crop_fraction = self.extract_parameter(keys=['crop_fraction'], expected_type=float, default=1.0, range_value=(0.1, 1.0))</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.parameters_data","title":"<code>parameters_data = self.validate_log_data(log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.defaulted_keys","title":"<code>defaulted_keys = set()</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.extract_parameter","title":"<code>extract_parameter(keys, expected_type, default=..., range_value=None)</code>","text":"<pre><code>extract_parameter(keys: list, expected_type: type[T], default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; T\n</code></pre><pre><code>extract_parameter(keys: list, expected_type: Any, default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; Any\n</code></pre> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <p>Examples:</p> <p>Extract a required string parameter that cannot be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\", \"key2\"], expected_type=str)\n</code></pre></p> <p>Extract a required integer parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=int | None)\n</code></pre></p> <p>Extract an optional float parameter within a specific range: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=float, default=0.5, range_value=(0.0, 1.0))\n</code></pre></p> <p>Extract an optional string parameter with a default value: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=str, default=\"default_value\")\n</code></pre></p> <p>Extract an optional string parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=Union[str, None], default=None)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>A list of possible keys to extract the parameter.</p> required <code>type[T]</code> <p>The expected type of the parameter, can use Union for optional types.</p> required <code>Any</code> <p>The default value if the parameter is not found. Use ... for required parameters.</p> <code>...</code> <code>tuple[Any, Any] | None</code> <p>A tuple of two numbers representing the allowed range of the parameter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed parameter.</p>"},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.extract_parameter(keys)","title":"<code>keys</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.extract_parameter(expected_type)","title":"<code>expected_type</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.extract_parameter(default)","title":"<code>default</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.extract_parameter(range_value)","title":"<code>range_value</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.to_dict","title":"<code>to_dict()</code>","text":"<p>Return parameters as a dictionary, excluding internal fields.</p>"},{"location":"api/frameworks/ultralytics/parameters/augmentation_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.augmentation_parameters.UltralyticsAugmentationParameters.validate_log_data","title":"<code>validate_log_data(log_data)</code>","text":"<p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/","title":"frameworks.ultralytics.parameters.hyper_parameters","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters","title":"<code>hyper_parameters</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsHyperParameters</code> <p>Defines the set of training hyperparameters used for Ultralytics models.</p>"},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters","title":"<code>UltralyticsHyperParameters(log_data)</code>","text":"<p>               Bases: <code>HyperParameters</code></p> <p>Defines the set of training hyperparameters used for Ultralytics models.</p> <p>This class extracts, validates, and stores training hyperparameters from a Picsellia experiment log. Each parameter includes type validation, default value fallback, and optional value range enforcement.</p> <p>Parameters:</p> Name Type Description Default <code>LogDataType</code> <p>The dictionary of logged hyperparameters from the Picsellia platform.</p> required <p>Methods:</p> Name Description <code>extract_parameter</code> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <code>to_dict</code> <p>Return parameters as a dictionary, excluding internal fields.</p> <code>validate_log_data</code> <p>Validate and return log data if it's a dictionary.</p> <p>Attributes:</p> Name Type Description <code>time</code> <code>patience</code> <code>save_period</code> <code>cache</code> <code>workers</code> <code>optimizer</code> <code>deterministic</code> <code>single_cls</code> <code>rect</code> <code>cos_lr</code> <code>close_mosaic</code> <code>amp</code> <code>fraction</code> <code>profile</code> <code>freeze</code> <code>lr0</code> <code>lrf</code> <code>momentum</code> <code>weight_decay</code> <code>warmup_epochs</code> <code>warmup_momentum</code> <code>warmup_bias_lr</code> <code>box</code> <code>cls</code> <code>dfl</code> <code>pose</code> <code>kobj</code> <code>label_smoothing</code> <code>nbs</code> <code>overlap_mask</code> <code>mask_ratio</code> <code>dropout</code> <code>plots</code> <code>parameters_data</code> <code>defaulted_keys</code> <code>set[str]</code> <code>epochs</code> <code>batch_size</code> <code>image_size</code> <code>seed</code> <code>validate</code> <code>train_set_split_ratio</code> <code>device</code>"},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters(log_data)","title":"<code>log_data</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.time","title":"<code>time = self.extract_parameter(keys=['time'], expected_type=(Optional[float]), default=None)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.patience","title":"<code>patience = self.extract_parameter(keys=['patience'], expected_type=int, default=100)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.save_period","title":"<code>save_period = self.extract_parameter(keys=['save_period'], expected_type=int, default=100)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.cache","title":"<code>cache = self.extract_parameter(keys=['cache', 'use_cache'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.workers","title":"<code>workers = self.extract_parameter(keys=['workers'], expected_type=int, default=8)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.optimizer","title":"<code>optimizer = self.extract_parameter(keys=['optimizer'], expected_type=str, default='auto')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.deterministic","title":"<code>deterministic = self.extract_parameter(keys=['deterministic'], expected_type=bool, default=True)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.single_cls","title":"<code>single_cls = self.extract_parameter(keys=['single_cls'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.rect","title":"<code>rect = self.extract_parameter(keys=['rect'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.cos_lr","title":"<code>cos_lr = self.extract_parameter(keys=['cos_lr'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.close_mosaic","title":"<code>close_mosaic = self.extract_parameter(keys=['close_mosaic'], expected_type=int, default=10)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.amp","title":"<code>amp = self.extract_parameter(keys=['amp'], expected_type=bool, default=True)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.fraction","title":"<code>fraction = self.extract_parameter(keys=['fraction'], expected_type=float, default=1.0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.profile","title":"<code>profile = self.extract_parameter(keys=['profile'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.freeze","title":"<code>freeze = self.extract_parameter(keys=['freeze'], expected_type=(Optional[int]), default=None)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.lr0","title":"<code>lr0 = self.extract_parameter(keys=['lr0'], expected_type=float, default=0.01)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.lrf","title":"<code>lrf = self.extract_parameter(keys=['lrf'], expected_type=float, default=0.1)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.momentum","title":"<code>momentum = self.extract_parameter(keys=['momentum'], expected_type=float, default=0.937)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.weight_decay","title":"<code>weight_decay = self.extract_parameter(keys=['weight_decay'], expected_type=float, default=0.0005)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.warmup_epochs","title":"<code>warmup_epochs = self.extract_parameter(keys=['warmup_epochs'], expected_type=float, default=3.0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.warmup_momentum","title":"<code>warmup_momentum = self.extract_parameter(keys=['warmup_momentum'], expected_type=float, default=0.8)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.warmup_bias_lr","title":"<code>warmup_bias_lr = self.extract_parameter(keys=['warmup_bias_lr'], expected_type=float, default=0.1)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.box","title":"<code>box = self.extract_parameter(keys=['box'], expected_type=float, default=7.5)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.cls","title":"<code>cls = self.extract_parameter(keys=['cls'], expected_type=float, default=0.5)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.dfl","title":"<code>dfl = self.extract_parameter(keys=['dfl'], expected_type=float, default=1.5)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.pose","title":"<code>pose = self.extract_parameter(keys=['pose'], expected_type=float, default=12.0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.kobj","title":"<code>kobj = self.extract_parameter(keys=['kobj'], expected_type=float, default=2.0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.label_smoothing","title":"<code>label_smoothing = self.extract_parameter(keys=['label_smoothing'], expected_type=float, default=0.0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.nbs","title":"<code>nbs = self.extract_parameter(keys=['nbs'], expected_type=int, default=64)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.overlap_mask","title":"<code>overlap_mask = self.extract_parameter(keys=['overlap_mask'], expected_type=bool, default=True)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.mask_ratio","title":"<code>mask_ratio = self.extract_parameter(keys=['mask_ratio'], expected_type=int, default=4)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.dropout","title":"<code>dropout = self.extract_parameter(keys=['dropout'], expected_type=float, default=0.0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.plots","title":"<code>plots = self.extract_parameter(keys=['plots'], expected_type=bool, default=True)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.parameters_data","title":"<code>parameters_data = self.validate_log_data(log_data)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.defaulted_keys","title":"<code>defaulted_keys = set()</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.epochs","title":"<code>epochs = self.extract_parameter(keys=['epoch', 'epochs'], expected_type=int, default=10)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.batch_size","title":"<code>batch_size = self.extract_parameter(keys=['batch_size', 'batch'], expected_type=int, default=8)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.image_size","title":"<code>image_size = self.extract_parameter(keys=['image_size', 'imgsz', 'img_size'], expected_type=int, default=640)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.seed","title":"<code>seed = self.extract_parameter(keys=['seed'], expected_type=int, default=0)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.validate","title":"<code>validate = self.extract_parameter(keys=['validate', 'val', 'validation'], expected_type=bool, default=False)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.train_set_split_ratio","title":"<code>train_set_split_ratio = self.extract_parameter(keys=['prop_train_split', 'train_set_split_ratio'], expected_type=float, default=0.8)</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.device","title":"<code>device = self.extract_parameter(keys=['device'], expected_type=str, default='cuda:0')</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.extract_parameter","title":"<code>extract_parameter(keys, expected_type, default=..., range_value=None)</code>","text":"<pre><code>extract_parameter(keys: list, expected_type: type[T], default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; T\n</code></pre><pre><code>extract_parameter(keys: list, expected_type: Any, default: Any = ..., range_value: tuple[Any, Any] | None = None) -&gt; Any\n</code></pre> <p>Extract a parameter using keys, type, optional default, and optional value range.</p> <p>Examples:</p> <p>Extract a required string parameter that cannot be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\", \"key2\"], expected_type=str)\n</code></pre></p> <p>Extract a required integer parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=int | None)\n</code></pre></p> <p>Extract an optional float parameter within a specific range: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=float, default=0.5, range_value=(0.0, 1.0))\n</code></pre></p> <p>Extract an optional string parameter with a default value: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=str, default=\"default_value\")\n</code></pre></p> <p>Extract an optional string parameter that can be None: <pre><code>parameter = self.extract_parameter(keys=[\"key1\"], expected_type=Union[str, None], default=None)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>A list of possible keys to extract the parameter.</p> required <code>type[T]</code> <p>The expected type of the parameter, can use Union for optional types.</p> required <code>Any</code> <p>The default value if the parameter is not found. Use ... for required parameters.</p> <code>...</code> <code>tuple[Any, Any] | None</code> <p>A tuple of two numbers representing the allowed range of the parameter.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The parsed parameter.</p>"},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.extract_parameter(keys)","title":"<code>keys</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.extract_parameter(expected_type)","title":"<code>expected_type</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.extract_parameter(default)","title":"<code>default</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.extract_parameter(range_value)","title":"<code>range_value</code>","text":""},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.to_dict","title":"<code>to_dict()</code>","text":"<p>Return parameters as a dictionary, excluding internal fields.</p>"},{"location":"api/frameworks/ultralytics/parameters/hyper_parameters/#picsellia_cv_engine.frameworks.ultralytics.parameters.hyper_parameters.UltralyticsHyperParameters.validate_log_data","title":"<code>validate_log_data(log_data)</code>","text":"<p>Validate and return log data if it's a dictionary.</p>"},{"location":"api/frameworks/ultralytics/services/data/utils/","title":"frameworks.ultralytics.services.data.utils","text":""},{"location":"api/frameworks/ultralytics/services/data/utils/#picsellia_cv_engine.frameworks.ultralytics.services.data.utils","title":"<code>utils</code>","text":"<p>Functions:</p> Name Description <code>detect_inference_type_from_experiment</code> <p>Detects the inference type from the types of all attached dataset versions.</p> <code>generate_data_yaml</code> <code>prepare_classification_data</code> <p>Prepares and organizes a dataset collection for Ultralytics classification tasks.</p>"},{"location":"api/frameworks/ultralytics/services/data/utils/#picsellia_cv_engine.frameworks.ultralytics.services.data.utils.detect_inference_type_from_experiment","title":"<code>detect_inference_type_from_experiment(experiment)</code>","text":"<p>Detects the inference type from the types of all attached dataset versions. Ensures all attached datasets are of the same type, otherwise raises an error.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>The experiment to inspect.</p> required <p>Returns:</p> Name Type Description <code>InferenceType</code> <code>InferenceType</code> <p>The common inference type of all attached datasets.</p>"},{"location":"api/frameworks/ultralytics/services/data/utils/#picsellia_cv_engine.frameworks.ultralytics.services.data.utils.detect_inference_type_from_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/data/utils/#picsellia_cv_engine.frameworks.ultralytics.services.data.utils.generate_data_yaml","title":"<code>generate_data_yaml(dataset_collection)</code>","text":""},{"location":"api/frameworks/ultralytics/services/data/utils/#picsellia_cv_engine.frameworks.ultralytics.services.data.utils.prepare_classification_data","title":"<code>prepare_classification_data(dataset_collection)</code>","text":"<p>Prepares and organizes a dataset collection for Ultralytics classification tasks.</p> <p>This function iterates over each dataset in the provided <code>DatasetCollection</code>, organizing them using the <code>ClassificationDatasetPreparator</code> to structure the dataset for use with Ultralytics classification. Each dataset is moved into a new directory, with the structure suitable for Ultralytics training.</p> <p>Parameters:</p> Name Type Description Default <code>DatasetCollection</code> <p>The original dataset collection to be prepared for classification.</p> required <p>Returns:</p> Name Type Description <code>DatasetCollection</code> <code>DatasetCollection[CocoDataset]</code> <p>A dataset collection where each dataset has been organized and prepared for Ultralytics classification tasks.</p>"},{"location":"api/frameworks/ultralytics/services/data/utils/#picsellia_cv_engine.frameworks.ultralytics.services.data.utils.prepare_classification_data(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/","title":"frameworks.ultralytics.services.model.callbacks","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks","title":"<code>callbacks</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsCallbacks</code> <p>Provides callback hooks for training and evaluation lifecycle events in Ultralytics YOLO models.</p> <p>Functions:</p> Name Description <code>extract_column_names</code> <p>Parses a YOLO-style descriptor string to extract column names, preserving prefixes like 'Box' and 'Mask'.</p> <code>log_confusion_matrix</code>"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks","title":"<code>UltralyticsCallbacks(experiment, logger, metric_mapping, model, save_period)</code>","text":"<p>Provides callback hooks for training and evaluation lifecycle events in Ultralytics YOLO models.</p> <p>This class integrates with Picsellia to log metrics, images, and artifacts during the training and validation process.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>The experiment object used for logging.</p> required <code>type[TBaseLogger]</code> <p>The logger class used for metric/image logging.</p> required <code>TMetricMapping</code> <p>Maps framework-specific metric names to standard names.</p> required <code>UltralyticsModel</code> <p>The model wrapper to manage artifacts and paths.</p> required <code>int</code> <p>Frequency (in epochs) to save model checkpoints.</p> required <p>Methods:</p> Name Description <code>on_train_epoch_end</code> <p>Callback called at the end of each training epoch.</p> <code>on_fit_epoch_end</code> <p>Callback called at the end of each epoch (after validation).</p> <code>on_val_end</code> <p>Callback called after validation.</p> <code>on_train_end</code> <p>Callback called at the end of training.</p> <code>get_callbacks</code> <p>Returns the dictionary of callback methods for integration into the Ultralytics engine.</p> <p>Attributes:</p> Name Type Description <code>experiment</code> <code>model</code> <code>save_period</code>"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks(logger)","title":"<code>logger</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks(metric_mapping)","title":"<code>metric_mapping</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks(save_period)","title":"<code>save_period</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.experiment","title":"<code>experiment = experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.save_period","title":"<code>save_period = save_period</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_train_epoch_end","title":"<code>on_train_epoch_end(trainer)</code>","text":"<p>Callback called at the end of each training epoch. Logs training and validation losses, learning rates, and periodically saves the model.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseTrainer</code> <p>The trainer object with training state and losses.</p> required"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_train_epoch_end(trainer)","title":"<code>trainer</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_fit_epoch_end","title":"<code>on_fit_epoch_end(trainer)</code>","text":"<p>Callback called at the end of each epoch (after validation). Logs time, metrics, and training images.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseTrainer</code> <p>The trainer object with metrics and epoch info.</p> required"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_fit_epoch_end(trainer)","title":"<code>trainer</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_val_end","title":"<code>on_val_end(validator)</code>","text":"<p>Callback called after validation. Logs validation result images and performance metrics.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseValidator</code> <p>The validator object with validation metrics.</p> required"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_val_end(validator)","title":"<code>validator</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_train_end","title":"<code>on_train_end(trainer)</code>","text":"<p>Callback called at the end of training. Currently logs final metrics (disabled by default).</p> <p>Parameters:</p> Name Type Description Default <code>TBaseTrainer</code> <p>The trainer object.</p> required"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.on_train_end(trainer)","title":"<code>trainer</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.UltralyticsCallbacks.get_callbacks","title":"<code>get_callbacks()</code>","text":"<p>Returns the dictionary of callback methods for integration into the Ultralytics engine.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Callable]</code> <p>Callback function names mapped to their handlers.</p>"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.extract_column_names","title":"<code>extract_column_names(desc)</code>","text":"<p>Parses a YOLO-style descriptor string to extract column names, preserving prefixes like 'Box' and 'Mask'.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>A description string (e.g., \"Class Images Instances Box(P R mAP50)\").</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Parsed column names (e.g., [\"Class\", \"Images\", \"Instances\", \"Box(P)\", ...]).</p>"},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.extract_column_names(desc)","title":"<code>desc</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/callbacks/#picsellia_cv_engine.frameworks.ultralytics.services.model.callbacks.log_confusion_matrix","title":"<code>log_confusion_matrix(validator, logger)</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/","title":"frameworks.ultralytics.services.model.exporter","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter","title":"<code>exporter</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsModelExporter</code> <p>Exporter class for Ultralytics models.</p>"},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter","title":"<code>UltralyticsModelExporter(model)</code>","text":"<p>               Bases: <code>ModelExporter</code></p> <p>Exporter class for Ultralytics models.</p> <p>This class handles the export process for models trained using the Ultralytics framework. It supports exporting to formats such as ONNX and relocating the exported model to a specified path.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The model instance containing metadata and paths required for export.</p> required <p>Methods:</p> Name Description <code>export_model</code> <p>Exports the model to the specified format and moves the file to a target directory.</p> <code>save_model_to_experiment</code> <p>Save exported model to a Picsellia experiment.</p> <code>save_model_to_model_version</code> <p>Save exported model to a Picsellia model version.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>UltralyticsModel</code>"},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.export_model","title":"<code>export_model(exported_model_destination_path, export_format, hyperparameters)</code>","text":"<p>Exports the model to the specified format and moves the file to a target directory.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to save the exported model.</p> required <code>str</code> <p>Export format (e.g., 'onnx').</p> required <code>UltralyticsHyperParameters</code> <p>Export configuration including image size.</p> required"},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.export_model(exported_model_destination_path)","title":"<code>exported_model_destination_path</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.export_model(export_format)","title":"<code>export_format</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.export_model(hyperparameters)","title":"<code>hyperparameters</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_experiment","title":"<code>save_model_to_experiment(experiment, exported_weights_path, exported_weights_name)</code>","text":"<p>Save exported model to a Picsellia experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>Target experiment.</p> required <code>str</code> <p>Path to exported weights directory.</p> required <code>str</code> <p>File name to use in Picsellia.</p> required"},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_experiment(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_experiment(exported_weights_path)","title":"<code>exported_weights_path</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_experiment(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_model_version","title":"<code>save_model_to_model_version(model_version, exported_weights_path, exported_weights_name)</code>","text":"<p>Save exported model to a Picsellia model version.</p> <p>Parameters:</p> Name Type Description Default <code>ModelVersion</code> <p>Target model version.</p> required <code>str</code> <p>Path to exported weights directory.</p> required <code>str</code> <p>File name to use in Picsellia.</p> required"},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_model_version(model_version)","title":"<code>model_version</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_model_version(exported_weights_path)","title":"<code>exported_weights_path</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/exporter/#picsellia_cv_engine.frameworks.ultralytics.services.model.exporter.UltralyticsModelExporter.save_model_to_model_version(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/","title":"frameworks.ultralytics.services.model.trainer","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer","title":"<code>trainer</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsModelTrainer</code> <p>Trainer class for managing the training lifecycle of a model using the Ultralytics framework.</p>"},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer","title":"<code>UltralyticsModelTrainer(model, experiment)</code>","text":"<p>Trainer class for managing the training lifecycle of a model using the Ultralytics framework.</p> <p>This class handles the setup of callbacks, integration with the Picsellia experiment system, and executes training using specific hyperparameters and augmentations.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The model to be trained.</p> required <code>Experiment</code> <p>The experiment instance used for logging and tracking results.</p> required <p>Methods:</p> Name Description <code>train_model</code> <p>Executes training on the model using the provided datasets and parameters.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>experiment</code>"},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.experiment","title":"<code>experiment = experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.train_model","title":"<code>train_model(dataset_collection, hyperparameters, augmentation_parameters, callbacks=UltralyticsCallbacks)</code>","text":"<p>Executes training on the model using the provided datasets and parameters.</p> <p>Parameters:</p> Name Type Description Default <code>DatasetCollection</code> <p>Dataset used for training and validation.</p> required <code>UltralyticsHyperParameters</code> <p>Training configuration including learning rate, epochs, etc.</p> required <code>UltralyticsAugmentationParameters</code> <p>Data augmentation parameters.</p> required <code>type</code> <p>Callback class to use for logging and event handling.</p> <code>UltralyticsCallbacks</code> <p>Returns:</p> Name Type Description <code>UltralyticsModel</code> <code>UltralyticsModel</code> <p>The trained model instance.</p>"},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.train_model(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.train_model(hyperparameters)","title":"<code>hyperparameters</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.train_model(augmentation_parameters)","title":"<code>augmentation_parameters</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/trainer/#picsellia_cv_engine.frameworks.ultralytics.services.model.trainer.UltralyticsModelTrainer.train_model(callbacks)","title":"<code>callbacks</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/utils/","title":"frameworks.ultralytics.services.model.utils","text":""},{"location":"api/frameworks/ultralytics/services/model/utils/#picsellia_cv_engine.frameworks.ultralytics.services.model.utils","title":"<code>utils</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/base/","title":"frameworks.ultralytics.services.model.logger.base","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base","title":"<code>base</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsBaseMetricMapping</code> <p>A base class that defines the standard metric mappings for Ultralytics models.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping","title":"<code>UltralyticsBaseMetricMapping()</code>","text":"<p>               Bases: <code>MetricMapping</code></p> <p>A base class that defines the standard metric mappings for Ultralytics models.</p> <p>This class extends the MetricMapping to register common metrics used during training and validation in the Ultralytics framework. It provides a consistent mapping between framework-specific metric names and their standardized names across training phases.</p> <p>Methods:</p> Name Description <code>add_metric</code> <p>Add a metric to the specified phase.</p> <code>get_mapping</code> <p>Get mapping of framework names to standard names for a given phase.</p> <p>Attributes:</p> Name Type Description <code>mappings</code> <code>dict[str, list[Metric]]</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping.mappings","title":"<code>mappings = {'train': [], 'val': [], 'test': []}</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping.add_metric","title":"<code>add_metric(phase, metric)</code>","text":"<p>Add a metric to the specified phase.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>One of 'train', 'val', or 'test'.</p> required <code>Metric</code> <p>The metric to register.</p> required"},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping.add_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping.add_metric(metric)","title":"<code>metric</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping.get_mapping","title":"<code>get_mapping(phase=None)</code>","text":"<p>Get mapping of framework names to standard names for a given phase.</p> <p>Parameters:</p> Name Type Description Default <code>str | None</code> <p>One of 'train', 'val', 'test'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str]</code> <p>Mapping of metric names.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/base/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.base.UltralyticsBaseMetricMapping.get_mapping(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/","title":"frameworks.ultralytics.services.model.logger.classification","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification","title":"<code>classification</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsClassificationMetricMapping</code> <p>Defines the metric mapping for classification tasks in the Ultralytics framework.</p> <code>UltralyticsClassificationLogger</code> <p>Logger for Ultralytics-based classification models.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping","title":"<code>UltralyticsClassificationMetricMapping()</code>","text":"<p>               Bases: <code>UltralyticsBaseMetricMapping</code></p> <p>Defines the metric mapping for classification tasks in the Ultralytics framework.</p> <p>This class extends the base Ultralytics metric mapping and adds classification-specific metrics such as top-1 and top-5 accuracy and loss for both training and validation phases.</p> <p>Registers classification metrics including loss, top-1 accuracy, and top-5 accuracy for both training and validation.</p> <p>Methods:</p> Name Description <code>add_metric</code> <p>Add a metric to the specified phase.</p> <code>get_mapping</code> <p>Get mapping of framework names to standard names for a given phase.</p> <p>Attributes:</p> Name Type Description <code>mappings</code> <code>dict[str, list[Metric]]</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping.mappings","title":"<code>mappings = {'train': [], 'val': [], 'test': []}</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping.add_metric","title":"<code>add_metric(phase, metric)</code>","text":"<p>Add a metric to the specified phase.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>One of 'train', 'val', or 'test'.</p> required <code>Metric</code> <p>The metric to register.</p> required"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping.add_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping.add_metric(metric)","title":"<code>metric</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping.get_mapping","title":"<code>get_mapping(phase=None)</code>","text":"<p>Get mapping of framework names to standard names for a given phase.</p> <p>Parameters:</p> Name Type Description Default <code>str | None</code> <p>One of 'train', 'val', 'test'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str]</code> <p>Mapping of metric names.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationMetricMapping.get_mapping(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger","title":"<code>UltralyticsClassificationLogger(experiment, metric_mapping)</code>","text":"<p>               Bases: <code>BaseLogger</code></p> <p>Logger for Ultralytics-based classification models.</p> <p>This class is responsible for logging classification-related metrics during training and validation, using an Ultralytics-compatible metric mapping.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>The experiment object used for logging.</p> required <code>ClassificationMetricMapping</code> <p>The metric mapping used to normalize metric names.</p> required <p>Methods:</p> Name Description <code>log_metric</code> <p>Log a metric value (e.g. for line plot).</p> <code>log_value</code> <p>Log a scalar value (e.g., accuracy score).</p> <code>log_image</code> <p>Log an image file.</p> <code>log_confusion_matrix</code> <p>Log a confusion matrix as a heatmap.</p> <code>log_table</code> <p>Log a table (either a key-value dict or 2D matrix).</p> <code>get_log_name</code> <p>Construct log name with optional phase and mapped name.</p> <p>Attributes:</p> Name Type Description <code>experiment</code> <code>metric_mapping</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger(metric_mapping)","title":"<code>metric_mapping</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.experiment","title":"<code>experiment = experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.metric_mapping","title":"<code>metric_mapping = metric_mapping</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_metric","title":"<code>log_metric(name, value, log_type=LogType.LINE, phase=None)</code>","text":"<p>Log a metric value (e.g. for line plot).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Metric name.</p> required <code>float</code> <p>Metric value.</p> required <code>LogType</code> <p>Logging type (default LINE).</p> <code>LINE</code> <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_metric(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_metric(value)","title":"<code>value</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_metric(log_type)","title":"<code>log_type</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_value","title":"<code>log_value(name, value, phase=None, precision=4)</code>","text":"<p>Log a scalar value (e.g., accuracy score).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Metric name.</p> required <code>float</code> <p>Value to log.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code> <code>int</code> <p>Decimal precision to round.</p> <code>4</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_value(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_value(value)","title":"<code>value</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_value(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_value(precision)","title":"<code>precision</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_image","title":"<code>log_image(name, image_path, phase=None)</code>","text":"<p>Log an image file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>str</code> <p>Path to image.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_image(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_image(image_path)","title":"<code>image_path</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_image(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_confusion_matrix","title":"<code>log_confusion_matrix(name, labelmap, matrix, phase=None)</code>","text":"<p>Log a confusion matrix as a heatmap.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>dict</code> <p>Mapping of label indices to names.</p> required <code>ndarray</code> <p>Confusion matrix.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_confusion_matrix(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_confusion_matrix(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_confusion_matrix(matrix)","title":"<code>matrix</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_confusion_matrix(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_table","title":"<code>log_table(name, data, phase=None)</code>","text":"<p>Log a table (either a key-value dict or 2D matrix).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>dict</code> <p>Data to log.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_table(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_table(data)","title":"<code>data</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.log_table(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.get_log_name","title":"<code>get_log_name(metric_name, phase=None)</code>","text":"<p>Construct log name with optional phase and mapped name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Base metric name.</p> required <code>str | None</code> <p>Optional phase.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Full log name.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.get_log_name(metric_name)","title":"<code>metric_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.classification.UltralyticsClassificationLogger.get_log_name(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/","title":"frameworks.ultralytics.services.model.logger.object_detection","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection","title":"<code>object_detection</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsObjectDetectionMetricMapping</code> <p>Defines the metric mapping for object detection tasks using the Ultralytics framework.</p> <code>UltralyticsObjectDetectionLogger</code> <p>Logger for Ultralytics-based object detection models.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping","title":"<code>UltralyticsObjectDetectionMetricMapping()</code>","text":"<p>               Bases: <code>UltralyticsBaseMetricMapping</code></p> <p>Defines the metric mapping for object detection tasks using the Ultralytics framework.</p> <p>This mapping class registers framework-specific metric names and their corresponding standard names for both training and validation phases. It includes loss components, label metrics, and evaluation metrics.</p> <p>Sets up metric associations for box loss, classification loss, distribution focal loss (DFL), precision, recall, and mAP values.</p> <p>Methods:</p> Name Description <code>add_metric</code> <p>Add a metric to the specified phase.</p> <code>get_mapping</code> <p>Get mapping of framework names to standard names for a given phase.</p> <p>Attributes:</p> Name Type Description <code>mappings</code> <code>dict[str, list[Metric]]</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping.mappings","title":"<code>mappings = {'train': [], 'val': [], 'test': []}</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping.add_metric","title":"<code>add_metric(phase, metric)</code>","text":"<p>Add a metric to the specified phase.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>One of 'train', 'val', or 'test'.</p> required <code>Metric</code> <p>The metric to register.</p> required"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping.add_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping.add_metric(metric)","title":"<code>metric</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping.get_mapping","title":"<code>get_mapping(phase=None)</code>","text":"<p>Get mapping of framework names to standard names for a given phase.</p> <p>Parameters:</p> Name Type Description Default <code>str | None</code> <p>One of 'train', 'val', 'test'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str]</code> <p>Mapping of metric names.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionMetricMapping.get_mapping(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger","title":"<code>UltralyticsObjectDetectionLogger(experiment, metric_mapping)</code>","text":"<p>               Bases: <code>BaseLogger</code></p> <p>Logger for Ultralytics-based object detection models.</p> <p>This logger uses an UltralyticsObjectDetectionMetricMapping to normalize metric names and logs them to a Picsellia experiment during training and validation phases.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>The experiment object used for logging.</p> required <code>UltralyticsObjectDetectionMetricMapping</code> <p>Mapping for translating framework-specific metrics.</p> required <p>Methods:</p> Name Description <code>log_metric</code> <p>Log a metric value (e.g. for line plot).</p> <code>log_value</code> <p>Log a scalar value (e.g., accuracy score).</p> <code>log_image</code> <p>Log an image file.</p> <code>log_confusion_matrix</code> <p>Log a confusion matrix as a heatmap.</p> <code>log_table</code> <p>Log a table (either a key-value dict or 2D matrix).</p> <code>get_log_name</code> <p>Construct log name with optional phase and mapped name.</p> <p>Attributes:</p> Name Type Description <code>experiment</code> <code>metric_mapping</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger(metric_mapping)","title":"<code>metric_mapping</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.experiment","title":"<code>experiment = experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.metric_mapping","title":"<code>metric_mapping = metric_mapping</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_metric","title":"<code>log_metric(name, value, log_type=LogType.LINE, phase=None)</code>","text":"<p>Log a metric value (e.g. for line plot).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Metric name.</p> required <code>float</code> <p>Metric value.</p> required <code>LogType</code> <p>Logging type (default LINE).</p> <code>LINE</code> <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_metric(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_metric(value)","title":"<code>value</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_metric(log_type)","title":"<code>log_type</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_value","title":"<code>log_value(name, value, phase=None, precision=4)</code>","text":"<p>Log a scalar value (e.g., accuracy score).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Metric name.</p> required <code>float</code> <p>Value to log.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code> <code>int</code> <p>Decimal precision to round.</p> <code>4</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_value(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_value(value)","title":"<code>value</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_value(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_value(precision)","title":"<code>precision</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_image","title":"<code>log_image(name, image_path, phase=None)</code>","text":"<p>Log an image file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>str</code> <p>Path to image.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_image(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_image(image_path)","title":"<code>image_path</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_image(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_confusion_matrix","title":"<code>log_confusion_matrix(name, labelmap, matrix, phase=None)</code>","text":"<p>Log a confusion matrix as a heatmap.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>dict</code> <p>Mapping of label indices to names.</p> required <code>ndarray</code> <p>Confusion matrix.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_confusion_matrix(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_confusion_matrix(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_confusion_matrix(matrix)","title":"<code>matrix</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_confusion_matrix(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_table","title":"<code>log_table(name, data, phase=None)</code>","text":"<p>Log a table (either a key-value dict or 2D matrix).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>dict</code> <p>Data to log.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_table(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_table(data)","title":"<code>data</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.log_table(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.get_log_name","title":"<code>get_log_name(metric_name, phase=None)</code>","text":"<p>Construct log name with optional phase and mapped name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Base metric name.</p> required <code>str | None</code> <p>Optional phase.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Full log name.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.get_log_name(metric_name)","title":"<code>metric_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.object_detection.UltralyticsObjectDetectionLogger.get_log_name(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/","title":"frameworks.ultralytics.services.model.logger.segmentation","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation","title":"<code>segmentation</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsSegmentationMetricMapping</code> <p>Defines the metric mapping for segmentation tasks using the Ultralytics framework.</p> <code>UltralyticsSegmentationLogger</code> <p>Logger for Ultralytics-based segmentation models.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping","title":"<code>UltralyticsSegmentationMetricMapping()</code>","text":"<p>               Bases: <code>UltralyticsObjectDetectionMetricMapping</code></p> <p>Defines the metric mapping for segmentation tasks using the Ultralytics framework.</p> <p>This class extends the object detection mapping and adds segmentation-specific metrics, such as segmentation loss and mask-based precision, recall, and mAP.</p> <p>Adds metrics for training and validation segmentation loss, as well as mask precision, recall, mAP50, and mAP50-95.</p> <p>Methods:</p> Name Description <code>add_metric</code> <p>Add a metric to the specified phase.</p> <code>get_mapping</code> <p>Get mapping of framework names to standard names for a given phase.</p> <p>Attributes:</p> Name Type Description <code>mappings</code> <code>dict[str, list[Metric]]</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping.mappings","title":"<code>mappings = {'train': [], 'val': [], 'test': []}</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping.add_metric","title":"<code>add_metric(phase, metric)</code>","text":"<p>Add a metric to the specified phase.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>One of 'train', 'val', or 'test'.</p> required <code>Metric</code> <p>The metric to register.</p> required"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping.add_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping.add_metric(metric)","title":"<code>metric</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping.get_mapping","title":"<code>get_mapping(phase=None)</code>","text":"<p>Get mapping of framework names to standard names for a given phase.</p> <p>Parameters:</p> Name Type Description Default <code>str | None</code> <p>One of 'train', 'val', 'test'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, str]</code> <p>Mapping of metric names.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationMetricMapping.get_mapping(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger","title":"<code>UltralyticsSegmentationLogger(experiment, metric_mapping)</code>","text":"<p>               Bases: <code>BaseLogger</code></p> <p>Logger for Ultralytics-based segmentation models.</p> <p>This logger uses an UltralyticsSegmentationMetricMapping to log metrics during training and validation phases to a Picsellia experiment.</p> <p>Parameters:</p> Name Type Description Default <code>Experiment</code> <p>The experiment used for logging.</p> required <code>UltralyticsSegmentationMetricMapping</code> <p>The segmentation-specific metric mapping.</p> required <p>Methods:</p> Name Description <code>log_metric</code> <p>Log a metric value (e.g. for line plot).</p> <code>log_value</code> <p>Log a scalar value (e.g., accuracy score).</p> <code>log_image</code> <p>Log an image file.</p> <code>log_confusion_matrix</code> <p>Log a confusion matrix as a heatmap.</p> <code>log_table</code> <p>Log a table (either a key-value dict or 2D matrix).</p> <code>get_log_name</code> <p>Construct log name with optional phase and mapped name.</p> <p>Attributes:</p> Name Type Description <code>experiment</code> <code>metric_mapping</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger(experiment)","title":"<code>experiment</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger(metric_mapping)","title":"<code>metric_mapping</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.experiment","title":"<code>experiment = experiment</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.metric_mapping","title":"<code>metric_mapping = metric_mapping</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_metric","title":"<code>log_metric(name, value, log_type=LogType.LINE, phase=None)</code>","text":"<p>Log a metric value (e.g. for line plot).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Metric name.</p> required <code>float</code> <p>Metric value.</p> required <code>LogType</code> <p>Logging type (default LINE).</p> <code>LINE</code> <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_metric(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_metric(value)","title":"<code>value</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_metric(log_type)","title":"<code>log_type</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_metric(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_value","title":"<code>log_value(name, value, phase=None, precision=4)</code>","text":"<p>Log a scalar value (e.g., accuracy score).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Metric name.</p> required <code>float</code> <p>Value to log.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code> <code>int</code> <p>Decimal precision to round.</p> <code>4</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_value(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_value(value)","title":"<code>value</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_value(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_value(precision)","title":"<code>precision</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_image","title":"<code>log_image(name, image_path, phase=None)</code>","text":"<p>Log an image file.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>str</code> <p>Path to image.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_image(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_image(image_path)","title":"<code>image_path</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_image(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_confusion_matrix","title":"<code>log_confusion_matrix(name, labelmap, matrix, phase=None)</code>","text":"<p>Log a confusion matrix as a heatmap.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>dict</code> <p>Mapping of label indices to names.</p> required <code>ndarray</code> <p>Confusion matrix.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_confusion_matrix(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_confusion_matrix(labelmap)","title":"<code>labelmap</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_confusion_matrix(matrix)","title":"<code>matrix</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_confusion_matrix(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_table","title":"<code>log_table(name, data, phase=None)</code>","text":"<p>Log a table (either a key-value dict or 2D matrix).</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Log name.</p> required <code>dict</code> <p>Data to log.</p> required <code>str | None</code> <p>Phase name.</p> <code>None</code>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_table(name)","title":"<code>name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_table(data)","title":"<code>data</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.log_table(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.get_log_name","title":"<code>get_log_name(metric_name, phase=None)</code>","text":"<p>Construct log name with optional phase and mapped name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Base metric name.</p> required <code>str | None</code> <p>Optional phase.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Full log name.</p>"},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.get_log_name(metric_name)","title":"<code>metric_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/logger/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.logger.segmentation.UltralyticsSegmentationLogger.get_log_name(phase)","title":"<code>phase</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/","title":"frameworks.ultralytics.services.model.predictor.classification","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification","title":"<code>classification</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsClassificationModelPredictor</code> <p>A predictor class that handles model inference and result post-processing for classification tasks</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor","title":"<code>UltralyticsClassificationModelPredictor(model)</code>","text":"<p>               Bases: <code>ModelPredictor[UltralyticsModel]</code></p> <p>A predictor class that handles model inference and result post-processing for classification tasks using the Ultralytics framework.</p> <p>This class performs pre-processing of datasets, runs inference on batches of images, and post-processes the predictions to generate PicselliaClassificationPrediction objects for classification tasks.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The context containing the loaded model and its configurations.</p> required <p>Methods:</p> Name Description <code>pre_process_dataset</code> <p>Prepares the dataset by extracting and returning a list of image file paths from the dataset directory.</p> <code>run_inference_on_batches</code> <p>Runs inference on each batch of images using the model.</p> <code>post_process_batches</code> <p>Post-processes all inference results by matching predictions with assets.</p> <code>prepare_batches</code> <code>get_picsellia_label</code> <p>Get or create a PicselliaLabel from a dataset category name.</p> <code>get_picsellia_confidence</code> <p>Wrap a confidence score in a PicselliaConfidence object.</p> <code>get_picsellia_rectangle</code> <p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>TModel</code>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Prepares the dataset by extracting and returning a list of image file paths from the dataset directory.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset containing image directories structured by class.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of full image file paths.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.run_inference_on_batches","title":"<code>run_inference_on_batches(image_batches)</code>","text":"<p>Runs inference on each batch of images using the model.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>Batches of image paths.</p> required <p>Returns:</p> Type Description <code>list[Results]</code> <p>list[Results]: A list of inference result objects, one per batch.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.run_inference_on_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.post_process_batches","title":"<code>post_process_batches(image_batches, batch_results, dataset)</code>","text":"<p>Post-processes all inference results by matching predictions with assets.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>List of image batches.</p> required <code>list[Results]</code> <p>Corresponding model outputs for each batch.</p> required <code>TBaseDataset</code> <p>Dataset used to resolve label references.</p> required <p>Returns:</p> Type Description <code>list[PicselliaClassificationPrediction]</code> <p>list[PicselliaClassificationPrediction]: Formatted predictions.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.post_process_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.post_process_batches(batch_results)","title":"<code>batch_results</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.post_process_batches(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.prepare_batches","title":"<code>prepare_batches(image_paths, batch_size)</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_label","title":"<code>get_picsellia_label(category_name, dataset)</code>","text":"<p>Get or create a PicselliaLabel from a dataset category name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the label category.</p> required <code>TBaseDataset</code> <p>Dataset that provides label access.</p> required <p>Returns:</p> Name Type Description <code>PicselliaLabel</code> <code>PicselliaLabel</code> <p>Wrapped label object.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_label(category_name)","title":"<code>category_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_label(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_confidence","title":"<code>get_picsellia_confidence(confidence)</code>","text":"<p>Wrap a confidence score in a PicselliaConfidence object.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Prediction confidence score.</p> required <p>Returns:</p> Name Type Description <code>PicselliaConfidence</code> <code>PicselliaConfidence</code> <p>Wrapped confidence object.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_confidence(confidence)","title":"<code>confidence</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_rectangle","title":"<code>get_picsellia_rectangle(x, y, w, h)</code>","text":"<p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Top-left x-coordinate.</p> required <code>int</code> <p>Top-left y-coordinate.</p> required <code>int</code> <p>Width of the box.</p> required <code>int</code> <p>Height of the box.</p> required <p>Returns:</p> Name Type Description <code>PicselliaRectangle</code> <code>PicselliaRectangle</code> <p>Rectangle wrapper for object detection.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_rectangle(x)","title":"<code>x</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_rectangle(y)","title":"<code>y</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_rectangle(w)","title":"<code>w</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/classification/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.classification.UltralyticsClassificationModelPredictor.get_picsellia_rectangle(h)","title":"<code>h</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/","title":"frameworks.ultralytics.services.model.predictor.object_detection","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection","title":"<code>object_detection</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsDetectionModelPredictor</code> <p>A predictor class that handles inference and result formatting for object detection tasks</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor","title":"<code>UltralyticsDetectionModelPredictor(model)</code>","text":"<p>               Bases: <code>ModelPredictor[UltralyticsModel]</code></p> <p>A predictor class that handles inference and result formatting for object detection tasks using the Ultralytics framework.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The detection model with its weights and configuration loaded.</p> required <p>Methods:</p> Name Description <code>run_inference_on_batches</code> <p>Runs inference on each image batch using the model.</p> <code>post_process_batches</code> <p>Converts raw model outputs into structured rectangle predictions.</p> <code>format_predictions</code> <p>Transforms raw model predictions into Picsellia-compatible rectangle, label, and confidence objects.</p> <code>rescale_normalized_box</code> <p>Rescales a bounding box from normalized coordinates to pixel dimensions.</p> <code>cast_type_list_to_int</code> <p>Converts all values in a box list to integers.</p> <code>pre_process_dataset</code> <p>Extracts all image paths from the dataset's image directory.</p> <code>prepare_batches</code> <code>get_picsellia_label</code> <p>Get or create a PicselliaLabel from a dataset category name.</p> <code>get_picsellia_confidence</code> <p>Wrap a confidence score in a PicselliaConfidence object.</p> <code>get_picsellia_rectangle</code> <p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>TModel</code>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.run_inference_on_batches","title":"<code>run_inference_on_batches(image_batches)</code>","text":"<p>Runs inference on each image batch using the model.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>A list of image batches.</p> required <p>Returns:</p> Type Description <code>list[Results]</code> <p>list[Results]: A list of inference result objects, one per batch.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.run_inference_on_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.post_process_batches","title":"<code>post_process_batches(image_batches, batch_results, dataset)</code>","text":"<p>Converts raw model outputs into structured rectangle predictions.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>List of image batches.</p> required <code>list[Results]</code> <p>Model predictions per batch.</p> required <code>TBaseDataset</code> <p>Dataset context used for label resolution.</p> required <p>Returns:</p> Type Description <code>list[PicselliaRectanglePrediction]</code> <p>list[PicselliaRectanglePrediction]: Structured prediction results per image.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.post_process_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.post_process_batches(batch_results)","title":"<code>batch_results</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.post_process_batches(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.format_predictions","title":"<code>format_predictions(asset, prediction, dataset)</code>","text":"<p>Transforms raw model predictions into Picsellia-compatible rectangle, label, and confidence objects.</p> <p>Parameters:</p> Name Type Description Default <code>Asset</code> <p>The asset corresponding to the image.</p> required <code>Results</code> <p>The prediction results for the image.</p> required <code>TBaseDataset</code> <p>The dataset used to retrieve label mappings.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[list[PicselliaRectangle], list[PicselliaLabel], list[PicselliaConfidence]]</code> <p>Lists of PicselliaRectangle, PicselliaLabel, and PicselliaConfidence objects.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.format_predictions(asset)","title":"<code>asset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.format_predictions(prediction)","title":"<code>prediction</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.format_predictions(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.rescale_normalized_box","title":"<code>rescale_normalized_box(box, width, height)</code>  <code>staticmethod</code>","text":"<p>Rescales a bounding box from normalized coordinates to pixel dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>list</code> <p>Normalized box in [x_min, y_min, x_max, y_max] format.</p> required <code>int</code> <p>Image width.</p> required <code>int</code> <p>Image height.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: Rescaled box in [x, y, width, height] format.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.rescale_normalized_box(box)","title":"<code>box</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.rescale_normalized_box(width)","title":"<code>width</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.rescale_normalized_box(height)","title":"<code>height</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.cast_type_list_to_int","title":"<code>cast_type_list_to_int(box)</code>  <code>staticmethod</code>","text":"<p>Converts all values in a box list to integers.</p> <p>Parameters:</p> Name Type Description Default <code>list[float]</code> <p>Bounding box coordinates.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>list[int]: Bounding box with integer values.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.cast_type_list_to_int(box)","title":"<code>box</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Extracts all image paths from the dataset's image directory.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset object containing the image directory.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of file paths to the dataset images.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.prepare_batches","title":"<code>prepare_batches(image_paths, batch_size)</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_label","title":"<code>get_picsellia_label(category_name, dataset)</code>","text":"<p>Get or create a PicselliaLabel from a dataset category name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the label category.</p> required <code>TBaseDataset</code> <p>Dataset that provides label access.</p> required <p>Returns:</p> Name Type Description <code>PicselliaLabel</code> <code>PicselliaLabel</code> <p>Wrapped label object.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_label(category_name)","title":"<code>category_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_label(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_confidence","title":"<code>get_picsellia_confidence(confidence)</code>","text":"<p>Wrap a confidence score in a PicselliaConfidence object.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Prediction confidence score.</p> required <p>Returns:</p> Name Type Description <code>PicselliaConfidence</code> <code>PicselliaConfidence</code> <p>Wrapped confidence object.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_confidence(confidence)","title":"<code>confidence</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_rectangle","title":"<code>get_picsellia_rectangle(x, y, w, h)</code>","text":"<p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Top-left x-coordinate.</p> required <code>int</code> <p>Top-left y-coordinate.</p> required <code>int</code> <p>Width of the box.</p> required <code>int</code> <p>Height of the box.</p> required <p>Returns:</p> Name Type Description <code>PicselliaRectangle</code> <code>PicselliaRectangle</code> <p>Rectangle wrapper for object detection.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_rectangle(x)","title":"<code>x</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_rectangle(y)","title":"<code>y</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_rectangle(w)","title":"<code>w</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/object_detection/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.object_detection.UltralyticsDetectionModelPredictor.get_picsellia_rectangle(h)","title":"<code>h</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/","title":"frameworks.ultralytics.services.model.predictor.segmentation","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation","title":"<code>segmentation</code>","text":"<p>Classes:</p> Name Description <code>UltralyticsSegmentationModelPredictor</code> <p>A predictor class that handles model inference and result post-processing for segmentation tasks</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor","title":"<code>UltralyticsSegmentationModelPredictor(model)</code>","text":"<p>               Bases: <code>ModelPredictor[UltralyticsModel]</code></p> <p>A predictor class that handles model inference and result post-processing for segmentation tasks using the Ultralytics framework.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The model used to perform inference.</p> required <p>Methods:</p> Name Description <code>run_inference_on_batches</code> <p>Runs inference on each batch of images.</p> <code>post_process_batches</code> <p>Converts raw predictions into PicselliaPolygonPrediction objects for each image.</p> <code>format_predictions</code> <p>Extracts and formats segmentation predictions into Picsellia types.</p> <code>format_polygons</code> <p>Converts a polygon array to a list of integer coordinates.</p> <code>pre_process_dataset</code> <p>Extracts all image paths from the dataset's image directory.</p> <code>prepare_batches</code> <code>get_picsellia_label</code> <p>Get or create a PicselliaLabel from a dataset category name.</p> <code>get_picsellia_confidence</code> <p>Wrap a confidence score in a PicselliaConfidence object.</p> <code>get_picsellia_rectangle</code> <p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>TModel</code>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor(model)","title":"<code>model</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.run_inference_on_batches","title":"<code>run_inference_on_batches(image_batches)</code>","text":"<p>Runs inference on each batch of images.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>A list of image path batches.</p> required <p>Returns:</p> Type Description <code>list[Results]</code> <p>list[Results]: The list of inference results for each batch.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.run_inference_on_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.post_process_batches","title":"<code>post_process_batches(image_batches, batch_results, dataset)</code>","text":"<p>Converts raw predictions into PicselliaPolygonPrediction objects for each image.</p> <p>Parameters:</p> Name Type Description Default <code>list[list[str]]</code> <p>The original image path batches.</p> required <code>list[Results]</code> <p>The inference results for each batch.</p> required <code>TBaseDataset</code> <p>Dataset used to retrieve asset metadata.</p> required <p>Returns:</p> Type Description <code>list[PicselliaPolygonPrediction]</code> <p>list[PicselliaPolygonPrediction]: Structured predictions ready for evaluation/logging.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.post_process_batches(image_batches)","title":"<code>image_batches</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.post_process_batches(batch_results)","title":"<code>batch_results</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.post_process_batches(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.format_predictions","title":"<code>format_predictions(prediction, dataset)</code>","text":"<p>Extracts and formats segmentation predictions into Picsellia types.</p> <p>Parameters:</p> Name Type Description Default <code>Results</code> <p>A single inference result containing segmentation masks.</p> required <code>TBaseDataset</code> <p>Dataset used to resolve labels.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[list[PicselliaPolygon], list[PicselliaLabel], list[PicselliaConfidence]]</code> <p>Lists of PicselliaPolygon, PicselliaLabel, and PicselliaConfidence.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.format_predictions(prediction)","title":"<code>prediction</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.format_predictions(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.format_polygons","title":"<code>format_polygons(polygon)</code>  <code>staticmethod</code>","text":"<p>Converts a polygon array to a list of integer coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>ndarray</code> <p>Polygon mask as an array of coordinates.</p> required <p>Returns:</p> Type Description <code>list[list[int]]</code> <p>list[list[int]]: Polygon represented as a list of integer point pairs.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.format_polygons(polygon)","title":"<code>polygon</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.pre_process_dataset","title":"<code>pre_process_dataset(dataset)</code>","text":"<p>Extracts all image paths from the dataset's image directory.</p> <p>Parameters:</p> Name Type Description Default <code>TBaseDataset</code> <p>The dataset object containing the image directory.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of file paths to the dataset images.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.pre_process_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.prepare_batches","title":"<code>prepare_batches(image_paths, batch_size)</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_label","title":"<code>get_picsellia_label(category_name, dataset)</code>","text":"<p>Get or create a PicselliaLabel from a dataset category name.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the label category.</p> required <code>TBaseDataset</code> <p>Dataset that provides label access.</p> required <p>Returns:</p> Name Type Description <code>PicselliaLabel</code> <code>PicselliaLabel</code> <p>Wrapped label object.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_label(category_name)","title":"<code>category_name</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_label(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_confidence","title":"<code>get_picsellia_confidence(confidence)</code>","text":"<p>Wrap a confidence score in a PicselliaConfidence object.</p> <p>Parameters:</p> Name Type Description Default <code>float</code> <p>Prediction confidence score.</p> required <p>Returns:</p> Name Type Description <code>PicselliaConfidence</code> <code>PicselliaConfidence</code> <p>Wrapped confidence object.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_confidence(confidence)","title":"<code>confidence</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_rectangle","title":"<code>get_picsellia_rectangle(x, y, w, h)</code>","text":"<p>Create a PicselliaRectangle from bounding box coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Top-left x-coordinate.</p> required <code>int</code> <p>Top-left y-coordinate.</p> required <code>int</code> <p>Width of the box.</p> required <code>int</code> <p>Height of the box.</p> required <p>Returns:</p> Name Type Description <code>PicselliaRectangle</code> <code>PicselliaRectangle</code> <p>Rectangle wrapper for object detection.</p>"},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_rectangle(x)","title":"<code>x</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_rectangle(y)","title":"<code>y</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_rectangle(w)","title":"<code>w</code>","text":""},{"location":"api/frameworks/ultralytics/services/model/predictor/segmentation/#picsellia_cv_engine.frameworks.ultralytics.services.model.predictor.segmentation.UltralyticsSegmentationModelPredictor.get_picsellia_rectangle(h)","title":"<code>h</code>","text":""},{"location":"api/steps/base/datalake/loader/","title":"steps.base.datalake.loader","text":""},{"location":"api/steps/base/datalake/loader/#picsellia_cv_engine.steps.base.datalake.loader","title":"<code>loader</code>","text":"<p>Functions:</p> Name Description <code>load_datalake</code> <p>Loads and prepares data from a Picsellia Datalake.</p>"},{"location":"api/steps/base/datalake/loader/#picsellia_cv_engine.steps.base.datalake.loader.load_datalake","title":"<code>load_datalake()</code>","text":"<p>Loads and prepares data from a Picsellia Datalake.</p> <p>This function retrieves input and output datalakes from an active processing job and downloads all associated data (e.g., images). It supports both single datalake extraction (input only) and dual datalake extraction (input &amp; output).</p> <p>Usage: - Extracts one or two datalakes from the active processing job. - Downloads all associated data and organizes them into a structured object. - Ideal for data processing tasks requiring images from a Datalake.</p> <p>Behavior: - If only an input datalake is available, it downloads and returns <code>Datalake</code>. - If both input and output datalakes exist, it returns a <code>DatalakeCollection</code>,   allowing access to both datasets.</p> <p>Requirements: - The processing job must have at least one attached datalake. - Ensure <code>job_id</code> is set in the active processing context. - Data assets should be stored in the Picsellia Datalake.</p> <p>Returns:</p> Type Description <code>Datalake | DatalakeCollection</code> <ul> <li><code>Datalake</code>: If only an input datalake is available.</li> </ul> <code>Datalake | DatalakeCollection</code> <ul> <li><code>DatalakeCollection</code>: If both input and output datalakes exist.</li> </ul> <p>Example: <pre><code>from picsellia_cv_engine.steps.data_extraction.processing.datalake import load_datalake\n\n# Load datalake data from the active processing job\ndatalake_data = load_datalake()\n\n# Check if the function returned a single datalake or a collection\nif isinstance(datalake_data, DatalakeCollection):\n   logger.info(\"Using both input and output datalakes.\")\n   logger.info(f\"Input datalake images: {datalake_data.input.image_dir}\")\n   logger.info(f\"Output datalake images: {datalake_data.output.image_dir}\")\nelse:\n   logger.info(\"Using only input datalake.\")\n   logger.info(f\"Input datalake images: {datalake_data.image_dir}\")\n</code></pre></p>"},{"location":"api/steps/base/dataset/loader/","title":"steps.base.dataset.loader","text":""},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader","title":"<code>loader</code>","text":"<p>Functions:</p> Name Description <code>load_coco_datasets</code> <p>A step for loading COCO datasets based on the current pipeline context (training or processing).</p> <code>load_yolo_datasets</code> <p>A step for loading YOLO datasets based on the current pipeline context (training or processing).</p>"},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader.load_coco_datasets","title":"<code>load_coco_datasets(use_id=True, skip_asset_listing=False)</code>","text":"<p>A step for loading COCO datasets based on the current pipeline context (training or processing).</p> <p>This function adapts to different contexts and loads datasets accordingly: - Training Contexts: Loads datasets for training, validation, and testing splits. - Processing Contexts: Loads either a single dataset or multiple datasets depending on the context.</p> <p>Parameters:</p> Name Type Description Default <code>bool</code> <p>Whether to use asset UUIDs as filenames when downloading images/annotations. If <code>False</code>, filenames from the original dataset will be used. Default is <code>True</code>.</p> <code>True</code> <code>bool</code> <p>Whether to skip listing dataset assets before downloading. Default is <code>False</code>. This is applicable only for processing contexts.</p> <code>False</code> <p>Returns:</p> Type Description <code>DatasetCollection[CocoDataset] | CocoDataset</code> <p>Union[DatasetCollection[CocoDataset], CocoDataset]: The loaded dataset(s) based on the context.</p> <ul> <li>For Training Contexts: Returns a <code>DatasetCollection[CocoDataset]</code> containing training, validation,   and test datasets.</li> <li>For Processing Contexts:<ul> <li>If both input and output datasets are available, returns a <code>DatasetCollection[CocoDataset]</code>.</li> <li>If only an input dataset is available, returns a single <code>CocoDataset</code> for the input dataset.</li> </ul> </li> </ul> Example <ul> <li>In a Training Context, the function loads and prepares datasets for training, validation, and testing.</li> <li>In a Processing Context, it loads the input and output datasets (if available) or just the input dataset.</li> </ul>"},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader.load_coco_datasets(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader.load_coco_datasets(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader.load_yolo_datasets","title":"<code>load_yolo_datasets(use_id=True, skip_asset_listing=False)</code>","text":"<p>A step for loading YOLO datasets based on the current pipeline context (training or processing).</p> <p>This function adapts to different contexts and loads datasets accordingly: - Training Contexts: Loads datasets for training, validation, and testing splits. - Processing Contexts: Loads either a single dataset or multiple datasets depending on the context.</p> <p>Parameters:</p> Name Type Description Default <code>bool</code> <p>Whether to use asset UUIDs as filenames when downloading images/annotations. If <code>False</code>, filenames from the original dataset will be used. Default is <code>True</code>.</p> <code>True</code> <code>bool</code> <p>Whether to skip listing dataset assets before downloading. Default is <code>False</code>. This is applicable only for processing contexts.</p> <code>False</code> <p>Returns:</p> Type Description <code>DatasetCollection[YoloDataset] | YoloDataset</code> <p>Union[DatasetCollection[YoloDataset], YoloDataset]: The loaded dataset(s) based on the context.</p>"},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader.load_yolo_datasets(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/steps/base/dataset/loader/#picsellia_cv_engine.steps.base.dataset.loader.load_yolo_datasets(skip_asset_listing)","title":"<code>skip_asset_listing</code>","text":""},{"location":"api/steps/base/dataset/preprocessor/","title":"steps.base.dataset.preprocessor","text":""},{"location":"api/steps/base/dataset/preprocessor/#picsellia_cv_engine.steps.base.dataset.preprocessor","title":"<code>preprocessor</code>","text":"<p>Functions:</p> Name Description <code>prepare_classification_datasets</code> <p>Prepares a classification dataset by organizing image files into category-based subdirectories.</p>"},{"location":"api/steps/base/dataset/preprocessor/#picsellia_cv_engine.steps.base.dataset.preprocessor.prepare_classification_datasets","title":"<code>prepare_classification_datasets(dataset_collection, destination_dir)</code>","text":"<p>Prepares a classification dataset by organizing image files into category-based subdirectories.</p> <p>This function processes a dataset collection by sorting images into directories named after their respective class labels (categories). The dataset is restructured into a format that is compatible with models training for classification tasks, where each category of images is placed into its own folder.</p> <p>Parameters:</p> Name Type Description Default <code>DatasetCollection</code> <p>The dataset collection to prepare, which includes images and the corresponding class labels.</p> required <code>str</code> <p>The destination directory where the prepared dataset will be saved, with category-based subdirectories for each class.</p> required <p>Returns:</p> Name Type Description <code>DatasetCollection</code> <code>DatasetCollection</code> <p>A dataset collection with images organized into subdirectories, each named after the corresponding class labels.</p> <p>Examples:</p> <p>Before Preparation: <pre><code>dataset/\n\u251c\u2500\u2500 train/\n\u2502   \u251c\u2500\u2500 image1.jpg\n\u2502   \u251c\u2500\u2500 image2.jpg\n\u2502   \u251c\u2500\u2500 image3.jpg\n\u251c\u2500\u2500 val/\n\u2502   \u251c\u2500\u2500 image4.jpg\n\u2502   \u251c\u2500\u2500 image5.jpg\n\u2502   \u251c\u2500\u2500 image6.jpg\n\u2514\u2500\u2500 test/\n    \u251c\u2500\u2500 image7.jpg\n    \u251c\u2500\u2500 image8.jpg\n    \u2514\u2500\u2500 image9.jpg\n</code></pre></p> <p>After Preparation: <pre><code>dataset/\n\u251c\u2500\u2500 train/\n\u2502   \u251c\u2500\u2500 category1/\n\u2502   \u2502   \u251c\u2500\u2500 image1.jpg\n\u2502   \u2502   \u2514\u2500\u2500 image3.jpg\n\u2502   \u2514\u2500\u2500 category2/\n\u2502       \u2514\u2500\u2500 image2.jpg\n\u251c\u2500\u2500 val/\n\u2502   \u251c\u2500\u2500 category1/\n\u2502   \u2502   \u2514\u2500\u2500 image4.jpg\n\u2502   \u2514\u2500\u2500 category2/\n\u2502       \u251c\u2500\u2500 image5.jpg\n\u2502       \u2514\u2500\u2500 image6.jpg\n\u2514\u2500\u2500 test/\n    \u251c\u2500\u2500 category1/\n    \u2502   \u2514\u2500\u2500 image7.jpg\n    \u2514\u2500\u2500 category2/\n        \u251c\u2500\u2500 image8.jpg\n        \u2514\u2500\u2500 image9.jpg\n</code></pre></p>"},{"location":"api/steps/base/dataset/preprocessor/#picsellia_cv_engine.steps.base.dataset.preprocessor.prepare_classification_datasets(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/steps/base/dataset/preprocessor/#picsellia_cv_engine.steps.base.dataset.preprocessor.prepare_classification_datasets(destination_dir)","title":"<code>destination_dir</code>","text":""},{"location":"api/steps/base/dataset/uploader/","title":"steps.base.dataset.uploader","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader","title":"<code>uploader</code>","text":"<p>Functions:</p> Name Description <code>upload_full_dataset</code> <p>Upload both images and annotations for a COCO dataset.</p> <code>upload_dataset_images</code> <p>Upload only the image files from a COCO dataset.</p> <code>upload_dataset_annotations</code> <p>Upload only the annotations from a COCO dataset.</p>"},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset","title":"<code>upload_full_dataset(dataset, datalake=None, data_tag=None, use_id=True, fail_on_asset_not_found=True, replace_annotations=None, attempts=1000)</code>","text":"<p>Upload both images and annotations for a COCO dataset.</p> <p>This step manages the complete dataset upload workflow. It configures the dataset type based on its annotations and handles image and annotation upload according to the dataset's inference type (classification, detection, etc.).</p> <p>If annotations are present: - The dataset type is automatically inferred. - Both images and annotations are uploaded. - If <code>replace_annotations</code> is not explicitly provided, it will be determined from the processing context.</p> <p>If annotations are missing: - Only images are uploaded.</p> <p>Parameters:</p> Name Type Description Default <code>CocoDataset</code> <p>The dataset to upload (including images and optionally annotations).</p> required <code>Optional[Datalake]</code> <p>The target datalake. If not provided, it is inferred from the processing context.</p> <code>None</code> <code>Optional[str]</code> <p>The tag used to associate the upload in the datalake. Defaults to the one in the context.</p> <code>None</code> <code>bool</code> <p>Whether to use asset IDs for the upload (defaults to True).</p> <code>True</code> <code>bool</code> <p>If True, raises an error when a corresponding asset is not found.</p> <code>True</code> <code>Optional[bool]</code> <p>Whether to overwrite existing annotations. Fetched from context if None.</p> <code>None</code>"},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset(datalake)","title":"<code>datalake</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset(data_tag)","title":"<code>data_tag</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset(fail_on_asset_not_found)","title":"<code>fail_on_asset_not_found</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_full_dataset(replace_annotations)","title":"<code>replace_annotations</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_images","title":"<code>upload_dataset_images(dataset, datalake=None, data_tag=None, attempts=1000)</code>","text":"<p>Upload only the image files from a COCO dataset.</p> <p>This step uploads all image assets associated with the provided dataset to the datalake. Annotation data, if present, is ignored.</p> <p>Parameters:</p> Name Type Description Default <code>CocoDataset</code> <p>The dataset whose image files should be uploaded.</p> required <code>Optional[Datalake]</code> <p>The target datalake. Inferred from the context if not provided.</p> <code>None</code> <code>Optional[str]</code> <p>Optional tag to associate with the uploaded data. Inferred from the context if not provided.</p> <code>None</code>"},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_images(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_images(datalake)","title":"<code>datalake</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_images(data_tag)","title":"<code>data_tag</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_annotations","title":"<code>upload_dataset_annotations(dataset, use_id=True, fail_on_asset_not_found=True, replace_annotations=None)</code>","text":"<p>Upload only the annotations from a COCO dataset.</p> <p>This step uploads only the annotations portion of a dataset, based on its inference type. It configures the dataset type (e.g., classification, detection, etc.) based on the annotations present.</p> <p>If <code>replace_annotations</code> is not explicitly provided, the value is taken from the processing parameters context.</p> <p>Parameters:</p> Name Type Description Default <code>CocoDataset</code> <p>The dataset containing annotations to upload.</p> required <code>bool</code> <p>Whether to use asset IDs for the upload. Defaults to True.</p> <code>True</code> <code>bool</code> <p>Whether to fail if an asset referenced in the annotations is missing. Defaults to True.</p> <code>True</code> <code>Optional[bool]</code> <p>Whether to overwrite existing annotations. Fetched from context if not provided.</p> <code>None</code>"},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_annotations(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_annotations(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_annotations(fail_on_asset_not_found)","title":"<code>fail_on_asset_not_found</code>","text":""},{"location":"api/steps/base/dataset/uploader/#picsellia_cv_engine.steps.base.dataset.uploader.upload_dataset_annotations(replace_annotations)","title":"<code>replace_annotations</code>","text":""},{"location":"api/steps/base/dataset/validator/","title":"steps.base.dataset.validator","text":""},{"location":"api/steps/base/dataset/validator/#picsellia_cv_engine.steps.base.dataset.validator","title":"<code>validator</code>","text":"<p>Functions:</p> Name Description <code>validate_dataset</code> <p>Validates a dataset or a dataset collection to ensure data integrity and correctness.</p>"},{"location":"api/steps/base/dataset/validator/#picsellia_cv_engine.steps.base.dataset.validator.validate_dataset","title":"<code>validate_dataset(dataset, fix_annotation=False)</code>","text":"<p>Validates a dataset or a dataset collection to ensure data integrity and correctness.</p> <p>This function checks each dataset in a collection or a single dataset for any issues. If annotation errors are found, it can attempt to fix them based on the provided <code>fix_annotation</code> flag. If validation fails for any dataset, an error is logged. The validation process is skipped for datasets without a validator.</p> <p>Parameters:</p> Name Type Description Default <code>Union[TBaseDataset, DatasetCollection]</code> <p>The dataset or dataset collection to validate. If a <code>DatasetCollection</code> is provided, each individual dataset within the collection will be validated.</p> required <code>bool</code> <p>Flag to indicate whether to attempt fixing annotation errors. Defaults to <code>False</code>. If set to <code>True</code>, the function will try to correct any found annotation issues during validation.</p> <code>False</code>"},{"location":"api/steps/base/dataset/validator/#picsellia_cv_engine.steps.base.dataset.validator.validate_dataset(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/base/dataset/validator/#picsellia_cv_engine.steps.base.dataset.validator.validate_dataset(fix_annotation)","title":"<code>fix_annotation</code>","text":""},{"location":"api/steps/base/model/builder/","title":"steps.base.model.builder","text":""},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder","title":"<code>builder</code>","text":"<p>Functions:</p> Name Description <code>build_model</code> <p>Instantiate and initialize a model for training or inference.</p>"},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder.build_model","title":"<code>build_model(model_cls=Model, pretrained_weights_name=None, trained_weights_name=None, config_name=None, exported_weights_name=None)</code>","text":"<p>Instantiate and initialize a model for training or inference.</p> <p>This step constructs a <code>Model</code> object using the provided model class and the currently active pipeline context. It supports initializing the model with various types of weights, such as pretrained, trained, or exported weights, and optionally includes a configuration file.</p> <p>The method also ensures that any required weight files are downloaded to the appropriate local directory as defined by the context.</p> <p>Parameters:</p> Name Type Description Default <code>type[TModel]</code> <p>The model class to instantiate. Defaults to the base <code>Model</code> class.</p> <code>Model</code> <code>str</code> <p>The name of pretrained weights to load into the model.</p> <code>None</code> <code>str</code> <p>The name of previously trained weights to resume training or evaluate.</p> <code>None</code> <code>str</code> <p>The name of the configuration file to initialize the model.</p> <code>None</code> <code>str</code> <p>The name of exported weights used for inference or deployment.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TModel</code> <code>TModel</code> <p>An initialized model instance with the appropriate weights loaded.</p>"},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder.build_model(model_cls)","title":"<code>model_cls</code>","text":""},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder.build_model(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder.build_model(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder.build_model(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/steps/base/model/builder/#picsellia_cv_engine.steps.base.model.builder.build_model(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/steps/base/model/evaluator/","title":"steps.base.model.evaluator","text":""},{"location":"api/steps/base/model/evaluator/#picsellia_cv_engine.steps.base.model.evaluator","title":"<code>evaluator</code>","text":"<p>Functions:</p> Name Description <code>evaluate_model</code> <p>Perform evaluation of model predictions against ground truth annotations using Picsellia's ModelEvaluator.</p>"},{"location":"api/steps/base/model/evaluator/#picsellia_cv_engine.steps.base.model.evaluator.evaluate_model","title":"<code>evaluate_model(picsellia_predictions, inference_type, assets, output_dir)</code>","text":"<p>Perform evaluation of model predictions against ground truth annotations using Picsellia's ModelEvaluator.</p> <p>This step supports multiple inference types including classification, object detection, segmentation, and OCR. It compares the provided model predictions to the actual asset annotations, computes evaluation metrics, and stores the results in the specified output directory.</p> <p>Parameters:</p> Name Type Description Default <code>List[Union[PicselliaClassificationPrediction, PicselliaRectanglePrediction, PicselliaPolygonPrediction, PicselliaOCRPrediction]]</code> <p>List of model predictions corresponding to a supported inference type.</p> required <code>InferenceType</code> <p>The type of inference performed (e.g., CLASSIFICATION, DETECTION, SEGMENTATION, OCR).</p> required <code>Union[List[Asset], MultiAsset]</code> <p>The ground truth dataset assets to evaluate against.</p> required <code>str</code> <p>The path to the directory where evaluation results will be saved (e.g., confusion matrix, metrics report).</p> required"},{"location":"api/steps/base/model/evaluator/#picsellia_cv_engine.steps.base.model.evaluator.evaluate_model(picsellia_predictions)","title":"<code>picsellia_predictions</code>","text":""},{"location":"api/steps/base/model/evaluator/#picsellia_cv_engine.steps.base.model.evaluator.evaluate_model(inference_type)","title":"<code>inference_type</code>","text":""},{"location":"api/steps/base/model/evaluator/#picsellia_cv_engine.steps.base.model.evaluator.evaluate_model(assets)","title":"<code>assets</code>","text":""},{"location":"api/steps/base/model/evaluator/#picsellia_cv_engine.steps.base.model.evaluator.evaluate_model(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"api/steps/base/model/prediction_converter/","title":"steps.base.model.prediction_converter","text":""},{"location":"api/steps/base/model/prediction_converter/#picsellia_cv_engine.steps.base.model.prediction_converter","title":"<code>prediction_converter</code>","text":"<p>Functions:</p> Name Description <code>convert_predictions_to_coco</code> <p>Convert a list of Picsellia predictions into COCO format annotations.</p> <p>Attributes:</p> Name Type Description <code>PredictionType</code>"},{"location":"api/steps/base/model/prediction_converter/#picsellia_cv_engine.steps.base.model.prediction_converter.PredictionType","title":"<code>PredictionType = Union[PicselliaClassificationPrediction, PicselliaRectanglePrediction, PicselliaPolygonPrediction]</code>  <code>module-attribute</code>","text":""},{"location":"api/steps/base/model/prediction_converter/#picsellia_cv_engine.steps.base.model.prediction_converter.convert_predictions_to_coco","title":"<code>convert_predictions_to_coco(predictions, dataset, use_id=False)</code>","text":"<p>Convert a list of Picsellia predictions into COCO format annotations.</p> <p>Supports: - Classification (as single-class boxes covering full image) - Object detection (rectangle) - Segmentation (polygon)</p> <p>Parameters:</p> Name Type Description Default <code>list[PredictionType]</code> <p>List of predictions (classification, detection or segmentation)</p> required <code>CocoDataset</code> <p>Dataset containing image + category info</p> required <code>bool</code> <p>If True, match images using asset.id_with_extension instead of asset.filename</p> <code>False</code> <p>Returns:</p> Type Description <code>CocoDataset</code> <p>Updated CocoDataset</p>"},{"location":"api/steps/base/model/prediction_converter/#picsellia_cv_engine.steps.base.model.prediction_converter.convert_predictions_to_coco(predictions)","title":"<code>predictions</code>","text":""},{"location":"api/steps/base/model/prediction_converter/#picsellia_cv_engine.steps.base.model.prediction_converter.convert_predictions_to_coco(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/base/model/prediction_converter/#picsellia_cv_engine.steps.base.model.prediction_converter.convert_predictions_to_coco(use_id)","title":"<code>use_id</code>","text":""},{"location":"api/steps/clip/model/evaluator/","title":"steps.clip.model.evaluator","text":""},{"location":"api/steps/clip/model/evaluator/#picsellia_cv_engine.steps.clip.model.evaluator","title":"<code>evaluator</code>","text":"<p>Functions:</p> Name Description <code>evaluate</code> <p>Evaluate a CLIP model on an image-only dataset using clustering.</p>"},{"location":"api/steps/clip/model/evaluator/#picsellia_cv_engine.steps.clip.model.evaluator.evaluate","title":"<code>evaluate(model, dataset)</code>","text":"<p>Evaluate a CLIP model on an image-only dataset using clustering.</p> <p>This step: - Loads the trained CLIP model and processor. - Runs inference on the dataset to extract image embeddings. - Applies UMAP to reduce dimensionality. - Uses DBSCAN to identify clusters in the embedding space. - Saves and logs clustering visualizations (UMAP plot, cluster image grids, outliers).</p> <p>Parameters:</p> Name Type Description Default <code>CLIPModel</code> <p>The trained CLIP model to evaluate.</p> required <code>CocoDataset</code> <p>The image dataset to evaluate the model on.</p> required"},{"location":"api/steps/clip/model/evaluator/#picsellia_cv_engine.steps.clip.model.evaluator.evaluate(model)","title":"<code>model</code>","text":""},{"location":"api/steps/clip/model/evaluator/#picsellia_cv_engine.steps.clip.model.evaluator.evaluate(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/clip/model/loader/","title":"steps.clip.model.loader","text":""},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader","title":"<code>loader</code>","text":"<p>Functions:</p> Name Description <code>load_model</code> <p>Load a CLIP model using the Picsellia model interface.</p>"},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader.load_model","title":"<code>load_model(pretrained_weights_name, trained_weights_name=None, config_name=None, exported_weights_name=None, repo_id='openai/clip-vit-large-patch14-336')</code>","text":"<p>Load a CLIP model using the Picsellia model interface.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name of the pretrained weights artifact.</p> required <code>str | None</code> <p>Optional name of the trained weights.</p> <code>None</code> <code>str | None</code> <p>Optional name of the model config file.</p> <code>None</code> <code>str | None</code> <p>Optional name of exported weights for evaluation or inference.</p> <code>None</code> <code>str</code> <p>HuggingFace repo ID used for loading the processor (default is OpenAI's ViT-L/14-336).</p> <code>'openai/clip-vit-large-patch14-336'</code> <p>Returns:</p> Type Description <code>CLIPModel</code> <p>A loaded instance of CLIPModel, ready for inference.</p>"},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader.load_model(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader.load_model(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader.load_model(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader.load_model(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/steps/clip/model/loader/#picsellia_cv_engine.steps.clip.model.loader.load_model(repo_id)","title":"<code>repo_id</code>","text":""},{"location":"api/steps/clip/model/predictor/","title":"steps.clip.model.predictor","text":""},{"location":"api/steps/clip/model/predictor/#picsellia_cv_engine.steps.clip.model.predictor","title":"<code>predictor</code>","text":"<p>Functions:</p> Name Description <code>predict</code> <p>Inference step for CLIP on an image-only dataset.</p>"},{"location":"api/steps/clip/model/predictor/#picsellia_cv_engine.steps.clip.model.predictor.predict","title":"<code>predict(model, dataset)</code>","text":"<p>Inference step for CLIP on an image-only dataset.</p> <p>This step extracts image embeddings using the provided CLIP model and dataset.</p> <p>Parameters:</p> Name Type Description Default <code>CLIPModel</code> <p>The CLIP model instance with loaded weights and processor.</p> required <code>CocoDataset</code> <p>A COCO-style dataset containing image assets.</p> required <p>Returns:</p> Type Description <code>list[PicselliaCLIPEmbeddingPrediction]</code> <p>A list of predictions with image embeddings for each asset in the dataset.</p>"},{"location":"api/steps/clip/model/predictor/#picsellia_cv_engine.steps.clip.model.predictor.predict(model)","title":"<code>model</code>","text":""},{"location":"api/steps/clip/model/predictor/#picsellia_cv_engine.steps.clip.model.predictor.predict(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/clip/model/trainer/","title":"steps.clip.model.trainer","text":""},{"location":"api/steps/clip/model/trainer/#picsellia_cv_engine.steps.clip.model.trainer","title":"<code>trainer</code>","text":"<p>Functions:</p> Name Description <code>train</code> <p>Training step for CLIP using the Picsellia training engine.</p>"},{"location":"api/steps/clip/model/trainer/#picsellia_cv_engine.steps.clip.model.trainer.train","title":"<code>train(model, dataset_collection)</code>","text":"<p>Training step for CLIP using the Picsellia training engine.</p> <p>This step uses BLIP to generate captions for the dataset and runs CLIP fine-tuning using a CLI script.</p> <p>Parameters:</p> Name Type Description Default <code>CLIPModel</code> <p>CLIP model instance to be trained.</p> required <code>DatasetCollection[CocoDataset]</code> <p>Dataset collection containing train/val/test splits.</p> required <p>Returns:</p> Type Description <code>CLIPModel</code> <p>The trained CLIP model with updated weights.</p>"},{"location":"api/steps/clip/model/trainer/#picsellia_cv_engine.steps.clip.model.trainer.train(model)","title":"<code>model</code>","text":""},{"location":"api/steps/clip/model/trainer/#picsellia_cv_engine.steps.clip.model.trainer.train(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/steps/grounding_dino/model/loader/","title":"steps.grounding_dino.model.loader","text":""},{"location":"api/steps/grounding_dino/model/loader/#picsellia_cv_engine.steps.grounding_dino.model.loader","title":"<code>loader</code>","text":"<p>Functions:</p> Name Description <code>load_grounding_dino_model</code>"},{"location":"api/steps/grounding_dino/model/loader/#picsellia_cv_engine.steps.grounding_dino.model.loader.load_grounding_dino_model","title":"<code>load_grounding_dino_model(pretrained_weights_name, trained_weights_name=None, config_name=None, exported_weights_name=None)</code>","text":""},{"location":"api/steps/grounding_dino/model/predictor/","title":"steps.grounding_dino.model.predictor","text":""},{"location":"api/steps/grounding_dino/model/predictor/#picsellia_cv_engine.steps.grounding_dino.model.predictor","title":"<code>predictor</code>","text":"<p>Functions:</p> Name Description <code>run_grounding_dino_inference</code>"},{"location":"api/steps/grounding_dino/model/predictor/#picsellia_cv_engine.steps.grounding_dino.model.predictor.run_grounding_dino_inference","title":"<code>run_grounding_dino_inference(model, dataset)</code>","text":""},{"location":"api/steps/sam2/model/trainer/","title":"steps.sam2.model.trainer","text":""},{"location":"api/steps/sam2/model/trainer/#picsellia_cv_engine.steps.sam2.model.trainer","title":"<code>trainer</code>","text":"<p>Functions:</p> Name Description <code>train</code> <p>Training step for fine-tuning a SAM2 model on a custom dataset.</p>"},{"location":"api/steps/sam2/model/trainer/#picsellia_cv_engine.steps.sam2.model.trainer.train","title":"<code>train(model, dataset_collection, sam2_repo_path)</code>","text":"<p>Training step for fine-tuning a SAM2 model on a custom dataset.</p> <p>This step prepares the dataset and masks, configures the environment, and launches the SAM2 training loop.</p> <p>Parameters:</p> Name Type Description Default <code>Model</code> <p>The Picsellia model instance containing pretrained weights and logging context.</p> required <code>DatasetCollection[CocoDataset]</code> <p>The dataset collection for training, expected to include a 'train' split.</p> required <code>str</code> <p>Path to the local SAM2 repository used for training.</p> required"},{"location":"api/steps/sam2/model/trainer/#picsellia_cv_engine.steps.sam2.model.trainer.train(model)","title":"<code>model</code>","text":""},{"location":"api/steps/sam2/model/trainer/#picsellia_cv_engine.steps.sam2.model.trainer.train(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"api/steps/sam2/model/trainer/#picsellia_cv_engine.steps.sam2.model.trainer.train(sam2_repo_path)","title":"<code>sam2_repo_path</code>","text":""},{"location":"api/steps/ultralytics/dataset/preparator/","title":"steps.ultralytics.dataset.preparator","text":""},{"location":"api/steps/ultralytics/dataset/preparator/#picsellia_cv_engine.steps.ultralytics.dataset.preparator","title":"<code>preparator</code>","text":"<p>Functions:</p> Name Description <code>prepare_ultralytics_dataset</code> <p>Prepare and validate a dataset for training with the Ultralytics framework.</p>"},{"location":"api/steps/ultralytics/dataset/preparator/#picsellia_cv_engine.steps.ultralytics.dataset.preparator.prepare_ultralytics_dataset","title":"<code>prepare_ultralytics_dataset(use_id=True)</code>","text":"<p>Prepare and validate a dataset for training with the Ultralytics framework.</p> <p>This step dynamically selects the appropriate dataset loading and formatting strategy based on the inference task type (classification, object detection, or segmentation) detected from the current experiment context.</p> <p>Processing includes: - Loading COCO-style datasets for classification tasks and restructuring them into class-based folders. - Loading YOLO-style datasets for detection and segmentation tasks, followed by generating a <code>data.yaml</code> file. - Validating the dataset and optionally fixing annotation issues.</p> <p>Returns:</p> Name Type Description <code>DatasetCollection</code> <code>DatasetCollection</code> <p>A dataset collection object ready for use in training pipelines.</p>"},{"location":"api/steps/ultralytics/model/evaluator/","title":"steps.ultralytics.model.evaluator","text":""},{"location":"api/steps/ultralytics/model/evaluator/#picsellia_cv_engine.steps.ultralytics.model.evaluator","title":"<code>evaluator</code>","text":"<p>Functions:</p> Name Description <code>evaluate_ultralytics_model</code> <p>Evaluate an Ultralytics model on a given dataset and log evaluation metrics.</p>"},{"location":"api/steps/ultralytics/model/evaluator/#picsellia_cv_engine.steps.ultralytics.model.evaluator.evaluate_ultralytics_model","title":"<code>evaluate_ultralytics_model(model, dataset)</code>","text":"<p>Evaluate an Ultralytics model on a given dataset and log evaluation metrics.</p> <p>This step handles evaluation for classification, object detection, and segmentation models trained with the Ultralytics framework. It:</p> <ul> <li>Retrieves the current training context from the pipeline.</li> <li>Chooses the appropriate predictor class based on the model's task type.</li> <li>Runs inference on the provided dataset in batches.</li> <li>Post-processes predictions into Picsellia-compatible format.</li> <li>Computes evaluation metrics and logs them to the experiment.</li> </ul> Supported tasks <ul> <li>Classification</li> <li>Object Detection</li> <li>Segmentation</li> </ul> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The trained Ultralytics model to evaluate.</p> required <code>TBaseDataset</code> <p>The dataset to evaluate the model on.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"api/steps/ultralytics/model/evaluator/#picsellia_cv_engine.steps.ultralytics.model.evaluator.evaluate_ultralytics_model(model)","title":"<code>model</code>","text":""},{"location":"api/steps/ultralytics/model/evaluator/#picsellia_cv_engine.steps.ultralytics.model.evaluator.evaluate_ultralytics_model(dataset)","title":"<code>dataset</code>","text":""},{"location":"api/steps/ultralytics/model/exporter/","title":"steps.ultralytics.model.exporter","text":""},{"location":"api/steps/ultralytics/model/exporter/#picsellia_cv_engine.steps.ultralytics.model.exporter","title":"<code>exporter</code>","text":"<p>Functions:</p> Name Description <code>export_ultralytics_model</code> <p>Export a trained Ultralytics model and save it to the associated experiment.</p>"},{"location":"api/steps/ultralytics/model/exporter/#picsellia_cv_engine.steps.ultralytics.model.exporter.export_ultralytics_model","title":"<code>export_ultralytics_model(model)</code>","text":"<p>Export a trained Ultralytics model and save it to the associated experiment.</p> <p>This step performs the following: - Retrieves the active Picsellia training context. - Initializes a model exporter for the given Ultralytics model. - Exports the model to the format specified in the export parameters (e.g., ONNX). - Saves the exported model as an artifact in the experiment.</p> <p>If the model does not have an <code>exported_weights_dir</code> set, the function logs a message and skips the export.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The trained Ultralytics model to export.</p> required Logs <p>Skips export if no export destination is defined on the model.</p>"},{"location":"api/steps/ultralytics/model/exporter/#picsellia_cv_engine.steps.ultralytics.model.exporter.export_ultralytics_model(model)","title":"<code>model</code>","text":""},{"location":"api/steps/ultralytics/model/loader/","title":"steps.ultralytics.model.loader","text":""},{"location":"api/steps/ultralytics/model/loader/#picsellia_cv_engine.steps.ultralytics.model.loader","title":"<code>loader</code>","text":"<p>Functions:</p> Name Description <code>load_ultralytics_model</code> <p>Load an Ultralytics YOLO model with the specified weights and configurations.</p>"},{"location":"api/steps/ultralytics/model/loader/#picsellia_cv_engine.steps.ultralytics.model.loader.load_ultralytics_model","title":"<code>load_ultralytics_model(pretrained_weights_name, trained_weights_name=None, config_name=None, exported_weights_name=None)</code>","text":"<p>Load an Ultralytics YOLO model with the specified weights and configurations.</p> <p>This step: - Retrieves the current training context from the pipeline. - Initializes an <code>UltralyticsModel</code> using metadata from the experiment and optional weight/config names. - Downloads the pretrained weights and loads them using Ultralytics' <code>YOLO</code> API. - Sets the loaded model into the <code>UltralyticsModel</code> instance for downstream training or inference.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>The name of the pretrained weights file to load.</p> required <code>str</code> <p>Name of the trained weights (if resuming training or fine-tuning).</p> <code>None</code> <code>str</code> <p>Name of the configuration file used for the model.</p> <code>None</code> <code>str</code> <p>Name of the exported weights (e.g., for inference/export steps).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>UltralyticsModel</code> <code>UltralyticsModel</code> <p>An initialized model with its architecture and weights loaded.</p>"},{"location":"api/steps/ultralytics/model/loader/#picsellia_cv_engine.steps.ultralytics.model.loader.load_ultralytics_model(pretrained_weights_name)","title":"<code>pretrained_weights_name</code>","text":""},{"location":"api/steps/ultralytics/model/loader/#picsellia_cv_engine.steps.ultralytics.model.loader.load_ultralytics_model(trained_weights_name)","title":"<code>trained_weights_name</code>","text":""},{"location":"api/steps/ultralytics/model/loader/#picsellia_cv_engine.steps.ultralytics.model.loader.load_ultralytics_model(config_name)","title":"<code>config_name</code>","text":""},{"location":"api/steps/ultralytics/model/loader/#picsellia_cv_engine.steps.ultralytics.model.loader.load_ultralytics_model(exported_weights_name)","title":"<code>exported_weights_name</code>","text":""},{"location":"api/steps/ultralytics/model/trainer/","title":"steps.ultralytics.model.trainer","text":""},{"location":"api/steps/ultralytics/model/trainer/#picsellia_cv_engine.steps.ultralytics.model.trainer","title":"<code>trainer</code>","text":"<p>Functions:</p> Name Description <code>train_ultralytics_model</code> <p>Train an Ultralytics model using the provided dataset collection and training context.</p>"},{"location":"api/steps/ultralytics/model/trainer/#picsellia_cv_engine.steps.ultralytics.model.trainer.train_ultralytics_model","title":"<code>train_ultralytics_model(model, dataset_collection)</code>","text":"<p>Train an Ultralytics model using the provided dataset collection and training context.</p> <p>This step: - Retrieves the active training context to access hyperparameters, augmentation settings, and experiment metadata. - Initializes an <code>UltralyticsModelTrainer</code> to handle the training logic. - Runs the training pipeline on the dataset collection. - Sets the latest run directory and locates the best model weights after training. - Saves the trained model weights as an artifact in the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>UltralyticsModel</code> <p>The model instance to be trained.</p> required <code>DatasetCollection[TBaseDataset]</code> <p>The dataset collection used for training, typically including 'train', 'val', and optionally 'test' datasets.</p> required <p>Returns:</p> Name Type Description <code>UltralyticsModel</code> <code>UltralyticsModel</code> <p>The trained model with updated internal state and trained weights.</p>"},{"location":"api/steps/ultralytics/model/trainer/#picsellia_cv_engine.steps.ultralytics.model.trainer.train_ultralytics_model(model)","title":"<code>model</code>","text":""},{"location":"api/steps/ultralytics/model/trainer/#picsellia_cv_engine.steps.ultralytics.model.trainer.train_ultralytics_model(dataset_collection)","title":"<code>dataset_collection</code>","text":""},{"location":"usage/","title":"\ud83d\udcda Pipeline Usage Examples","text":"<p>This section includes real-world examples for both processing and training pipelines using the <code>pxl-pipeline</code> cli.</p>"},{"location":"usage/#processing-pipelines","title":"\ud83d\udd01 Processing Pipelines","text":"<ul> <li>Dataset Version Creation Template</li> <li>Pre-annotation Template</li> </ul>"},{"location":"usage/#training-pipelines","title":"\ud83c\udfcb\ufe0f Training Pipelines","text":"<ul> <li>Ultralytics Training Template</li> </ul>"},{"location":"usage/cli_overview/","title":"\ud83e\udde0 How the pxl-pipeline cli works","text":""},{"location":"usage/cli_overview/#pipeline-lifecycle","title":"\ud83d\ude80 Pipeline lifecycle","text":"<ul> <li><code>init</code> \u2192 generate template</li> <li><code>test</code> \u2192 runs the pipeline locally in <code>.venv/</code></li> <li><code>deploy</code> \u2192 builds &amp; pushes Docker image + registers in Picsellia</li> <li><code>smoke-test</code> \u2192 runs pipeline in a container before deploying</li> </ul>"},{"location":"usage/cli_overview/#project-structure","title":"\ud83d\udcc2 Project structure","text":"<p>Here is a typical pipeline folder structure:</p> <pre><code>my_pipeline/\n\u251c\u2500\u2500 config.toml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 Dockerfile\n\n\u251c\u2500\u2500 picsellia_pipeline.py\n\u251c\u2500\u2500 local_pipeline.py\n\u251c\u2500\u2500 steps.py\n\u251c\u2500\u2500 utils/\n\u2502 \u2514\u2500\u2500 parameters.py\n\n\u251c\u2500\u2500 runs/\n\u2502 \u2514\u2500\u2500 run1/\n\u2502 \u2514\u2500\u2500 run_config.toml\n\n\u2514\u2500\u2500 .venv/\n</code></pre>"},{"location":"usage/cli_overview/#key-files","title":"Key files:","text":"<ul> <li> <p><code>config.toml</code>   Describes the pipeline metadata, entrypoint files, requirements file, and model metadata.   \u2795 This makes pipelines easily portable and shareable.</p> </li> <li> <p><code>pyproject.toml</code> / <code>uv.lock</code>   Managed by <code>uv</code> to declare dependencies.   You don\u2019t need to manually install anything \u2014 just run the CLI.</p> </li> <li> <p><code>picsellia_pipeline.py</code>   Entrypoint when running on Picsellia (inside Docker).</p> </li> <li> <p><code>local_pipeline.py</code>   Entrypoint for running and testing the pipeline locally.</p> </li> <li> <p><code>steps.py</code>   Contains <code>@step</code>-decorated functions that define the logic of your pipeline.</p> </li> <li> <p><code>utils/parameters.py</code>   Contains the parameter class (<code>TrainingHyperParameters</code>, <code>ProcessingParameters</code>, etc.) used to extract configuration at runtime.</p> </li> <li> <p><code>.venv/</code>   Created automatically by the CLI when you run <code>pxl-pipeline test</code>.</p> </li> </ul>"},{"location":"usage/cli_overview/#environment-variables","title":"\ud83d\udd10 Environment variables","text":"<p>The CLI requires:</p> <pre><code>PICSELLIA_API_TOKEN\nPICSELLIA_ORGANIZATION_NAME\nPICSELLIA_HOST  # optional, defaults to https://app.picsellia.com\n</code></pre> <p>They are:</p> <ul> <li>Prompted once during init, test, or deploy</li> <li>Saved in: <code>~/.config/picsellia/.env</code></li> <li>Automatically loaded on future runs</li> </ul> <p>You can:</p> <ul> <li>Manually edit that file</li> <li>Or override any value in the current terminal session with export VAR=...</li> </ul>"},{"location":"usage/cli_overview/#dependency-management-with-uv","title":"\ud83e\uddf0 Dependency management with uv","text":"<p>Each pipeline uses <code>uv</code> as the dependency manager. It handles package resolution and installation via <code>pyproject.toml</code>, without needing pip or poetry.</p>"},{"location":"usage/cli_overview/#what-happens-during-pxl-pipeline-test","title":"\ud83d\udce6 What happens during pxl-pipeline test?","text":"<p>When you run:</p> <pre><code>pxl-pipeline test my_pipeline\n</code></pre> <p>The following is automatically done for you:</p> <ul> <li><code>uv lock</code> resolves all dependencies and generates/updates <code>uv.lock</code></li> <li><code>uv sync</code>  installs packages into <code>.venv/</code> based on the lock file</li> </ul> <p>You don't need to install or activate anything manually \u2014 the CLI ensures the right environment is built.</p>"},{"location":"usage/cli_overview/#adding-dependencies","title":"\u2795 Adding dependencies","text":"<p>To install a PyPI package:</p> <pre><code>uv add opencv-python --project my_pipeline\n</code></pre> <p>To add a Git-based package:</p> <pre><code>uv add git+https://github.com/picselliahq/picsellia-cv-engine.git --project my_pipeline\n</code></pre> <p>This updates the pyproject.toml and uv.lock files inside your pipeline folder.</p> <p>\ud83d\udca1 Tip: the <code>--project</code> flag ensures the package is added to the correct pipeline folder.</p>"},{"location":"usage/cli_overview/#how-runs-work","title":"\ud83d\udcc1 How <code>runs/</code> work","text":"<p>Each test run creates a new directory under runs/:</p> <pre><code>\u251c\u2500\u2500 runs/\n\u2502   \u251c\u2500\u2500 run1/\n\u2502   \u251c\u2500\u2500 run2/\n\u2502   \u2514\u2500\u2500 run3/\n\u2502       \u2514\u2500\u2500 run_config.toml\n</code></pre> <p>Inside each run folder:</p> <ul> <li><code>run_config.toml</code> stores the parameters used for that run (e.g. <code>experiment_id</code>, <code>model_version_id</code>, etc.)</li> <li>The dataset and model will be downloaded into this folder</li> <li>Logs, annotations, and any outputs will be saved here</li> </ul>"},{"location":"usage/cli_overview/#reusing-configurations","title":"Reusing configurations","text":"<ul> <li>If a previous run exists, the CLI will prompt:</li> </ul> <pre><code>\ud83d\udcdd Reuse previous config? experiment_id=... [Y/n]\n</code></pre> <ul> <li> <p>Choosing Y reuses the last config (but creates a new folder and re-downloads assets).</p> </li> <li> <p>Use the flag <code>--reuse-dir</code> to reuse the same directory and config, without downloading again.</p> </li> </ul>"},{"location":"usage/cli_overview/#working-with-pipeline-parameters","title":"Working with pipeline parameters","text":""},{"location":"usage/cli_overview/#adding-a-custom-parameter","title":"\u2795 Adding a custom parameter","text":"<p>Each pipeline includes a <code>utils/parameters.py</code> file containing a parameter class that extracts and validates values from Picsellia metadata (experiment or processing).</p>"},{"location":"usage/cli_overview/#1-locate-your-parameters-file","title":"1. Locate your parameters file","text":"<pre><code>my_pipeline/\n\u251c\u2500\u2500 utils/\n\u2502   \u2514\u2500\u2500 parameters.py  \u2190 edit this file\n</code></pre>"},{"location":"usage/cli_overview/#2-edit-the-parameter-class","title":"2. Edit the parameter class","text":"<p>Inside <code>parameters.py</code>, you\u2019ll find a class that inherits from:</p> <ul> <li> <p><code>Parameters</code> (for processing pipelines)</p> </li> <li> <p><code>HyperParameters</code> (for training pipelines)</p> </li> </ul> <p>Add your new fields by calling <code>self.extract_parameter(...)</code> in the constructor.</p> <pre><code>from picsellia_cv_engine.core.parameters import Parameters\n\nclass ProcessingParameters(Parameters):\n    def __init__(self, log_data):\n        super().__init__(log_data)\n\n        # Add your custom parameters here \ud83d\udc47\n        self.threshold = self.extract_parameter(\n            keys=[\"threshold\"],\n            expected_type=float,\n            default=0.5,\n        )\n\n        self.use_filter = self.extract_parameter(\n            keys=[\"use_filter\"],\n            expected_type=bool,\n            default=True,\n        )\n</code></pre> <ol> <li>Link the class in <code>config.toml</code></li> </ol> <p>Make sure the class is declared in your pipeline\u2019s <code>config.toml</code>:</p> <pre><code>[execution]\nparameters_class = \"utils/parameters.py:ProcessingParameters\"\n</code></pre>"},{"location":"usage/cli_overview/#what-you-can-define","title":"\u2705 What you can define","text":"<p>Each parameter can include:</p> Field Description <code>keys</code> One or more fallback keys (e.g. <code>[\"lr\", \"learning_rate\"]</code>) <code>expected_type</code> Type validation (<code>int</code>, <code>float</code>, <code>bool</code>, <code>str</code>, <code>Optional[...]</code>) <code>default</code> Optional default value (or <code>...</code> to mark as required) <code>range_value</code> Value bounds: <code>(min, max)</code> for numeric parameters <p>Advanced use cases (enums, optional types, dynamic validation) are documented in the base Parameters class via extract_parameter(...).</p>"},{"location":"usage/cli_overview/#summary","title":"\u2705 Summary","text":"<ul> <li> <p>Pipelines are self-contained and shareable via config.toml</p> </li> <li> <p>Dependencies are isolated and reproducible with uv</p> </li> <li> <p>CLI stores runs in runs/, with config and outputs</p> </li> <li> <p>Parameters are centralized and easy to extend</p> </li> <li> <p>You can deploy to Picsellia with <code>pxl-pipeline deploy ...</code></p> </li> </ul> <p>For template-specific usage, see:</p> <ul> <li> <p>Training - Ultralytics</p> </li> <li> <p>Processing - Pre-annotation</p> </li> <li> <p>Processing - Dataset version creation</p> </li> </ul>"},{"location":"usage/commands/deploy/","title":"<code>pxl-pipeline deploy</code>","text":"<p>The <code>deploy</code> command builds a Docker image for your pipeline, pushes it to the registry, and registers (or updates) the pipeline in Picsellia.</p>"},{"location":"usage/commands/deploy/#usage","title":"Usage","text":"<pre><code>pxl-pipeline deploy PIPELINE_NAME --organization ORG_NAME [--env ENV]\n</code></pre>"},{"location":"usage/commands/deploy/#example","title":"Example:","text":"<pre><code>pxl-pipeline deploy dataset_version_creation --organization my-org --env STAGING\n</code></pre>"},{"location":"usage/commands/deploy/#options","title":"Options","text":"Option Description Default <code>PIPELINE_NAME</code> Name of the pipeline project (folder). \u2705 Required <code>--organization</code> Picsellia organization name. \u2705 Required <code>--env</code> Target environment: <code>PROD</code>, <code>STAGING</code>, <code>LOCAL</code> <code>PROD</code>"},{"location":"usage/commands/deploy/#what-happens-during-deploy","title":"What happens during deploy?","text":"<p>1. Pipeline details</p> <ul> <li>Reads pipeline metadata from <code>config.toml</code> (type, description, etc.).</li> </ul> <p>2. Docker image name</p> <ul> <li> <p>If not already set in <code>config.toml</code>, prompts you to provide one.</p> </li> <li> <p>Format: <code>user/pipeline_name</code>.</p> </li> </ul> <p>3. Version bump</p> <ul> <li> <p>Prompts for the next version bump (<code>patch</code>, <code>minor</code>, <code>major</code>, <code>rc</code>, <code>final</code>).</p> </li> <li> <p>Updates config.toml with the new version and image tag.</p> </li> </ul> <p>4. Resource allocation</p> <ul> <li> <p>Prompts for default CPU and GPU allocation if missing.</p> </li> <li> <p>Saves values in the docker section of config.toml.</p> </li> </ul> <p>5. Build &amp; push Docker image</p> <ul> <li> <p>Builds the Docker image for the pipeline.</p> </li> <li> <p>Pushes tags: the new version and either latest (or test if RC).</p> </li> </ul> <p>6. Environment setup</p> <ul> <li> <p>Resolves the target environment (PROD, STAGING, or LOCAL).</p> </li> <li> <p>Loads API token and org name from config or env vars.</p> </li> </ul> <p>7. Register/update in Picsellia</p> <ul> <li> <p>If the pipeline does not exist, it is created.</p> </li> <li> <p>If it already exists, it is updated with the new image + resources.</p> </li> </ul>"},{"location":"usage/commands/init/","title":"<code>pxl-pipeline init</code>","text":"<p>The <code>init</code> command bootstraps a new pipeline project (either processing or training) with the standard folder structure, dependencies, and metadata required to run pipelines in Picsellia.</p>"},{"location":"usage/commands/init/#usage","title":"Usage","text":"<pre><code>pxl-pipeline init PIPELINE_NAME \\\n  --type [processing|training] \\\n  --template TEMPLATE_NAME \\\n  [OPTIONS]\n</code></pre>"},{"location":"usage/commands/init/#arguments","title":"Arguments","text":"Argument Description Required <code>PIPELINE_NAME</code> Name of the pipeline project (and its folder). \u2705"},{"location":"usage/commands/init/#options","title":"Options","text":"Option Description Default <code>--type</code> Pipeline type: <code>processing</code> or <code>training</code>. \u2705 Required <code>--template</code> Template name. \u2705 Required <code>--output-dir</code> Target directory where the pipeline will be created. <code>.</code> (current) <code>--use-pyproject</code> Generate a <code>pyproject.toml</code> for dependency management (via <code>uv</code>). <code>True</code>"},{"location":"usage/commands/init/#templates","title":"Templates","text":""},{"location":"usage/commands/init/#processing","title":"Processing","text":"<ul> <li> <p><code>dataset_version_creation</code>: create a new dataset version from existing images/annotations.</p> </li> <li> <p><code>pre_annotation</code>: automatically annotate datasets using an existing model.</p> </li> <li> <p><code>data_auto_tagging</code>: add tags to data stored in a datalake.</p> </li> </ul>"},{"location":"usage/commands/init/#training","title":"Training","text":"<ul> <li><code>yolov8</code>: Train YOLOv8 models on datasets hosted in Picsellia.</li> </ul>"},{"location":"usage/commands/init/#behavior","title":"Behavior","text":""},{"location":"usage/commands/init/#processing-pipelines","title":"Processing pipelines","text":"<ul> <li> <p>Generate the full pipeline scaffold:</p> <ul> <li><code>config.toml</code></li> <li><code>steps.py</code></li> <li><code>utils/parameters.py</code></li> <li><code>.venv/</code> (with dependencies installed via <code>uv</code>)</li> </ul> </li> </ul>"},{"location":"usage/commands/init/#training-pipelines","title":"Training pipelines","text":"<ul> <li>Prompt for organization and environment if not set via env vars:</li> </ul> <pre><code>export PICSELLIA_ORGANIZATION=my-org\nexport PICSELLIA_ENV=STAGING\n</code></pre> <ul> <li> <p>Prompt for model version:</p> <ul> <li> <p>Reuse an existing private/public model version</p> </li> <li> <p>Or create a new one (define model name, version, framework, inference type)</p> </li> </ul> </li> <li> <p>Save model metadata into config.toml:</p> </li> </ul> <pre><code>[model_version]\nname = \"v1\"\norigin_name = \"MyModel\"\nframework = \"ONNX\"\ninference_type = \"OBJECT_DETECTION\"\n</code></pre>"},{"location":"usage/commands/init/#examples","title":"Examples","text":""},{"location":"usage/commands/init/#create-a-dataset-processing-pipeline","title":"Create a dataset processing pipeline","text":"<pre><code>pxl-pipeline init my_dataset_pipeline \\\n  --type processing \\\n  --template dataset_version_creation\n</code></pre>"},{"location":"usage/commands/init/#create-a-yolov8-training-pipeline","title":"Create a YOLOv8 training pipeline","text":"<pre><code>pxl-pipeline init my_yolo_pipeline \\\n  --type training \\\n  --template yolov8\n</code></pre> <p>\ud83d\udc49 During setup, the CLI will prompt:</p> <ul> <li>Organization name (if not set in env vars)</li> <li>Picsellia environment (prod/staging/local)</li> <li>Model version reuse/creation</li> </ul>"},{"location":"usage/commands/init/#project-structure","title":"Project Structure","text":"<pre><code>my_pipeline/\n\u251c\u2500\u2500 config.toml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 Dockerfile\n\n\u251c\u2500\u2500 pipeline.py\n\u251c\u2500\u2500 steps.py\n\u251c\u2500\u2500 utils/\n\u2502   \u2514\u2500\u2500 parameters.py\n\n\u251c\u2500\u2500 runs/\n\u2502   \u2514\u2500\u2500 run1/\n\u2502       \u2514\u2500\u2500 run_config.toml\n\n\u2514\u2500\u2500 .venv/\n</code></pre>"},{"location":"usage/commands/test/","title":"\ud83e\uddea pxl-pipeline test","text":"<p>The <code>test</code> command runs a pipeline locally in a virtual environment, using the same logic that will later run on Picsellia. It uses the unified entrypoint <code>pipeline.py</code> with <code>--mode local</code>.</p>"},{"location":"usage/commands/test/#usage","title":"Usage","text":"<pre><code>pxl-pipeline test PIPELINE_NAME [OPTIONS]\n</code></pre> <p>Example:</p> <pre><code>pxl-pipeline test yolov8 --run-config-file runs/run_config.toml\n</code></pre> <p>This runs: <pre><code>python pipeline.py --mode local --config-file runs/run_config.toml\n</code></pre></p>"},{"location":"usage/commands/test/#options","title":"Options","text":"Option Description Default <code>--run-config-file</code> Path to a TOML file containing pipeline inputs, outputs, and parameters. If omitted, you\u2019ll be prompted for required values, and a <code>run_config.toml</code> will be generated automatically. None <code>--reuse-dir</code> Reuse the last run directory instead of creating a new one. This avoids re-downloading datasets and models. <code>False</code> <code>--organization</code> Picsellia organization name (will be inferred from environment if missing). Prompted <code>--env</code> Picsellia environment: <code>PROD</code>, <code>STAGING</code>, <code>LOCAL</code>. <code>PROD</code>"},{"location":"usage/commands/test/#run-directories-and-configs","title":"Run directories and configs","text":""},{"location":"usage/commands/test/#at-initialization","title":"At initialization","text":"<p>When you create a pipeline with <code>pxl-pipeline init</code>, a template <code>run_config.toml</code> is generated under <code>runs/</code>. This file acts as a starting point you can edit to configure inputs, outputs, and parameters.</p>"},{"location":"usage/commands/test/#at-each-test-run","title":"At each test run","text":"<p>Each time you run <code>pxl-pipeline test</code>:</p> <ul> <li>A new run directory is created under <code>runs/runX/</code> (unless <code>--reuse-dir</code> is used).</li> <li>A fresh <code>run_config.toml</code> is copied or generated in that folder.</li> <li>Required values are auto-filled or prompted if missing.</li> <li>Datasets and model versions are downloaded inside the run folder.</li> <li>Outputs generated by the pipeline are written there as well.</li> <li>The <code>run_config.toml</code> is updated at launch and completion with extra metadata (IDs, URLs to datasets, outputs, etc.).</li> </ul>"},{"location":"usage/commands/test/#example-structure","title":"Example structure:","text":"<pre><code>my_pipeline/\n\u251c\u2500\u2500 runs/\n\u2502   \u251c\u2500\u2500 run1/\n\u2502   \u2502   \u251c\u2500\u2500 run_config.toml\n\u2502   \u2502   \u251c\u2500\u2500 dataset/        # downloaded dataset files\n\u2502   \u2502   \u251c\u2500\u2500 model/          # downloaded model weights\n\u2502   \u2502   \u2514\u2500\u2500 outputs/        # generated results\n\u2502   \u251c\u2500\u2500 run2/\n\u2502   \u2502   \u2514\u2500\u2500 run_config.toml\n\u2502   \u2514\u2500\u2500 run3/\n\u2502       \u2514\u2500\u2500 run_config.toml\n</code></pre> <p>\ud83d\udca1 This makes each run self-contained and reproducible.</p>"},{"location":"usage/processing/dataset_version_creation/","title":"Dataset Version Creation Pipeline","text":"<p>This guide explains how to create, customize, test, and deploy a dataset processing pipeline using <code>pxl-pipeline</code> cli with the <code>dataset_version_creation</code> template.</p> <p>These pipelines are typically used to modify images and annotations \u2014 for example, applying augmentations or filtering classes.</p>"},{"location":"usage/processing/dataset_version_creation/#1-initialize-your-pipeline","title":"1. Initialize your pipeline","text":"<pre><code>pxl-pipeline init my_custom_pipeline --type processing --template dataset_version_creation\n</code></pre> <p>This generates a pipeline folder with standard files. See project structure for details.</p>"},{"location":"usage/processing/dataset_version_creation/#2-customize-your-pipeline-logic","title":"2. Customize your pipeline logic","text":""},{"location":"usage/processing/dataset_version_creation/#stepspy","title":"steps.py","text":"<p>The <code>process_images()</code> function defines the core logic. It takes input images and COCO annotations, applies transformations, and writes the output to new directories.</p> <pre><code>from picsellia_cv_engine import step\n\n@step()\ndef process_images(input_images_dir: str, input_coco: dict, output_images_dir: str, output_coco: dict, parameters: dict):\n    # Modify images and annotations here\n    ...\n    return output_coco\n</code></pre> <p>You can split your logic into multiple steps if needed.</p>"},{"location":"usage/processing/dataset_version_creation/#inputoutput-contract","title":"Input/output contract","text":"<p>Each dataset processing step uses these I/O conventions:</p> <ul> <li> <p><code>input_images_dir</code> \u2013 Folder with input images</p> </li> <li> <p><code>input_coco</code> \u2013 COCO annotation dict for input dataset</p> </li> <li> <p><code>parameters</code> \u2013 Dict of pipeline parameters (see Working with parameters)</p> </li> <li> <p><code>output_images_dir</code> \u2013 Empty folder where processed images must be saved</p> </li> <li> <p><code>output_coco</code> \u2013 Empty dict where modified annotations must be written</p> </li> </ul> <p>\ud83d\udca1 You must fill both <code>output_images_dir</code> and <code>output_coco</code>. They are automatically uploaded by the CLI after the step completes.</p>"},{"location":"usage/processing/dataset_version_creation/#image-processing-example","title":"Image processing example","text":"<p>Save processed images like this:</p> <pre><code>processed_img.save(os.path.join(output_images_dir, image_filename))\n</code></pre> <p>Update output_coco with metadata:</p> <pre><code>output_coco[\"images\"].append({\n    \"id\": new_id,\n    \"file_name\": image_filename,\n    \"width\": processed_img.width,\n    \"height\": processed_img.height,\n})\n</code></pre> <p>Be sure to also update the \"annotations\" field.</p>"},{"location":"usage/processing/dataset_version_creation/#checklist","title":"\u2714\ufe0f Checklist:","text":"<ul> <li> <p>Process and save all images to output_images_dir</p> </li> <li> <p>Append image metadata to output_coco[\"images\"]</p> </li> <li> <p>Copy and adapt annotations to output_coco[\"annotations\"]</p> </li> </ul>"},{"location":"usage/processing/dataset_version_creation/#3-define-pipeline-parameters","title":"3. Define pipeline parameters","text":"<p>Parameters can be passed through the pipeline\u2019s context. If you need custom ones, define them in <code>utils/parameters.py</code> using a class that inherits from Parameters:</p> <pre><code>class ProcessingParameters(Parameters):\n    def __init__(self, log_data):\n        super().__init__(log_data)\n        self.blur = self.extract_parameter([\"blur\"], expected_type=bool, default=False)\n</code></pre> <p>See Working with pipeline parameters for more.</p>"},{"location":"usage/processing/dataset_version_creation/#4-manage-dependencies-with-uv","title":"4. Manage dependencies with uv","text":"<p>To add Python packages, use:</p> <pre><code>uv add opencv-python --project my_custom_pipeline\nuv add git+https://github.com/picselliahq/picsellia-cv-engine.git --project my_custom_pipeline\n</code></pre> <p>Dependencies are declared in pyproject.toml. You don\u2019t need to activate or install manually \u2014 see dependency management with uv.</p>"},{"location":"usage/processing/dataset_version_creation/#5-test-your-pipeline-locally","title":"5. Test your pipeline locally","text":"<p>Run your test with:</p> <pre><code>pxl-pipeline test my_custom_pipeline\n</code></pre> <p>This will:</p> <ul> <li>Prompt for the input dataset and output name</li> <li>Run the pipeline via local_pipeline.py</li> <li>Save everything under runs/runX/ (see How runs work)</li> </ul> <p>To reuse the same folder and avoid re-downloading assets, use:</p> <pre><code>pxl-pipeline test my_custom_pipeline --reuse-dir\n</code></pre> <p>See how runs/ work for more details.</p>"},{"location":"usage/processing/dataset_version_creation/#6-deploy-to-pipeline","title":"6. Deploy to pipeline","text":"<pre><code>pxl-pipeline deploy my_custom_pipeline\n</code></pre> <p>This will:</p> <ul> <li> <p>Build and push the Docker image</p> </li> <li> <p>Register the pipeline in Picsellia under Processings \u2192 Dataset \u2192 Private</p> </li> </ul> <p>See deployment lifecycle.</p> <p>Make sure you\u2019re logged in to Docker before deploying.</p>"},{"location":"usage/processing/pre_annotation/","title":"Pre-Annotation Pipeline","text":"<p>This guide explains how to create, customize, test, and deploy a pre-annotation pipeline using <code>pxl-pipeline</code> cli with the <code>pre_annotation</code> template.</p> <p>These pipelines apply an existing model (e.g. YOLOv8, GroundingDINO) to automatically annotate a dataset.</p>"},{"location":"usage/processing/pre_annotation/#1-initialize-your-pipeline","title":"1. Initialize your pipeline","text":"<pre><code>pxl-pipeline init my_preannotation_pipeline --type processing --template pre_annotation\n</code></pre> <p>This generates a pipeline folder with standard files. See project structure for details.</p>"},{"location":"usage/processing/pre_annotation/#2-customize-your-pipeline","title":"2. Customize your pipeline","text":""},{"location":"usage/processing/pre_annotation/#stepspy","title":"steps.py","text":"<p>Contains the <code>process()</code> step where the model is applied to the dataset.</p> <pre><code>@step\ndef process(picsellia_model: Model, picsellia_dataset: CocoDataset):\n    output_coco = process_images(\n        picsellia_model=picsellia_model,\n        picsellia_dataset=picsellia_dataset,\n        parameters=parameters,\n    )\n    ...\n    return picsellia_dataset\n</code></pre>"},{"location":"usage/processing/pre_annotation/#utilsprocessingpy","title":"utils/processing.py","text":"<p>Implements <code>process_images()</code> where you:</p> <ul> <li>Apply the model to each image</li> <li>Generate bounding boxes or segmentation masks</li> <li>Format the output in COCO</li> </ul> <p>You can modify this logic to use a different model (e.g., GroundingDINO) or post-process detections.</p>"},{"location":"usage/processing/pre_annotation/#utilsparameterspy","title":"utils/parameters.py","text":"<p>Define your custom parameters (e.g. threshold):</p> <pre><code>self.threshold = self.extract_parameter([\"threshold\"], expected_type=float, default=0.1)\n</code></pre> <p>Learn more in Working with pipeline parameters.</p>"},{"location":"usage/processing/pre_annotation/#3-manage-dependencies-with-uv","title":"3. Manage dependencies with <code>uv</code>","text":"<p>This template uses <code>uv</code> for dependency management. Dependencies are declared in <code>pyproject.toml</code> and resolved automatically.</p> <p>To add packages:</p> <p><pre><code>uv add opencv-python --project my_preannotation_pipeline\nuv add git+https://github.com/picselliahq/picsellia-cv-engine.git --project my_preannotation_pipeline\n</code></pre> See dependency management with uv for full details.</p>"},{"location":"usage/processing/pre_annotation/#4-test-locally","title":"4. Test locally","text":"<pre><code>pxl-pipeline test my_preannotation_pipeline\n</code></pre> <p>You\u2019ll be prompted for:</p> <ul> <li><code>input_dataset_version_id</code></li> <li><code>model_version_id</code></li> </ul> <p>A new folder will be created under <code>runs/</code>, storing config and results.</p> <p>To reuse the same folder and avoid re-downloading assets, use:</p> <pre><code>pxl-pipeline test my_preannotation_pipeline --reuse-dir\n</code></pre> <p>See how runs/ work for more details.</p>"},{"location":"usage/processing/pre_annotation/#5-deploy-to-picsellia","title":"5. Deploy to Picsellia","text":"<pre><code>pxl-pipeline deploy my_preannotation_pipeline\n</code></pre> <p>This will:</p> <ul> <li> <p>Build and push the Docker image</p> </li> <li> <p>Register the pipeline in Picsellia under Processings \u2192 Dataset \u2192 Private</p> </li> </ul> <p>See deployment lifecycle.</p> <p>Make sure you\u2019re logged in to Docker before deploying.</p>"},{"location":"usage/training/ultralytics/","title":"Ultralytics Training Pipeline Template","text":"<p>This guide explains how to create, customize, test, and deploy a training pipeline using the <code>ultralytics</code> template from <code>pxl-pipeline</code> cli.</p> <p>This pipeline integrates tightly with Picsellia for model logging, dataset handling, and experiment tracking.</p>"},{"location":"usage/training/ultralytics/#1-initialize-your-pipeline","title":"1. Initialize your pipeline","text":"<pre><code>pxl-pipeline init test_training --type training --template ultralytics\n</code></pre> <p>This generates a pipeline folder with standard files. See project structure for details.</p> <p>During init, you'll be prompted to:</p> <ul> <li>Create a new model version or select an existing one</li> <li>If you create one, default parameters from <code>TrainingHyperParameters</code> will be used</li> <li>If using an existing model, ensure the parameter class matches the version's expected inputs</li> </ul>"},{"location":"usage/training/ultralytics/#2-customize-your-pipeline","title":"2. Customize your pipeline","text":""},{"location":"usage/training/ultralytics/#stepspy","title":"<code>steps.py</code>","text":"<p>This is where your model is built and trained:</p> <pre><code>@step()\ndef train(picsellia_model: Model, picsellia_datasets: DatasetCollection[YoloDataset]):\n    ...\n</code></pre> <p>You can modify: - Preprocessing logic - Model instantiation - Training arguments - Logging: save best model, export formats, etc.</p>"},{"location":"usage/training/ultralytics/#utilsparameterspy","title":"<code>utils/parameters.py</code>","text":"<p>This file defines the training configuration for the pipeline.</p> <p>By default:</p> <pre><code>class TrainingHyperParameters(HyperParameters):\n    def __init__(self, log_data: LogDataType):\n        super().__init__(log_data=log_data)\n        self.epochs = self.extract_parameter([\"epochs\"], expected_type=int, default=3)\n        self.batch_size = self.extract_parameter([\"batch_size\"], expected_type=int, default=8)\n        self.image_size = self.extract_parameter([\"image_size\"], expected_type=int, default=640)\n</code></pre> <p>To add a new hyperparameter (e.g., learning rate):</p> <pre><code>self.learning_rate = self.extract_parameter([\"lr\"], expected_type=float, default=0.001)\n</code></pre> <p>Use it in <code>steps.py</code>:</p> <pre><code>ultralytics_model.train(\n    ...,\n    lr0=context.hyperparameters.learning_rate,\n)\n</code></pre> <p>\u27a1\ufe0f See Working with pipeline parameters for more advanced usage.</p> <p>\u26a0\ufe0f Make sure your parameter class stays in sync with your model version\u2019s expected configuration. A sync feature will be added soon to help with this.</p>"},{"location":"usage/training/ultralytics/#pyprojecttoml-customize-your-dependencies","title":"<code>pyproject.toml</code>: Customize your dependencies","text":"<p>Dependencies are managed with uv. To add a new package to the pipeline environment:</p> <pre><code>uv add albumentations --project test_training\n</code></pre> <p>To install a Git-based package:</p> <pre><code>uv add git+https://github.com/picselliahq/picsellia-cv-engine.git --project test_training\n</code></pre> <p>This updates the <code>pyproject.toml</code> and <code>uv.lock</code>. The CLI will automatically install everything on the next test or deploy.</p> <p>See dependency management with uv for full details.</p>"},{"location":"usage/training/ultralytics/#3-test-your-pipeline-locally","title":"3. Test your pipeline locally","text":"<pre><code>pxl-pipeline test test_training\n</code></pre> <p>This will:</p> <ol> <li>Create a <code>.venv</code> in the pipeline folder</li> <li>Install dependencies using uv</li> <li>Prompt for an <code>experiment_id</code></li> </ol> <p>You must create the experiment manually in the Picsellia UI and attach:</p> <ul> <li>The correct model version</li> <li>The training datasets</li> </ul> <p>\u2705 Outputs will be saved under:</p> <pre><code>pipelines/test_training/runs/&lt;runX&gt;/\n\u251c\u2500\u2500 run_config.toml\n\u251c\u2500\u2500 dataset/\n\u2514\u2500\u2500 models/\n</code></pre> <p>See how runs/ work for details on configuration reuse.</p> <p>\ud83d\udca1 If you update the parameters in TrainingHyperParameters, make sure to update them in the experiment config in the UI as well.</p>"},{"location":"usage/training/ultralytics/#4-deploy-to-picsellia","title":"4. Deploy to Picsellia","text":"<pre><code>pxl-pipeline deploy test_training\n</code></pre> <p>This will:</p> <ol> <li>Build a Docker image (based on your Dockerfile)</li> <li>Push it to your Docker registry</li> <li>Register the pipeline with the selected model version in Picsellia</li> </ol> <p>Your <code>Dockerfile</code> installs:</p> <ol> <li><code>picsellia-cv-engine</code></li> <li>Torch + CUDA (via pre-built wheels)</li> <li>Any other dependencies from <code>pyproject.toml</code> or <code>requirements.txt</code></li> </ol>"}]}